#!/usr/bin/perl
# Originally written 15 February 1999 by Jim Lippard as short hack script.
# Rewritten 25 February 1999 by Jim Lippard to use config file and be
#    a bit fancier.  Early a.m. 26 February: changed some error messages,
#    fixed uninitialized variable problem in read_size_file.
# Modified 11 August 1999 by Jim Lippard to support cyclog-format logs.
#    A cyclog is a directory containing files named with timestamps.
#    For cyclogs, we store the time logs were last examined as well as
#    the size of the last log file examined.  We can only detect a
#    reduction in size (editing) on the last log file examined.
#    cyclog is part of Daniel Bernstein's daemontools package, and may
#    be found at ftp://koobera.math.uic.edu/www/daemontools.html
#    This script now requires Time::HiRes from CPAN.
# Modified 26 August 1999 by Jim Lippard to support multilog-format
#    logs.  This is Bernstein's new replacement for cyclog, the format
#    is very similar.  The only real change is when converting the
#    timestamps.  Also modified to sort files within cyclogs/multilogs.
# Modified 23 December 1999 by Jim Lippard to change name on email to
#    "Reporter" and use hostname minus domain name in subject line.
# Modified 23 April 2002 by Jim Lippard to correctly parse regexps which
#    contain colons.
# Modified 12 February 2003 by Jim Lippard to allow the use of a single
#    reportnew.conf file for multiple hosts in a backwards-compatible
#    way by adding optional begin-host: hostname and end-host: hostname
#    fields.  If master_notify appears outside of any begin-host/end-host
#    blocks, it is the master_notify for all hosts.
# Modified 28 June 2003 by Jim Lippard--there appears to be a bug where
#    sometimes notifications are sent when the value in the notify hash
#    is undefined.  A workaround has been put in place to use the master_notify
#    address when an undefined value is sent to the send_notify sub.
# Modified 12 January 2009 by Jim Lippard to convert djbdns log IP addresses.
# Modified 11 February 2011 by Jim Lippard to change size for warning about
#    logfile turning over.
# Modified 3 December 2011 by Jim Lippard to catch an error condition
#    that leads to an unitialized value for $notify_list in the "To"
#    field generation of send_notify, probably caused by a bug in
#    parse_config that leaves everything undefined (perhaps when a
#    new log is added to the config file, perhaps when it's the first
#    log after a begin-host directive?).
# Modified 25 December 2011 by Jim Lippard to use /etc/reportnew.conf as
#    default config file and put default size file in same dir
#    or get it from the config file. Fixed bug mentioned in previous
#    (used "return" instead of "last" to prematurely exit from
#    parse_config subroutine).
# Modified 30 March 2013, 7-8 June 2013 by Jim Lippard to:
#    - Support multiple match/exclude/action triplets per log.
#    - Replace notify: with action: notify
#    - Add action: alert
# Modified 8 June 2013 by Jim Lippard to
#    - Add action: text
# Modified 4 July 2013 by Jim Lippard to add special casing for process
#    accounting logs.
# Modified 18 September 2013 by Jim Lippard to
#    - Add action: execute (with dropped privileges) [incomplete]
# Modified 25 October 2013 by Jim Lippard to change if (defined (@array))
#    to if (exists (@array)), since perl has deprecated the former and now warns.
# Modified 27 November 2019 by Jim Lippard to split hostname and domain name
#    differently (domain name is no longer hardcoded and hostname is just
#    first component of domain name rather than hostname with hardcoded domain
#    name removed).
# Modified 17 February 2020 by Jim Lippard to make notification email sender
#    configurable.
# Modified 22 February 2020 by Jim Lippard to look at rotated logs if a
#    log rotation has occurred since our last check of a standard logfile.
# Modified 23 February 2020 by Jim Lippard to give &match_line the option
#    to return the first capture group instead of 1 for a match.
# Modified 24 February 2020 by Jim Lippard to fix bug in checking for first
#    line date stamps which was causing repeat log reports.
# Modified 25 February 2020 by Jim Lippard to add session matching functionality.
# Modified 26-27 February 2020 by Jim Lippard to fix bugs in checking
#    date/time in first line of log (timezone, web log format).
# Modified 27 February 2020 by Jim Lippard to use SHA256 digest of first line
#    of log instead of parsing dates.
# Modified 28 February 2020 by Jim Lippard to assume a single digit number
#    of rotated logs in &identify_rotated_logs.
# Modified 2 September 2023 by Jim Lippard to read and write size file
#    before and after each log processed, to set email_sender properly
#    for errors that occur before it is defined, and to track current
#    processing on a log in the size file so that another process doesn't
#    start processing on the same log. Use File::Copy instead of system cp.
# Modified 3 September 2023 by Jim Lippard to fix minor bugs and properly
#    identify gzipped rotated log files.
# Modified 4 September 2023 by Jim Lippard to add new logfiles to size file
#    again, since I broke that.
# Modified 11 November 2023 by Jim Lippard to add macro substitution, both
#    pre-processing (to simplify match/exclude rules) and post-processing
#    (to enrich output by appending macro name or substituting macro name
#    in results). Added global and per-host macros in a single namespace.
# Modified 12 November 2023 by Jim Lippard to add special handling of
#    post-processing macro substitution for IP addresses to avoid appending
#    or substitution in the middle of a larger matching IP address.
# Modified 2 December 2023 by Jim Lippard to use unveil on OpenBSD to restrict
#    file system access to read-only for logs, execute-only for commands, and
#    read/write/create for /tmp.
# Modified 30 December 2023 by Jim Lippard to call pledge correctly.
# Modified 1 January 2024 by Jim Lippard so that first look at process
#    accounting logs in a new year doesn't go to the beginning (call to
#    parsedate was not using PREFER_PAST).
# Modified 1 January 2024 by Jim Lippard to clean up size file code and
#    implement file locking.
# Modified 10 February 2024 by Jim Lippard to allow importing macro values
#    from files.
# Modified 16 March 2024 by Jim Lippard to ignore comment lines in imported
#    files.
# Modified 31 March 2024 by Jim Lippard to properly complain about garbled
#    lines in size file.
# Modified 8 April 2024 by Jim Lippard to fix uninitialized $processing_pid
#    bug when size file is first created, make alert action use line breaks.
# Modified 14 April 2024 by Jim Lippard to handle process accounting logs
#    directly on OpenBSD for greater efficiency.
# Modified 17 April 2024 by Jim Lippard to set last log checktime more
#    appropriately for process accounting logs (to match end of most recent
#    log processing for OpenBSD, and start of most recent log procesing for
#    the old lastcomm/reverse order processing).
# Modified 22 April 2024 by Jim Lippard to remove 'ps' pledge by using
#    kill to verify existence of running processes instead of calling ps.
# Modified 23 April 2024 by Jim Lippard to use IO::Uncompress::Gunzip
#    instead of calling gunzip command, Sys::Hostname instead of hostname
#    command. Use OpenBSD::MkTemp on OpenBSD. Still need exec for sendmail,
#    tai64nlocal/echo (could use Time::TAI64 and Mail::Send; latter requires
#    escaping leading dots on message body lines).
# Modified 5 July 2024 by Jim Lippard to allow signedfile include macros
#    and add signify_publickey global directive.
# Modified 28 July 2024 by Jim Lippard to use Signify.pm.
# Modified 16 December 2024 by Jim Lippard for new config file format and
#    to add -c config check option and -d debug option (for existing
#    debug_flag). Remains backward compatible with the begin-host/end-host
#    format.
# Modified 17 December 2024 by Jim Lippard to fix up -c config check and
#    enforce restriction on using hosts and begin-host/end-host in the same
#    config file.
# Modified 22 December 2024 by Jim Lippard to properly handle process
#    accounting logs on a system that hasn't generated all of the rotated
#    logs yet and fail more gracefully if log files are missing.
# Modified 6 May 2025 by Jim Lippard to add include-macro-file and
#    include-macro-signedfile to allow files of full macro definitions
#    in addition to files of macro values. Create size file if it doesn't
#    exist to reduce unveil surface and pledges.
# Modified 8 May 2025 by Jim Lippard to do additional unveiling for signify
#    checking and use full signify public key path.
# Modified 6 July 2025 by Jim Lippard to use uid in process accounting logs
#    if there's no corresponding user in passwd file.
# Modified 13 August 2025 by Jim Lippard to allow whitespace (not just
#    non-whitespace) in macro definitions.
# Modified 14 September 2025 by Jim Lippard to change path of process
#    accounting log and handle lastcomm format for Linux, add -V version.
# Modified 16 September 2025 by Jim Lippard to support pulling logs from
#    Linux journals using journalctl.
# Modified 18 September 2025 by Jim Lippard to adjust $linux_format for
#    pacct for when there are overlength times.
# Modified 21 September 2025 by Jim Lippard to improve error message that
#    comes from OpenBSD process accounting when it gets turned off, clean
#    up some regexes.
# Modified 4 November 2025 by Jim Lippard to use File::Temp instead of
#    calling mktemp, do better validation on TAI64 dates, avoid shell
#    when invoking sendmail, use chomp instead of chop, create temp dir
#    once per execution, set umask so all created files are only readable
#    by root user, remove tai64nlocal command method for TAI64 log files.
# Modified 12 November 2025 by Jim Lippard to use $macos_format instead of
#    split for macOS process accounting logs, since command names can have
#    spaces in them.
# Modified 15 November 2025 by Jim Lippard to rearrange unveil order slightly,
#    fail if can't create temp dir, improve macOS process accounting sample in
#    config file.
# Modified 22 November 2025 by Jim Lippard to change read_size to get_size
#    to avoid possible implication that it's related to reading from the size
#    file. Do minimal validation on email addresses.
#    Fix minor bug in non-OpenBSD process accounting.
# Modified 25 November 2025 by Jim Lippard to open $JOURNALCTL without
#    invoking shell. Fix bug in identify_rotated_logs not matching gzips.
#    Preparation for privilege separation/running all log checks as
#    _reportnew when run as root.
#
#
# To Do:
#    - validate email addresses that can be passed to &send_notify.
#    - Find way to not miss additional process execution within the same
#      minute of the last check?
#    - Add time range checking option for match and exclude (new directive?)

# Suggested enhancements:
# * Process all rotated logs and original log, as well as all components
#   of cyclogs or multilogs, together and process all notifications for them
#   together at once instead of once per match per file.
# * Allow customization of subject line so that multiple reportnew
#   configs can be used on the same machine/same logs and be distinguishable.
# * Allow to run continuously (like swatch) monitoring logs with
#   select.  That will perhaps be more efficient than starting up
#   a perl process every N minutes, and will catch log changes more
#   rapidly.  It should wait a little bit for additional matching
#   messages, though, so that it doesn't send a separate message for
#   each log line.  (Easiest way might be to make it go into an
#   infinite loop, sleeping every N minutes at the end.  Though
#   it would be more efficient to use select.)

### Required packages.

use strict;
use warnings;
use Digest::SHA qw( sha256_hex );
use Fcntl qw(:DEFAULT :flock);
use File::Basename;
use File::Copy;
use if $^O ne "openbsd", "File::Temp", qw( :mktemp tempfile );
use Getopt::Std;
use IO::Uncompress::Gunzip qw( gunzip $GunzipError);
use POSIX qw( strftime );
#use Privileges::Drop;
use Signify;
use Sys::Hostname;
use Time::HiRes qw( gettimeofday );
use Time::ParseDate;
# required for multilog format
#use Time::TAI64 qw( :tai64n );
#my $TimeTAI64_module = 1;
my $TimeTAI64_module = 0;

use if $^O eq "openbsd", "OpenBSD::MkTemp", qw( mkdtemp mkstemp );
use if $^O eq "openbsd", "OpenBSD::Unveil";
use if $^O eq "openbsd", "OpenBSD::Pledge";

use POSIX qw( ctime fmod );
use constant AHZ => 64;
use constant SECSPERHOUR => 60 * 60;
use constant SECSPERMIN => 60;

### Constants.

my $HOSTNAME = hostname();
my ($SHORT_HOSTNAME, $DOMAINNAME) = split (/\./, $HOSTNAME, 2);

### Set to your security admin.
my $SECURITY_ADMIN = 'lippard@discord.org';

my $EMAIL_SENDER = 'nobody@' . $DOMAINNAME;

### Set to your log time zone (used only in one subroutine below).
my $TIME_ZONE = 'MST';

# for Linux journal logs.
my $JOURNALCTL = '/usr/bin/journalctl';
my $SYSTEMCTL = '/usr/bin/systemctl';

my $LASTCOMM = '/usr/bin/lastcomm';
my $SENDMAIL = '/usr/sbin/sendmail';
my $SIGNIFY = '/usr/bin/signify';
my $ETC_DIR = '/etc';
my $ZONEINFO_DIR = '/usr/share/zoneinfo';

my $VERSION = 'reportnew 1.25b of 27 November 2025';

my $DEFAULT_CONFIG_DIR = '/etc/reportnew';
my $DEFAULT_CONFIG_NAME = 'reportnew.conf';
my $DEFAULT_SIZE_FILE_DIR = '/etc/reportnew';
my $DEFAULT_SIZE_FILE_NAME = 'reportnew.size';
my $CONFIG_SUFFIX = ".conf";
my $SIZE_SUFFIX = ".size";

my $SIZE_FILE_LOCK_TIMEOUT_LIMIT = 10;

my $SIGNIFY_DIR = '/etc/signify';

my $PROCESS_ACCOUNTING_LOG = '/var/account/acct'; # BSD and macOS location.
$PROCESS_ACCOUNTING_LOG = '/var/log/account/pacct' if ($^O eq 'linux');
my $MAX_PROCESS_ACCOUNTING_FILE = 3;

my $NL = '
';

my $LOG_TYPE_STANDARD_LOG = 0;
my $LOG_TYPE_CYCLOG_OR_MULTILOG = 1;
my $LOG_TYPE_PROCESS_ACCOUNTING = 2;
my $LOG_TYPE_LINUX_JOURNAL = 3;

my $LOG_PROCESSING_START = 1;
my $LOG_PROCESSING_END = 2;
my $LOG_APPEND = 3;

my $GLOBAL_CONTEXT = 1;
my $HOST_CONTEXT = 2;
my $SKIPPING = 3;
my $LOG_CONTEXT = 3; # not used, uses !defined($current_logfile)

### Variables.

# Filenames.
use vars qw($config_file $size_file $temp_dir);

# Global variables from config file.
use vars qw(
    $master_notify
    $email_sender
    $signify_pubkey
    @logfiles
    %match_hash
    %exclude_hash
    %action_hash
    %match_hash_ref
    %exclude_hash_ref
    %action_hash_ref
    %global_preproc_macro
    $have_global_postproc_macros
    %global_append_macro
    %global_substitute_macro   
    %preproc_macro
    $have_postproc_macros
    %append_macro
    %substitute_macro
    );

# Global variables from size file.
use vars qw(
    %log_size
    %log_mtime
    %log_checktime
    %log_sha256_digest
    %log_processing_pid
    );

# Global variables for linux journal logs.
use vars qw(
    @linux_journal_units
    @linux_journal_syslog_facilities
);

# Other global variables.
use vars qw(
    $debug_mode
    $config_check
    %opts
    %defined_hosts
    %defined_hostlog
    );

# Local variables in main program.
my ($logfile, $size, $mtime, $sha256_digest,  @cyclog_files, $cyclog_file,
    $old_log_checktime, $got_first_cyclog_file, $temp_logfile);
my ($rotated_logs_flag, $processed_rotated_log_flag, @rotated_logs, $rotated_logfile);

### Main program.

getopts ('cdV', \%opts) || die "Usage: reportnew [-c (check)|-d (debug)|-V (version)] [config-file]\n";

$config_check = $opts{'c'};
$debug_mode = $opts{'d'} || $config_check; # config_check implies debug_mode;
if ($opts{'V'}) {
    die "-V (version) cannot be used with other options.\n" if ($config_check || $debug_mode);
    print "$VERSION\n";
    exit;
}

if ($#ARGV == 0) {
    $config_file = $ARGV[0];
}
elsif ($#ARGV < 0) {
    $config_file = "$DEFAULT_CONFIG_DIR/$DEFAULT_CONFIG_NAME";
}
else {
    die "Usage: reportnew [-c (check)|-d (debug)|-V (version)] [config-file]\n";
}

if (substr ($config_file, length ($config_file) - 5, 5) ne $CONFIG_SUFFIX) {
    $config_file .= $CONFIG_SUFFIX;
}

# If on OpenBSD, use pledge and unveil. Do as much as possible before
# parsing the config, then finish unveiling after the config is parsed.
if ($^O eq 'openbsd') {
    # Pledge. stdio is already included.
    # proc required for pid testing and any exec requirements.
    # exec required for sendmail.
    pledge ('exec', 'proc', 'rpath', 'wpath', 'cpath', 'tmppath', 'unveil', 'flock') || die "Cannot pledge promises. $!\n";
    
    # Needed to parse dates on process accounting logs.
    unveil ($ZONEINFO_DIR, 'r');

    # Need for username resolution on process accounting logs.
    unveil ($ETC_DIR, 'r');

    # Unveil directory where config file is, so that any macros
    # with file import can be processed.
    my $macro_dir = dirname ($config_file);
    unveil ($macro_dir, 'r');

    # Allow writing to and creating files and dirs in /tmp.
    unveil ('/tmp', 'rwc');

    # Allow execution of commands. $LASTCOMM excluded since
    # it's not used on OpenBSD.
    unveil ($SENDMAIL, 'x');
    # Signify for signed include files in macros.
    unveil ($SIGNIFY, 'rx');
    unveil (dirname ($SIGNIFY), 'rx');
    unveil ($SIGNIFY_DIR, 'rx');
    unveil ('/dev/null', 'rw');
}

&parse_config ($config_file);

if ($config_check) {
    print "No issues identified in config file.\n";
    exit;
}

# Unveil log dirs from config and lock.
# If script execution actions are added, will need to unveil here.
if ($^O eq 'openbsd') {
    my (%unveiled_dirs, $logdir, $size_file_dir);

    # Unveil log directories.
    foreach $logfile (@logfiles) {
	next if $logfile =~ /^journal /; # shouldn't happen.
	$logdir = dirname ($logfile);
	if (!defined ($unveiled_dirs{$logdir})) {
	    unveil ($logdir, "r");
	    $unveiled_dirs{$logdir} = 1;
	}
    }

    # Need to unveil containing dir of size file, which can but
    # need not be same as containing dir of config file.
    $size_file_dir = dirname ($size_file);
    unveil ($size_file_dir, 'r');
    
    # Allow reading from and writing to size file.
    # c required for append.
    unveil ($size_file, 'rwc');
    
    # Need to unveil containing dir with rwc in order to create
    # size file if it doesn't already exist. Go ahead and create it.
    if (!-e $size_file) {
	$size_file_dir = dirname ($size_file);
	unveil ($size_file_dir, 'rwc');
	if (open (SIZEFILE, '>', "$size_file_dir/$size_file")) {
	    close (SIZEFILE);
	}
	else {
	    &send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot create size file. $!");
	}
	unveil ($size_file_dir, 'r');
    }

    # Now lock it to just those.
    unveil ();
}

# Any files we create are rw for root (or running user, non-priv works
# fine for process accounting) only.
my $old_umask = umask;
umask 0077;

# Create a temp_dir.
$temp_dir = mkdtemp ('/tmp/reportnew.XXXXXXX') || die "Cannot create temp dir. $!\n";
chomp ($temp_dir);

# Modified to read and write size file after each log processed, so that
# if something fails on processing, work already done isn't repeated.

foreach $logfile (@logfiles) {

    # Read all logs from size file, skip this one if it's already
    # being processed, otherwise mark this one as being processed.
    &read_size_file ($size_file);
    next if ($log_processing_pid{$logfile} != 0 && &pid_exists ($log_processing_pid{$logfile}));
    &write_size_file ($size_file, $logfile, $LOG_PROCESSING_START); # save PID

    if ($logfile eq $PROCESS_ACCOUNTING_LOG) {
	# For process accounting logs, we get the log checktime from this
	# read and not at the end of processing the log.
	
	# On OpenBSD, we still create a temp logfile from process
	# accounting logs, but do so directly instead of by calling
	# lastcomm, and we find the starting point more efficiently.
	if ($^O eq 'openbsd') {
	    ($temp_logfile, $log_checktime{$logfile}) = &openbsd_read_process_acct_log ($PROCESS_ACCOUNTING_LOG, $log_checktime{$logfile}, $temp_dir);
	}
	# Otherwise:
	# Read process accounting logs out to the last time seen, or
	# for all of it, and write it out to a tmp file, $temp_logfile,
	# putting it into chronological order instead of reverse.
	else {
	    ($temp_logfile, $log_checktime{$logfile}) = &read_process_acct_log ($PROCESS_ACCOUNTING_LOG, $log_checktime{$logfile}, $temp_dir);
	}
	# Then use check_logfile on the temp file, disregarding the size,
	# which is set to 0, just as for files in cyclogs.
	my $ignore_checktime;
	($log_size{$logfile}, $log_mtime{$logfile}, $ignore_checktime, $log_sha256_digest{$logfile}) =
	    &check_logfile ($temp_logfile, 0, $log_mtime{$logfile},
			    $log_checktime{$logfile}, $log_sha256_digest{$logfile},
			    $match_hash_ref{$logfile},
			    $exclude_hash_ref{$logfile}, $action_hash_ref{$logfile}, $LOG_TYPE_PROCESS_ACCOUNTING);

	# Unlink $temp_logfile.
	unlink ($temp_logfile);
    }
    elsif ($logfile =~ /^journal /) {
	# Similar to process accounting files, we handle Linux journal logs
	# by writing out the relevant information to a temporary log file,
	# and don't care about tracking size. We use the last read time as
	# the start time (with journalctl --since).
	# Options:
	# journal unit <unit>
	#    journalctl -u <unit> --since <last_check_time>
	# journal syslog-id <identifier>
	#    journalctl -t <identifier> --since <last_check_time>
	# journal syslog-facility <facility>
	#    journalctl --facility=<facility> --since <last_check_time>
	($temp_logfile, $log_checktime{$logfile}) = &read_linux_journal ($logfile, $log_checktime{$logfile}, $temp_dir);
	# Then use check_logfile on the temp file, disregarding the size,
	# which is set to 0, just as for files in cyclogs.
	my $ignore_checktime;
	($log_size{$logfile}, $log_mtime{$logfile}, $ignore_checktime, $log_sha256_digest{$logfile}) =
	    &check_logfile ($temp_logfile, 0, $log_mtime{$logfile},
			    $log_checktime{$logfile}, $log_sha256_digest{$logfile},
			    $match_hash_ref{$logfile},
			    $exclude_hash_ref{$logfile}, $action_hash_ref{$logfile}, $LOG_TYPE_LINUX_JOURNAL, $logfile);

	# Unlink $temp_logfile.
	unlink ($temp_logfile);
    }
    elsif (!-d $logfile) { # Standard syslog file.
	# If there are archived rotated logs which have been modified since
	# log_checktime{$logfile}, we should check any contents that postdate
	# that time. The oldest rotated logfile changed after our last
	# checktime will be the last one we looked at OR a more recent one
	# that we have to look at in its entirety (depending on frequency
	# of checks vs log rotation/retention, it might have already been
	# deleted).
	# We check the oldest one modified after our last check, and
	# if its first line is newer than our last check we check the entire
	# thing, otherwise we presume it's the same logfile we last checked
	# and we start where we left off.
	($rotated_logs_flag, @rotated_logs) = &identify_rotated_logs ($logfile, $log_checktime{$logfile});
	# We have rotated logs we need to examine.
	if ($rotated_logs_flag) {
	    $processed_rotated_log_flag = 0;
	    foreach $rotated_logfile (@rotated_logs) {
		# If the oldest logfile is one we've seen part of before,
		# we'll seek to the right position. We verify by checking
		# the SHA256 digest of the first line to see if it matches
		# what was there before. This check also occurs in check_logfile.
		# This will "work" on a gzip but could have high rate of
		# false positives.
		if (!$processed_rotated_log_flag) {
		    # If first line is different from what we last saw,
		    # then start from the beginning.
		    if ($log_sha256_digest{$logfile} eq '' ||
			&first_log_line_sha256_digest ($rotated_logfile) ne
			$log_sha256_digest{$logfile}) {
			$log_size{$logfile} = 0;
		    }
		    # We don't look at return values here.
			&check_logfile ($rotated_logfile, $log_size{$logfile}, $log_mtime{$logfile},
					$log_checktime{$logfile},
					$log_sha256_digest{$logfile},
					$match_hash_ref{$logfile},
					$exclude_hash_ref{$logfile},
					$action_hash_ref{$logfile},
					$LOG_TYPE_STANDARD_LOG);
		    
			$processed_rotated_log_flag = 1;
		}
		else {
		    # Again, not looking at return values.
		    &check_logfile ($rotated_logfile, 0, 0, 0,
				    $log_sha256_digest{$logfile},
				    $match_hash_ref{$logfile},
				    $exclude_hash_ref{$logfile},
				    $action_hash_ref{$logfile},
				    $LOG_TYPE_STANDARD_LOG);
		}

		# Set log_size to 0 for the regular logfile since we need to
		# look at the whole thing, and update first line SHA256.
		$log_size{$logfile} = 0;
		$log_sha256_digest{$logfile} = &first_log_line_sha256_digest ($logfile);
	    } # End processing of rotated logs.
	} # Standard logfile check.
	
	($log_size{$logfile}, $log_mtime{$logfile}, $log_checktime{$logfile}, $log_sha256_digest{$logfile}) =
	    &check_logfile ($logfile, $log_size{$logfile}, $log_mtime{$logfile},
			    $log_checktime{$logfile},
			    $log_sha256_digest{$logfile},
			    $match_hash_ref{$logfile},
			    $exclude_hash_ref{$logfile}, $action_hash_ref{$logfile}, $LOG_TYPE_STANDARD_LOG);
    }
    else { # cyclog or multilog
	if (opendir (CYCLOG, $logfile)) {
	    @cyclog_files = grep (!/^\./, readdir (CYCLOG));
	    closedir (CYCLOG);
	    $got_first_cyclog_file = 0;
	    $old_log_checktime = $log_checktime{$logfile};
	    foreach $cyclog_file (sort (@cyclog_files)) {
		next if ($cyclog_file eq 'lock'); # multilog format
		next if ($cyclog_file eq 'state'); # multilog format
		$cyclog_file = $logfile . '/' . $cyclog_file;
		($size, $mtime) = &get_size ($cyclog_file);
		next if ($mtime < $old_log_checktime);
		# If we get here, then we've found the oldest changed file
		# (since we last checked).
		$got_first_cyclog_file++;
		if ($got_first_cyclog_file == 1) {
		    ($log_size{$logfile}, $log_mtime{$logfile}, $log_checktime{$logfile}, $log_sha256_digest{$logfile}) =
			&check_logfile ($cyclog_file, $log_size{$logfile}, $log_mtime{$logfile},
					$old_log_checktime,
					$log_sha256_digest{$logfile},
					$match_hash_ref{$logfile},
					$exclude_hash_ref{$logfile},
					$action_hash_ref{$logfile},
					$LOG_TYPE_CYCLOG_OR_MULTILOG);
		}
		# For all the new files, we don't care about size or mtime.
		else {
		    ($log_size{$logfile}, $log_mtime{$logfile}, $log_checktime{$logfile}) =
			&check_logfile ($cyclog_file, 0, 0, 0,
					$log_sha256_digest{$logfile},
					$match_hash_ref{$logfile},
					$exclude_hash_ref{$logfile},
					$action_hash_ref{$logfile},
					$LOG_TYPE_CYCLOG_OR_MULTILOG);
		    # If we're on the last one, set the first line SHA256 digest.
		    # (Count is number of last element, not number of elements.)
		    # This is never reached if there is only one, but we've
		    # already set SHA256 above for the first one (zeroth) as well.
		    if ($got_first_cyclog_file > $#cyclog_files) {
			$log_sha256_digest{$logfile} = &first_log_line_sha256_digest ($cyclog_file);
		    }
		}
	    } # foreach
	} # if opendir successful
	else {
	    &send_error ($logfile, "Could not open cyclog/multilog $logfile. $!");
	}
    }

    # Read all other logs from size file, then update this one.
    &read_size_file ($size_file, $logfile);
    &write_size_file ($size_file, $logfile, $LOG_PROCESSING_END);
}

# Remove temp dir.
rmdir ($temp_dir);
umask $old_umask;

### Subroutines.

# Subroutine to parse configuration file.
# As written you the global directives at the top in the sample config file
# can be anywhere, it would probably be better to have a global section
# and individual host sections.
sub parse_config {
    my ($config_file) = @_;
    my ($current_context, $directive, $value, $line_num, $current_logfile,
	$specified_host, $current_host, $all_host_master_notify,
	$action, $action_value, $current_match_session_match_flag);
    my ($macro_name, $macro_value, $macro_options, $macro_file, $macro_dir);
    my ($multihost_config, $oldstyle_multihost, $found_my_host);
    my ($linux_journal_unit, $linux_journal_syslogid, $linux_journal_syslogfacility);

    $line_num = 0;
    $specified_host = 0;
    $current_match_session_match_flag = 0;
    $current_context = $GLOBAL_CONTEXT;
    $have_global_postproc_macros = 0;
    $have_postproc_macros = 0;
    $multihost_config = 0;
    $oldstyle_multihost = 0;
    $found_my_host = 0;
    $linux_journal_unit = 0;
    $linux_journal_syslogid = 0;
    $linux_journal_syslogfacility = 0;
    if (open (CONFIG, '<', $config_file)) {
	while (<CONFIG>) {
	    $line_num++;
	    if (!/^\s*#|^\s*$/) {
		chomp;
		# if SKIPPING, don't resume until we see another "hosts:",
		# unless doing a config_check.
		next if ($current_context == $SKIPPING &&
			 !/^\s*hosts:/ &&
			 !$config_check);
		# Macro definitions.
		if (/^([\w\-]+)\s*=\s*\"(.+)\"(.*$)/) {
		    $macro_name = $1;
		    $macro_value = $2;
		    $macro_options = $3;
		    &parse_macro ($macro_name, $macro_value, $macro_options,
				  $current_context, $current_host,
				  $line_num, 0);
		}
		elsif (/^.*:.*$/) {
		    ($directive, $value) = split (/:\s*/, $_, 2);

		    if ($directive eq 'hosts') {
			if ($multihost_config && $oldstyle_multihost) {
			    &send_error ($config_file, "Found \"hosts:\" directive while using old style \"begin-host:\" and \"end-host:\" directives on line $line_num. $value");
			    exit;
			}
			elsif (!$multihost_config) {
			    $multihost_config = 1;
			}
			if (defined ($master_notify) && !defined ($current_host)) {
			    $all_host_master_notify = $master_notify;
			}
			$current_host = $value if ($config_check);
			if (&my_host ($line_num, $value)) {
			    $current_context = $HOST_CONTEXT;
			    $current_host = $HOSTNAME if (!$config_check);
			    $found_my_host = 1;
			}
			else {
			    $current_context = $SKIPPING;
			}
		    }
		    elsif ($directive eq 'begin-host') {
			if ($multihost_config && !$oldstyle_multihost) {
			    &send_error ($config_file, "Found \"begin-host:\" directive while using new style \"hosts:\" directive on line $line_num. $value");
			    exit;
			}
			elsif (!$multihost_config) {
			    $multihost_config = 1;
			    $oldstyle_multihost = 1;
			}
			if (defined ($master_notify) && !defined ($current_host)) {
			    $all_host_master_notify = $master_notify;
			}
			$current_host = $value;
			$current_context = $HOST_CONTEXT;
			if ($config_check && !defined ($defined_hosts{$current_host})) {
			    print "New host name in \"begin-host:\" directive on line $line_num. $current_host\n";
			    $defined_hosts{$current_host} = 1;
			}
		    }
		    elsif ($directive eq 'end-host') {
			if ($multihost_config && !$oldstyle_multihost) {
			    &send_error ($config_file, "Found \"end-host:\" directive while using new style \"hosts:\" directive on line $line_num. $value");
			    exit;
			}
			if ($current_host ne $value) {
			    &send_error ($config_file, "end-host directive does not match begin-host directive (which uses \"$current_host\") on line $line_num. $value\n");
			    exit;
			}
			if ($current_host eq $HOSTNAME || $current_host eq $SHORT_HOSTNAME) {
			    $found_my_host = 1;
			    last unless ($config_check);
			}
			$current_host = "";
			undef $master_notify;
			undef @logfiles;
			undef %match_hash;
			undef %exclude_hash;
			undef %action_hash;
			undef %preproc_macro;
			undef %append_macro;
			undef %substitute_macro;
			$have_postproc_macros = 0;
		    }
		    elsif ($directive eq 'master_notify') {
			if (defined ($master_notify)) {
			    &send_error ($config_file, "Second master_notify directive on line $line_num. $value");
			    exit;
			}
			if (!&valid_email ($value)) {
			    &send_error ($config_file, "Invalid email address in master_notify directive on line $line_num. $value");
			    exit;
			}
			$master_notify = $value;
		    }
		    elsif ($directive eq 'size_file') {
			if (defined ($size_file)) {
			    &send_error ($config_file, "Second size_file directive on line $line_num. $value");
			    exit;
			}
			$size_file = $value;
		    }
		    elsif ($directive eq 'email_sender') {
			if (defined ($email_sender)) {
			    &send_error ($config_file, "Second email_sender directive on line $line_num. $value");
			    exit;
			}
			$email_sender = $value;
		    }
		    elsif ($directive eq 'signify_pubkey') {
			if (defined ($signify_pubkey)) {
			    &send_error ($config_file, "Second signify_pubkey directive on line $line_num. $value");
			    exit;
			}
			$signify_pubkey = $value;
			if ($signify_pubkey !~  /^[\w\-\.]+$/) {
			    &send_error ($config_file, "Invalid signify_pubkey file name \"$signify_pubkey\" line $line_num. $_\n");
			    exit;
			}
			$signify_pubkey .= '.pub' if (substr ($signify_pubkey, length ($signify_pubkey) - 4, 4)) ne '.pub';
			if (!-e "$SIGNIFY_DIR/$signify_pubkey") {
			    &send_error ($config_file, "Signify public key doesn't exist, \"$signify_pubkey\" on line $line_num. $_\n");
			    exit;
			}
			if (!-r "$SIGNIFY_DIR/$signify_pubkey") {
			    &send_error ($config_file, "Signify public key is not readable, \"$signify_pubkey\" on line $line_num. $_\n");
			    exit;	
			}
			$signify_pubkey = $SIGNIFY_DIR . '/' . $signify_pubkey;
		    }
		    elsif ($directive eq 'log') {
			# No longer check for logfile existence here due to need
			# to unveil first.
			# First, see if we already have this log file.
			if (grep ($_ eq $value, @logfiles)) {
			    if ($config_check && $multihost_config && !$oldstyle_multihost) {
				my (@hosts, $host);
				@hosts = split (/\s+/, $current_host);
				foreach $host (@hosts) {
				    if ($defined_hostlog{"$host:$value"}) {
					&send_error ($config_file, "Previously defined logfile for host $host on line $line_num. $value");
					exit;
				    }
				    $defined_hostlog{"$host:$value"} = 1;
				}
				# don't push to @logfiles, it's already there
				$current_logfile = $value;
				next;
			    }
			    else {
				&send_error ($config_file, "Previously defined logfile on line $line_num. $value");
				exit;
			    }
			}
			# Do minimal validation on log name.
			if (!&valid_logfile_format ($value)) {
			    &send_error ($config_file, "Invalid logfile name on line $line_num. $value");
			    exit;
			}
			if ($value =~ /^journal (unit|syslog-id|syslog-facility)/) {
			    if ($1 eq 'unit') {
				$linux_journal_unit = 1;
			    }
			    elsif ($1 eq 'syslog-id') {
				$linux_journal_syslogid = 1;
			    }
			    else {
				$linux_journal_syslogfacility = 1;
			    }
			}
			push (@logfiles, $value);
			$current_logfile = $value;
		    }
		    elsif ($directive eq 'match') {
			if (!defined ($current_logfile)) {
			    &send_error ($config_file, "No log directive corresponding to match directive on line $line_num. $_");
			    exit;
			}
			if (($value eq 'all') || &valid_regexp ($value) || ($value =~ /^session-with (.*$)/ && &valid_regexp ($1))) {
			    # Do preproc macro substitution.
			    $value = &preproc_macro_substitution ($value, $line_num) if ($value =~ /%%[\w\-]+%%/);
			    push (@{$match_hash{$current_logfile}}, $value);
			    if ($value =~ /^session-with/) {
				$current_match_session_match_flag = 1;
			    }
			    else {
				$current_match_session_match_flag = 0;
			    }
			}
			else {
			    &send_error ($config_file, "Invalid match directive on line $line_num. $_");
			    exit;
			}
		    }
		    elsif ($directive eq 'exclude') {
			if (!defined ($current_logfile)) {
			    &send_error ($config_file, "No log directive corresponding to exclude directive on line $line_num. $_");
			    exit;
			}
			if (($value eq 'none') || &valid_regexp ($value) || ($value =~ /^session-without (.*$)/ && &valid_regexp ($1))) {
			    if ($value =~ /^session-without/ && !$current_match_session_match_flag) {
				&send_error ($config_file, "Exclude directive is a session match but corresponding match directive is not on line $line_num. $_");
				exit;
			    }
			    elsif ($value !~ /^session-without/ && $current_match_session_match_flag) {
				&send_error ($config_file, "Exclude directive is not a session match but corresponding match directive is on line $line_num. $_");
				exit;
			    }
			    # Do preproc macro substitution.
			    $value = &preproc_macro_substitution ($value, $line_num) if ($value =~ /%%[\w\-]+%%/);
			    push (@{$exclude_hash{$current_logfile}}, $value);
			}
			else {
			    &send_error ($config_file, "Invalid exclude directive on line $line_num. $_");
			}
		    }
		    elsif ($directive eq 'action') {
			if (!defined ($current_logfile)) {
			    &send_error ($config_file, "No log directive corresponding to action directive on line $line_num. $_");
			    exit;
			}
			# Parse action (action, whitespace, value).
			if ($value !~ /\s/) {
			    $action = $value;
			    undef $action_value;
			}
			else {
			    ($action, $action_value) = split (/\s+/, $value, 2);
			}
			# action: notify
			if ($action eq 'notify') {
			    if (defined ($action_value)) {
				# Minimal email validation.
				my @check_emails = split (/,\s*/, $action_value);
				foreach my $check_email (@check_emails) {
				    if (!&valid_email ($check_email)) {
					&send_error ($config_file, "Invalid email address(es) following \"notify\" action in action directive on line $line_num. $_");
					exit;
				    }
				}
				push (@{$action_hash{$current_logfile}}, "$action,$action_value");
			    }
			    else {
				&send_error ($config_file, "Missing email address(es) following \"notify\" action in action directive on line $line_num. $_");
				exit;
			    }
			}
			# action: text
			elsif ($action eq 'text') {
			    if (defined ($action_value)) {
				# Should probably validate email format?
				push (@{$action_hash{$current_logfile}}, "$action,$action_value");
			    }
			    else {
				&send_error ($config_file, "Missing email address(es) following \"text\" action in action directive on line $line_num. $_");
				exit;
			    }
			}
			# action: alert
			elsif ($action eq 'alert') {
			    if (defined ($action_value)) {
				&send_error ($config_file, "Extraneous data following \"alert\" action in action directive on line $line_num. $_");
				exit;
			    }
			    push (@{$action_hash{$current_logfile}}, $action);
			}
			# action: execute
			elsif ($action eq 'execute') {
			    if (defined ($action_value)) {
				push (@{$action_hash{$current_logfile}}, "$action,$action_value");
			    }
			    else {
				&send_error ($config_file, "Missing script name following \"execute\" action in action directive on line $line_num. $_");
				exit;
			    }
			}
			# Other actions?
			else {
			    &send_error ($config_file, "Unknown action specified in action directive on line $line_num. $_");
			    exit;
			}
		    }
		    # For backwards compatibility.
		    elsif ($directive eq 'notify') {
			if (!defined ($current_logfile)) {
			    &send_error ($config_file, "No log directive corresponding to notify directive on line $line_num. $_");
			    exit;
			}
			push (@{$action_hash{$current_logfile}}, "$directive,$value");
			# need to specify that action=notify, and add
			# separate code to parse new action: directive.
		    }
		    # For including a file of macro definitions.
		    elsif ($directive eq 'include-macro-file' ||
			   $directive eq 'include-macro-signedfile') {
			$macro_file = $value;
			$macro_dir = dirname ($config_file);
			if ($macro_file !~  /^[\w\-\.]+$/) {
			    &send_error ($config_file, "Invalid macro include file name \"$macro_file\" in macro \"$macro_name\" on line $line_num. $_\n");
			    exit;
			}
			$macro_file = $macro_dir . '/' . $macro_file;
			if (!-r $macro_file) {
			    &send_error ($config_file, "Cannot read macro include file $macro_file in macro \"$macro_name\" on line $line_num. $_\n");
			    exit;
			}
			if ($directive =~ /signed/) {
			    if (!defined ($signify_pubkey)) {
				&send_error ($config_file, "No signify_pubkey directive has been parsed yet in config file before use of macro include file \"$macro_file\" on line $line_num. $_\n");
				exit;
			    }
			    if (!&verify_signify_sig ($macro_file)) {
				&send_error ($config_file, "Cannot verify signify signature on signed macro include file \"$macro_file\" on line $line_num. $_\n");
				exit;
			    }
			}
			if (open (INCLUDEFILE, '<', $macro_file)) {
			    my $include_file_line_num = 0;
			    while (<INCLUDEFILE>) {
				$include_file_line_num++;
				chomp;
				# ignore blank lines and comments
				if (!/^\s*$|^\s*#.*$/) {
				    if (/^([\w\-]+)\s*=\s*\"(\S+)\"(.*$)/) {
					$macro_name = $1;
					$macro_value = $2;
					$macro_options = $3;
					&parse_macro ($macro_name, $macro_value, $macro_options,
						      $current_context, $current_host,
						      $line_num, $include_file_line_num);
				    }
				    else {
					&send_error ($config_file, "Invalid macro definition line in macro include file \"$macro_file\" line $include_file_line_num, config file line $line_num.\n");
				    }
				}
			    }
			} # open
			else {
			    &send_error ($config_file, "Cannot open macro include file $macro_file in macro \"$macro_name\" on line $line_num. $! $_\n");
			}
		    }
		    else {
			&send_error ($config_file, "Unknown directive on line $line_num. $_");
			exit;
		    }
		}
	    }
	}
	close (CONFIG);
    }
    else {
	die "Cannot open config file $config_file. $!\n";
	&send_error ($config_file, "Cannot open config file. $!");
	exit;
    }

    # If multi-host, did we find our host in the config?
    if ($multihost_config && !$found_my_host) {
	&send_error ($config_file, "Did not find this host ($HOSTNAME) in config file.");
	exit;
    }

    if (!defined ($size_file)) {
	$size_file = "$DEFAULT_SIZE_FILE_DIR/$DEFAULT_SIZE_FILE_NAME";
    }
    elsif (substr ($size_file, length ($size_file) - 5, 5) ne $SIZE_SUFFIX) {
	$size_file .= $SIZE_SUFFIX;
    }

    if (!defined ($master_notify)) {
	if (defined ($all_host_master_notify)) {
	    $master_notify = $all_host_master_notify;
	}
	else {
	    $master_notify = $SECURITY_ADMIN;
	}
    }

    if (!defined ($email_sender)) {
	$email_sender = $EMAIL_SENDER;
    }

    foreach $current_logfile (@logfiles) {
	# These checks need to be changed.
	if (!defined ($match_hash{$current_logfile})) {
	    push (@{$match_hash{$current_logfile}}, 'all');
	}
	$match_hash_ref{$current_logfile} = \@{$match_hash{$current_logfile}};
	if (!defined ($exclude_hash{$current_logfile})) {
	    push (@{$exclude_hash{$current_logfile}}, 'none');
	}
	$exclude_hash_ref{$current_logfile} = \@{$exclude_hash{$current_logfile}};
	if (!defined ($action_hash{$current_logfile})) {
	    push (@{$action_hash{$current_logfile}}, $master_notify);
	    # need indicator for action=notify.
	}
	$action_hash_ref{$current_logfile} = \@{$action_hash{$current_logfile}};
    }

    # If there are linux journal logs, pull validation data.
    if ($linux_journal_unit) {
	@linux_journal_units = &get_linux_journal_units;
    }
    if ($linux_journal_syslogfacility) {
	@linux_journal_syslog_facilities = &get_linux_journal_syslog_facilities;
    }
    if ($linux_journal_syslogid) {
	# don't currently validate.
    }
}

# Minimal validation on email address.  Better to use
# Mail::RFC822::Address's valid.
sub valid_email {
    my ($email) = @_;

    if ($email =~ /.+\@.+\..+/) {
	return 1;
    }

    return 0;
}

# Minimal validation on logfile name. Lots of room for improvement.
# Also not great to be checking the linux journal format in so many
# places.
sub valid_logfile_format {
    my ($logfile) = @_;

    if ($logfile =~ /\.\./) {
	return 0;
    }
    elsif ($logfile =~ /^\/[\w\-\.\/]+$/) {
	return 1;
    }
    elsif ($logfile =~ /^journal (unit|syslog-id|syslog-facility) ([\w\-\.]+)$/) {
	return 1;
    }

    return 0;
}

# Subroutine to get linux journal units. Only loaded active and with
# names ending in ".service".
# Doesn't require privileges.
sub get_linux_journal_units {
    my @units;

    if (open (SYSTEMCTL, '-|', $SYSTEMCTL, 'list-units')) {
	while (<SYSTEMCTL>) {
	    chomp;
	    if (/^\s*(.*\.service).*loaded active/) {
		push (@units, $1);
	    }
	}
	close (SYSTEMCTL);
    }
    else {
	&send_error ($config_file, "Cannot pull journal units from $SYSTEMCTL. $!\n");
	exit;
    }
    return (@units);
}

# Subroutine to get available linux journal syslog facilities.
# Doesn't require privileges.
sub get_linux_journal_syslog_facilities {
    my @facilities;

    if (open (JOURNALCTL, '-|', $JOURNALCTL, '--facility=help')) {
	while (<JOURNALCTL>) {
	    chomp;
	    push (@facilities, $_) unless (/Available facilities:/);
	}
	close (JOURNALCTL);
    }
    else {
	&send_error ($config_file, "Cannot pull syslog facilities from $JOURNALCTL. $!\n");
	exit;
    }
    return (@facilities);
}

# Macro parsing moved out to separate subroutine (poorly modularized)
# in order to add include-macro-file/include-macro-signedfile.
# $line_num is config line number.
sub parse_macro {
    my ($macro_name, $macro_value, $macro_options,
	$current_context, $current_host,
	$line_num, $include_file_line_num) = @_;
    my ($macro_file, $macro_dir); # macro value file

    # Combine config line number and macro include file line number in errors
    # if we're processing a macro include file.
    if ($include_file_line_num) {
	$line_num = $include_file_line_num . ' of macro include file on config line ' . $line_num;
    }
    
    # if !defined ($current_host) then we're in global
    # context, otherwise we're in a specific host context.
    # need to convert all this stuff to subroutines.
    if (defined ($global_preproc_macro{$macro_name})) {
	&send_error ($config_file, "Previously defined global preproc macro \"$macro_name\" on line $line_num. $_\n");
	exit;
    }
    if (defined ($preproc_macro{$macro_name})) {
	&send_error ($config_file, "Previously defined host preproc macro \"$macro_name\" on line $line_num. $_\n");
	exit;
    }
    # Allow importation of macro value from a file in same
    # dir as config file. Only expand if either in global
    # context or if in host context for current host.
    if ($macro_value =~ /^<(?:signed)*file:(.*)>$/ &&
	(($current_context == $GLOBAL_CONTEXT) ||
	 ($current_context == $HOST_CONTEXT &&
	  $current_host eq $HOSTNAME))){
	$macro_file = $1;
	$macro_dir = dirname ($config_file);
	if ($macro_file !~  /^[\w\-\.]+$/) {
	    &send_error ($config_file, "Invalid macro value file name \"$macro_file\" in macro \"$macro_name\" on line $line_num. $_\n");
	    exit;
	}
	$macro_file = $macro_dir . '/' . $macro_file;
	if (!-r $macro_file) {
	    &send_error ($config_file, "Cannot read macro value file $macro_file in macro \"$macro_name\" on line $line_num. $_\n");
	    exit;
	}
	if ($macro_value =~ /^signed/) {
	    if (!defined ($signify_pubkey)) {
		&send_error ($config_file, "No signify_pubkey directive has been parsed yet in config file before use of macro value file \"$macro_file\" on line $line_num. $_\n");
		exit;			
	    }
	    if (!&verify_signify_sig ($macro_file)) {
		&send_error ($config_file, "Cannot verify signify signature on signed macro value file \"$macro_file\" on line $line_num. $_\n");
		exit;
	    }
	}
	if (open (VALUEFILE, '<', $macro_file)) {
	    $macro_value = "";
	    while (<VALUEFILE>) {
		chomp;
		# ignore blank lines and comments
		if (!/^\s*$|^\s*#.*$/) {
		    if ($macro_value eq "") {
			$macro_value = $_;
		    }
		    # If multiple lines, concatenate with |.
		    else {
			$macro_value .= '|' . $_;
		    }
		}
	    }
	    close (VALUEFILE);
	}
	else {
	    &send_error ($config_file, "Cannot open macro value file $macro_file in macro \"$macro_name\" on line $line_num. $! $_\n");
	}
    }
    if ($current_context == $GLOBAL_CONTEXT) {
	$global_preproc_macro{$macro_name} = $macro_value;
    }
    else {
	$preproc_macro{$macro_name} = $macro_value;
    }
    if ($macro_options =~ /:(append|substitute)/) {
	if ($1 eq 'append') {
	    if (defined ($global_append_macro{$macro_value})) {
		&send_error ($config_file, "Previously defined append global macro value \"$macro_value\" on line $line_num. $_\n");
		exit;				
	    }
	    if (defined ($append_macro{$macro_value})) {
		&send_error ($config_file, "Previously defined append host macro value \"$macro_value\" on line $line_num. $_\n");
		exit;
	    }
	    if ($current_context == $GLOBAL_CONTEXT) {
		$global_append_macro{$macro_value} = $macro_name;
		$have_global_postproc_macros = 1;
	    }
	    else {
		$append_macro{$macro_value} = $macro_name;
		$have_postproc_macros = 1;
	    }
	}
	else {
	    if (defined ($global_substitute_macro{$macro_value})) {
		&send_error ($config_file, "Previously defined substitute global macro value \"$macro_value\" on line $line_num. $_\n");
		exit;
	    }
	    if (defined ($substitute_macro{$macro_value})) {
		&send_error ($config_file, "Previously defined substitute host macro value \"$macro_value\" on line $line_num. $_\n");
		exit;
	    }
	    if ($current_context == $GLOBAL_CONTEXT) {
		$global_substitute_macro{$macro_value} = $macro_name;
		$have_global_postproc_macros = 1;
	    }
	    else {
		$substitute_macro{$macro_value} = $macro_name;
		$have_postproc_macros = 1;
	    }
	}
    }
    elsif ($macro_options ne '') {
	&send_error ($config_file, "Invalid macro options for macro \"$macro_name\" on line $line_num. $_\n");
	exit;
    }
}

# Verify signify signature on a file. Code originally derived from subroutine
# sigtree_signify_verify in sigtree.pl, now modified to use Signify.pm.
sub verify_signify_sig {
    my ($file) = @_;
    my (@errors);
    my $SKIP_SIGNIFY_CHECK = 0;
    my $SKIP_PRECHECKS = 0;

    # Already checked readability of file itself but Signify.pm will
    # check it again.
    if (Signify::verify ($file, $signify_pubkey)) {
	return 1;
    }

    @errors = Signify::signify_error;

    # Report any errors, apart from readability of file itself.
    if ($errors[0] =~ /^no executable/) {
	&send_error ($config_file, "No signify binary on system to verify signify signature.\n");
	return 0;
    }
    elsif ($errors[0] =~ /^no readable signature file/) {
	&send_error ($config_file, "Cannot open signed macro file \"$file\".\n");
	return 0;
    }
    elsif ($errors[0] =~ /^no readable public key/) {
	&send_error ($config_file, "Cannot open signify public key \"$signify_pubkey\" to verify signify signature.\n");
	return 0;
    }
    # shouldn't happen without opportune deletion.
    elsif ($errors[0] =~ /^no readable file/) {
	&send_error ($config_file, "Cannot read file $file to verify signify signature.\n");
	return 0;
    }
    else {
	&send_error ($config_file, "@errors");
	return 0;
    }
}

# Subroutine to return 1 if a host list includes the current host or "all"
# and 0 otherwise.
sub my_host {
    my ($line_num, $host_list) = @_;
    my (@hosts, $host);

    return 1 if ($host_list eq 'all');

    @hosts = split (/\s+/, $host_list);
    if ($config_check) {
	foreach $host (@hosts) {
	    if (!defined ($defined_hosts{$host})) {
		print "New host name in \"hosts:\" directive on line $line_num. $host\n";
		$defined_hosts{$host} = 1;
	    }
	}
    }

    return 1 if (grep (/^$SHORT_HOSTNAME$/, @hosts));
    return 1 if (grep (/^$HOSTNAME$/, @hosts));
    return 0;
}

# Look through a log file for any changed lines; add them to
# the global variable @notify_lines and execute the corresponding action.
#
# If $log_type == $LOG_TYPE_PROCESS_ACCOUNTING, then the display and
# size file reference is different from the name of the file actually
# being checked. (Should this be the same for cyclog/multilog?)
sub check_logfile {
    my ($logfile, $old_size, $old_mtime, $old_checktime, $old_sha256_digest, $match_ref, $exclude_ref, $action_ref, $log_type, $logfile_name) = @_;
    my ($ref_logfile, $size, $mtime, $checktime, $date, $line, $idx,
	@match_hashes, @exclude_hashes, @action_hashes,
	$match, $exclude, $action, $action_value,
	@notify_arrays, @notify_lines);
    my (@session_match_flag, @session_match_array, @session_exclude_array, $session_append_string);
    my $have_matches_flag;
    my $sha256_digest = '';
    my $gzip_temp_log_flag = 0;

    if ($log_type == $LOG_TYPE_PROCESS_ACCOUNTING) {
	$ref_logfile = $PROCESS_ACCOUNTING_LOG;
    }
    elsif ($log_type == $LOG_TYPE_LINUX_JOURNAL) {
	$ref_logfile = $logfile_name;
    }
    elsif (&is_gzip ($logfile)) {
	$gzip_temp_log_flag = 1;
	$ref_logfile = $logfile;
	$logfile = &gunzip_logfile ($ref_logfile, $temp_dir);
    }
    else {
	$ref_logfile = $logfile;
    }

    # Note: this is sometimes operating on a temp file in the case of gzipped
    # rotated logfiles or process accounting logs. So mtime will always
    # be > old_mtime for those
    # files -- but we've already verified that that's the case before
    # we got here so it shouldn't break anything.
    # If an old rotated log is larger than the last log file we looked
    # at, we're still checking the first log line to see if we need
    # to look at the whole log file, but we only compute that when needed.
    ($size, $mtime) = &get_size ($logfile);

    # Determine if we are processing a file we have already seen before,
    # or if it's a new one.
    # Not relevant to process accounting logs.
    if ($log_type == $LOG_TYPE_STANDARD_LOG ||
	$log_type == $LOG_TYPE_CYCLOG_OR_MULTILOG) {
	# If we don't have a first line SHA256 digest for the logfile,
	# get one. (Since it always gets passed in for log rotation and
	# cyclog/multilog processing, it should be non-null unless it's
	# a brand new log.)
	if ($old_sha256_digest eq '') {
	    $sha256_digest = &first_log_line_sha256_digest ($logfile);
	}
	# If it's an existing logfile -- we've received as input a
	# size (old_size > 0), an mtime (old_mtime > 0) and a first
	# line SHA256 digest (old_sha256_digest ne ''), then test to
	# see if we need to reset old_size to 0 and start at the
	# beginning.
	# If file has changed (mtime > old_mtime) and the size is
	# smaller than it was OR the first line SHA256 digest doesn't
	# match, then we start over (set old_size = 0).
	if ((($old_size > 0) &&
	     ($old_mtime > 0) &&
	     ($old_sha256_digest ne '') &&
	     ($mtime > $old_mtime)) &&
	    (($size < $old_size) ||
	     (($sha256_digest = &first_log_line_sha256_digest ($logfile)) ne $old_sha256_digest))) {
	    $old_size = 0;
	}
    }
    else { # process accounting logs, linux journal logs
	# We're always going to check for process accounting logs and
	# cyclogs/multilogs.  Used to say $size = $old_size + 1, but
	# since a change above, $size is size of /var/account/acct,
	# and $old_size = 0. [I don't understand this comment anymore.
	# I've just changed it so cyclogs get the test above.]
	# Process accounting logs always get old_size=0, size=1.
	$size = $old_size + 1;
    }

    # Turn match/exclude/action refs into arrays.
    @match_hashes = @{$match_ref};
    @exclude_hashes = @{$exclude_ref};
    @action_hashes = @{$action_ref};

    # Identify session rules.
    # Session rules collect matches as normal with the normal processing but most will be discarded.
    # The session_exclude_array is used to find the subset of matches that are kept (so it's somewhat misnamed), and by finding
    # strings which are appended to the session_match_array used for that final filtering.
    for ($idx = 0; $idx <= $#match_hashes; $idx++ ) {
	$session_match_flag[$idx] = 0;
	if ($match_hashes[$idx] =~ /^session-with (.*$)/) {
	    $match_hashes[$idx] = $1;
	    $session_match_array[$idx] = ''; # start empty
	    $session_match_flag[$idx] = 1;
	    if ($exclude_hashes[$idx] =~ /^session-without (.*$)/) {
		$session_exclude_array[$idx] = $1;
		$exclude_hashes[$idx] = 'none';
	    }
	    else {
		# This shouldn't happen.
		&send_error ($ref_logfile, "Internal error - found session match hash without corresponding session exclude hash for logfile $ref_logfile. $match_hashes[$idx] / $exclude_hashes[$idx]");
	    }
	}
	elsif ($exclude_hashes[$idx] =~ /^session-without/) {
	    # This also shouldn't happen.
	    &send_error ($ref_logfile, "Internal error - found session exclude hash without corresponding session match hash for logfile $ref_logfile. $match_hashes[$idx] / $exclude_hashes[$idx]");
	}
    }

    # Logfile has grown.
    if ($size > $old_size) {
	if (open (LOG, '<', $logfile)) {
	    seek (LOG, $old_size, 0) if ($old_size > 0);
	    while (<LOG>) {
		chomp;
		# Cycle through match/exclude hashes for each line.
		# Action is performed at end if notify--could be
		#   performed within this loop for other actions
		#   that might be performed on a line at a time.
		for ($idx = 0; $idx <= $#match_hashes; $idx++) {
		    $match = $match_hashes[$idx];
		    $exclude = $exclude_hashes[$idx];
		    $action = $action_hashes[$idx]; # May not be necessary.

		    # Process session matches. If we find a match to the exclude array, the relevant match group is returned so that
		    # it can be added to the $session_match_array which will be used to identify the matches to keep.
		    if ($session_match_flag[$idx]) {
			if ($session_append_string = &match_line ($session_exclude_array[$idx], $_, 1)) {
			    if ($session_match_array[$idx] eq '') {
				$session_match_array[$idx] = $session_append_string;
			    }
			    else {
				$session_match_array[$idx] .= '|' . $session_append_string;
			    }
			}
		    }

		    if ((($match eq 'all') || (&match_line ($match, $_))) &&
			(($exclude eq 'none') || (!&match_line ($exclude, $_)))) {
			if ($log_type == $LOG_TYPE_CYCLOG_OR_MULTILOG) { # cyclog or multilog
			    ($date, $line) = split (/\s+/, $_, 2);
			    if ((substr ($date, 0, 1) eq '@') && (length ($date) == 15)) { # cyclog
				$date = localtime ($date);
				push (@{$notify_arrays[$idx]}, $date . ' ' . $line);
			    }
			    elsif ((substr ($date, 0, 1) eq '@') && (length ($date) == 25) && $date =~ /^\@[\da-f]{24}$/) { # multilog
				if ($TimeTAI64_module) {
# Uncomment if using multilog/cyclog.				    
#				    $date = tai64nlocal ($date);
				}
				$line =~ s/\b([a-f0-9]{8})\b/join(".", unpack("C*", pack("H8", $1)))/eg;
				push (@{$notify_arrays[$idx]}, $date . ' ' . $line);
			    }
			    else { # unknown, leave it alone
				push (@{$notify_arrays[$idx]}, $_);
			    }
			}
			else { # syslog
			    push (@{$notify_arrays[$idx]}, $_);
			}
		    }
		}
	    }
	    close (LOG);

	    # If we were processing a gunzipped temp file, delete it.
	    unlink ($logfile) if ($gzip_temp_log_flag && $logfile =~ /^$temp_dir/);

	    # Perform action on corresponding matches, and reset
	    # @notify_lines for the next match/exclude/action.
	    for ($idx = 0; $idx <= $#action_hashes; $idx++) {
		$have_matches_flag = 0;
		$action = $action_hashes[$idx];
		($action, $action_value) = split (/,/, $action, 2);
		if (exists ($notify_arrays[$idx])) {
		    # Process session matches. Just return the notify_array lines which match the collected session match strings.
		    if ($session_match_flag[$idx]) {
			# Don't grep for a null string and match everything.
			if ($session_match_array[$idx] ne '') {
			    $have_matches_flag = 1;
			    @notify_lines = grep (/$session_match_array[$idx]/, @{$notify_arrays[$idx]});
			}
		    }
		    else { # regular matches
			$have_matches_flag = 1;
			@notify_lines = @{$notify_arrays[$idx]};
		    }
		}
		if ($have_matches_flag) {
		    # Here is where to do post-processing on @notify_lines to
		    # do substitution/appending of macro names on values.
		    if ($have_postproc_macros || $have_global_postproc_macros) {
			@notify_lines = &postproc_macro_substitution (@notify_lines);
		    }
		    if ($action eq 'notify') {
			&send_notify ($SHORT_HOSTNAME, $ref_logfile, $action_value, @notify_lines);
		    }
		    elsif ($action eq 'alert') {
			print "***$SHORT_HOSTNAME $ref_logfile\n";
			foreach $line (@notify_lines) {
			    print "$line\n";
			}
			print "***\n";
		    }
		    elsif ($action eq 'text') {
			# Might want to do separate text per line?
			&send_text ($SHORT_HOSTNAME, $ref_logfile, $action_value, @notify_lines);
		    }
		    elsif ($action eq 'execute') {
			&execute_script ($action_value, $HOSTNAME, $ref_logfile, @notify_lines);
		    }
		}
	    }

	    $checktime = gettimeofday();
	    $sha256_digest = $old_sha256_digest if ($sha256_digest eq '');
	    return ($size, $mtime, $checktime, $sha256_digest);
	}
	else {
	    &send_error ($ref_logfile, "Cannot open logfile $logfile. $!");
	}
    }

    $checktime = gettimeofday();
    $sha256_digest = $old_sha256_digest if ($sha256_digest eq '');
    return ($size, $mtime, $checktime, $sha256_digest);
}

# Is logfile a gzip file? (Named like one, that is. No test for file magic.)
sub is_gzip {
    my ($logfile) = @_;


    return 1 if (substr ($logfile, length ($logfile) - 3, 3) eq '.gz');

    return (0);
}

# Subroutine to unzip zipped logfile into a temp dir.
sub gunzip_logfile {
    my ($logfile, $temp_dir) = @_;
    my ($temp_in_file, $temp_out_file, $temp_logfile);

    $temp_in_file = basename ($logfile);
    $temp_out_file = substr ($temp_in_file, 0, length ($temp_in_file) - 3);
    $temp_logfile = $temp_dir . '/' . $temp_out_file;

    copy ($logfile, "$temp_dir/$temp_in_file");
    gunzip "$temp_dir/$temp_in_file" => $temp_logfile or
	&send_error ($logfile, "gunzip failed: $GunzipError");

    # Remove in file.
    unlink ("$temp_dir/$temp_in_file");

    return ($temp_logfile);
}

# Subroutine to return a SHA256 hash of the first log line (or 0).
# This subroutine may be touching files only accessible by root.
sub first_log_line_sha256_digest {
    my ($logfile) = @_;
    my ($first_line, $sha256_digest);

    if (open (LOG, '<', $logfile)) {
	$first_line = <LOG>;
	close (LOG);
	if (defined ($first_line)) {
	    chomp ($first_line);
	    $sha256_digest = sha256_hex ($first_line);
	    return ($sha256_digest);
	}
    }
    return 0;
}

# THIS IS NO LONGER USED, WILL KEEP AROUND FOR A WHILE IN CASE I
# DECIDE I NEED IT AGAIN. THE WEB_DATE_STRING PARSING IS INCOMPLETE.
# Replaced with SHA256 digest on first line to avoid dealing with
# parsing or timezone issues.
# Subroutine to return the parsed time of the first log line (or 0).
# DATE_STRING = standard syslog format
# DATE_STRING2 = process accounting log format
# RFC3339_date_string = RFC3339, newsyslog log rotation format
sub first_log_line_time {
    my ($logfile) = @_;
    my ($first_line, $log_time, $date);
    my $DATE_STRING = '\w{3}\s{1,2}\d{1,2}\s\d{2}:\d{2}:\d{2}';
    my $DATE_STRING2 = '\w{3}\s\w{3}\s{1,2}\d{1,2}\s\d{2}:\d{2}:\d{2}';
    my $WEB_DATE_STRING = '\[\w{3}\s\w{3}\s\d{1,2}\s\d{2}:\d{2}:\d{2}\.\d{6}\s\d{4}\]';
    my $RFC3339_date_string = '\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{3}Z';
    my $timezone = $TIME_ZONE;
    my $rfc3339_timezone = 'UTC';

    if (open (LOG, '<', $logfile)) {
	$first_line = <LOG>;
	close (LOG);
	if (defined ($first_line)) {
	    chomp ($first_line);
	    if ($first_line =~ /^($DATE_STRING|$DATE_STRING2|$RFC3339_date_string)/) {
		$date = $1;
		$timezone = $rfc3339_timezone if ($date =~ /^$RFC3339_date_string/);
		$log_time = parsedate ($date, PREFER_PAST => 1, ZONE => $timezone);
		return ($log_time);
	    }
	}
    }
    return 0;
}

# Identify any rotated logs which have modification times more recent than
# our last check. Was going to check here if the first one found had a line
# newer than our last check, but I don't want to unzip files twice.
# Was ignoring gzips for a few versions.
# This subroutine may be touching files only accessible by root.
sub identify_rotated_logs {
    my ($logfile, $old_checktime) = @_;
    my ($logdir, $logbase, @files, $file, $size, $mtime);
    my ($rotated_logs_flag, @rotated_logs);
    my $first_log_time;

    $rotated_logs_flag = 0;

    # Get directory and filename of logfile from full path.
    $logdir = dirname ($logfile);
    $logbase = basename ($logfile);

    # Read directory, searching for matching files.
    # Assumes a single-digit number of rotated logs.
    # Added match for gzips; sizes may be less meaningful.
    if (opendir (DIR, $logdir)) {
	@files = grep (/^$logbase\.\d(\.gz){0,1}$/, readdir (DIR));

	# Find files that have been modified since our last check.
	foreach $file (reverse (sort (@files))) {
	    ($size, $mtime) = &get_size ("$logdir/$file");
	    if ($mtime > $old_checktime) { # a rotated log that needs checking
		if (!$rotated_logs_flag) { # first one we find
		    $rotated_logs_flag = 1;
		}
		push (@rotated_logs, "$logdir/$file");
	    }
	}
	
	closedir (DIR); 
    }

    return ($rotated_logs_flag, @rotated_logs);
}

# Subroutine to read process accounting log files directly.
sub openbsd_read_process_acct_log {
    my ($acct_log, $checktime, $temp_dir) = @_;
    my ($found_first_log, $found_first_record, $idx, $start_idx,
	$acct_file, $acct_file_size, $acct_file_mtime,
	$prev_acct_file_size, $old_size,
	$processing_records, $last_acct_file_found);
    my ($command, $utime, $stime, $etime, $io, $btime, $uid, $gid,
	$mem, $tty, $pid, $flags);
    my ($date_time, $user, $cpu, $time, $delta, $duration);
    my ($new_checktime);
    my ($temp_fh);
    my %DEV_NAME = (
	"-1", "__",
	"256","tty",
	"2048","tty00",
	"2049","tty01",
	"2050","tty02",
	"2051","tty03",
	"2052","tty04",
	"2053","tty05",
	"2054","tty06",
	"2055","tty07",
	"2056","tty08",
	"2057","tty09",
	"2058","tty0a",
	"2059","tty0b",
	"3072","ttyC0",
	"3073","ttyC1",
	"3074","ttyC2",
	"3075","ttyC3",
	"3076","ttyC4",
	"3077","ttyC5",
	"3078","ttyC6",
	"3079","ttyC7",
	"3080","ttyC8",
	"3081","ttyC9",
	"3082","ttyCa",
	"3083","ttyCb",
	"3327","ttyCcfg",
	"16896","ttyU0",
	"16897","ttyU1",
	"16898","ttyU2",
	"16899","ttyU3",
	"24064","ttyVI00",
	"24074","ttyVI10",
	"24084","ttyVI20",
	"24094","ttyVI30",
	"24104","ttyVI40",
	"9728","ttyc0",
	"9729","ttyc1",
	"9730","ttyc2",
	"9731","ttyc3",
	"9732","ttyc4",
	"9733","ttyc5",
	"9734","ttyc6",
	"9735","ttyc7",
	"1280","ttyp0",
	"1281","ttyp1",
	"1282","ttyp2",
	"1283","ttyp3",
	"1284","ttyp4",
	"1285","ttyp5",
	"1286","ttyp6",
	"1287","ttyp7",
	"1288","ttyp8",
	"1289","ttyp9",
	"1316","ttypA",
	"1317","ttypB",
	"1318","ttypC",
	"1319","ttypD",
	"1320","ttypE",
	"1321","ttypF",
	"1322","ttypG",
	"1323","ttypH",
	"1324","ttypI",
	"1325","ttypJ",
	"1326","ttypK",
	"1327","ttypL",
	"1328","ttypM",
	"1329","ttypN",
	"1330","ttypO",
	"1331","ttypP",
	"1332","ttypQ",
	"1333","ttypR",
	"1334","ttypS",
	"1335","ttypT",
	"1336","ttypU",
	"1337","ttypV",
	"1338","ttypW",
	"1339","ttypX",
	"1340","ttypY",
	"1341","ttypZ",
	"1290","ttypa",
	"1291","ttypb",
	"1292","ttypc",
	"1293","ttypd",
	"1294","ttype",
	"1295","ttypf",
	"1296","ttypg",
	"1297","ttyph",
	"1298","ttypi",
	"1299","ttypj",
	"1300","ttypk",
	"1301","ttypl",
	"1302","ttypm",
	"1303","ttypn",
	"1304","ttypo",
	"1305","ttypp",
	"1306","ttypq",
	"1307","ttypr",
	"1308","ttyps",
	"1309","ttypt",
	"1310","ttypu",
	"1311","ttypv",
	"1312","ttypw",
	"1313","ttypx",
	"1314","ttypy",
	"1315","ttypz"
	);
	
    $found_first_log = 0;
    $found_first_record = 0;
    $processing_records = 0;
    $last_acct_file_found = -1;

    # If $log_mtime{$acct_log} < $checktime, there's nothing to do, but
    # this should never happen. Let's work backwards checking the older
    # logs to find a start point, then work forward from there.
    # Skip this if checktime = 0;
    if ($checktime) {
	$old_size = $log_size{$acct_log};
	($prev_acct_file_size, $acct_file_mtime) = &get_size ($acct_log);
	for ($idx = 0; $idx <= $MAX_PROCESS_ACCOUNTING_FILE; $idx++) {
	    $acct_file = $acct_log . '.' . $idx;
	    if (-e $acct_file) {
		$last_acct_file_found = $idx;
	    }
	    else {
		last;
	    }
	    ($acct_file_size, $acct_file_mtime) = &get_size ($acct_file);

	    if ($acct_file_mtime < $checktime) {
		$start_idx = $idx - 1;
		$found_first_log = 1;
		last;
	    }
	    $prev_acct_file_size = $acct_file_size;
	}
    }
    # If we didn't find one (or if $checktime=0), then everything is new
    # and we start with the oldest. If the system is new, the oldest
    # process accounting file could be < $MAX_PROCESS_ACCOUNTING_FILE.
    if (!$found_first_log) {
	$start_idx = $last_acct_file_found;
	$found_first_record = 1;
    }

    # So now we start from the oldest with changes, and look for a first
    # record unless we're processing everything.
    for ($idx = $start_idx; $idx >= -1; $idx--) {
	if ($idx == -1) {
	    $acct_file = $acct_log;
	}
	else {
	    $acct_file = $acct_log . '.' . $idx;
	}

	# Open file and look for first record if we need it. Once
	# we have a first record, open temp file and start writing out
	# to it.
	if (open (ACCTLOG, '<', $acct_file)) {
	    $/ = \64; # read 64-byte records
	    # If this is the old file, let's seek to
	    # one record before where we left off.
	    if ($found_first_log && !$found_first_record &&
		$prev_acct_file_size > 640 &&
		$old_size < $prev_acct_file_size &&
		$old_size % 64 == 0) {
		seek (ACCTLOG, $old_size - 64, 0);
		# would like to test if this record is older than
		# checktime, if not, should do binary search or start
		# at beginning (watching for out-of-sequence records by
		# accounting for duration).
	    }

	    while (<ACCTLOG>) {
		($command, $utime, $stime, $etime, $io, $btime, $uid, $gid, $mem, $tty, $pid, $flags) = unpack ("A24 S< S< S< S< Q< L< L< L< l< L< b32", $_);
		if (!$processing_records &&
		    ($btime > $checktime || $btime + (&expand ($etime) / AHZ) > $checktime)) {
		    $found_first_record = 1;
		    $processing_records = 1;

		    # Create temp file (OpenBSD only).
		    if ($^O eq 'openbsd') {
			($temp_fh, $temp_logfile) = mkstemp ("$temp_dir/reportnew.XXXXXXX");
			if (!defined ($temp_logfile)) {
			    &send_error ($temp_logfile, "Could not open temp file $temp_logfile for writing. $!");
			    exit; # or just return?
			}
		    }
		    else { # this shouldn't be reached
			# create and open
			($temp_fh, $temp_logfile) = tempfile ("$temp_dir/reportnew.XXXXXXX");
			if (!defined ($temp_logfile)) {
			    &send_error ($temp_logfile, "Could not open temp file $temp_logfile for writing. $!");
			    exit; # or just return?
			}
		    }
		}
		if ($processing_records) {
		    $date_time = ctime ($btime);
		    # Remove year.
		    $date_time = substr ($date_time, 0, length ($date_time) - 6);
		    # Go from raw device number to name.
		    if (defined ($DEV_NAME{$tty})) {
			$tty = $DEV_NAME{$tty};
		    }
		    else {
			$tty = '??';
		    }
		    # Convert uid to user (or use uid if no user in passwd file).
		    $user = getpwuid($uid) || $uid;
		    # Command + pid.
		    $command = "$command\[$pid\]";
		    # Process flags.
		    $flags = &flagbits ($flags);
		    # User time plus system time.
		    $cpu = (&expand ($utime) + &expand ($stime)) / AHZ;
		    $cpu = sprintf "%.2f", $cpu; # was %6.2f for formatted cols
		    $delta = &expand ($etime) / AHZ;
		    $duration = sprintf "%1.0f:%02.0f:%05.2f", $delta / SECSPERHOUR,
			fmod ($delta, SECSPERHOUR) / SECSPERMIN,
			fmod ($delta, SECSPERMIN);
		    print $temp_fh "$date_time $tty $user $command $flags $cpu secs $duration\n";
		}
	    }
	}
	else {
	    &send_error ($acct_file, "Could not open acct file $acct_file. $!");
	    exit;
	}
	$new_checktime = gettimeofday();
	close (ACCTLOG);
	$/ = $NL;
    }

    if (!$found_first_record || !$processing_records) {
	# This should provoke an error and exit, we never wrote anything
	# out. This can happen if process accounting is turned off.
	&send_error ($acct_file, "Could not find any new records in acct file $acct_file (OpenBSD method). This shouldn't happen--is process accounting on?");
	exit;
    }
    # Otherwise, close the temp file and return log path.
    close ($temp_fh);
	
    return ($temp_logfile, $new_checktime);
}

# Subroutine to expand accounting time.
sub expand {
    my ($time) = @_;
    my $newtime;

    $newtime = $time & 017777;
    $time >>= 13;
    while ($time) {
        $time--;
        $newtime <<= 3;
    }
    return ($newtime);
}

# Subroutine to return process flags in human-readable form.
# Might want to re-do this with unpacking flags to hex and
# using bitwise operators. (0x02 was ASU, now removed)
#    vec ($AFORK, 0, 8) = 0x01; # F
#    vec ($AMAP, 0, 8) = 0x04; # M
#    vec ($ACORE, 0, 8) = 0x08; # D
#    vec ($AXSIG, 0, 8) = 0x10; # X
#    vec ($APLEDGE, 0, 8) = 0x20; # P
#    vec ($ATRAP, 0, 8) = 0x40; # T
#    vec ($AUNVEIL, 0, 8) = 0x80; # U
#    vec ($APINSYS, 0, 8) = 0x200; # S
#    vec ($ABTCFI, 0, 8) = 0x400; # B
sub flagbits {
    my ($flag) = @_;
    my ($output, $idx);
    my $flagcodes = 'F-MDXPTU-SB';

    $output = '-';
    for ($idx = 0; $idx <= 32; $idx++) {
	if (substr ($flag, $idx, 1) eq '1') {
	    $output .= substr ($flagcodes, $idx, 1);
	}
    }

    return ($output);
}

# Subroutine to read process accounting log files using lastcomm.
sub read_process_acct_log {
    my ($acct_log, $checktime, $temp_dir) = @_;
    my ($idx, $acct_file, @lastcomm_logs, $log_line, $temp_logfile);
    my ($command, $flags, $user, $tty, $time_info,
	$cpu, $secs, $day_name, $month, $day, $time, $duration,
	$time_dec);
    my ($new_checktime);
    my ($temp_fh);
    # last field A30+, no duration
    my $linux_format = 'A16 A7 A9 A9 A*';
    # last field A44+, includes duration
    my $macos_format = 'A11 A8 A9 A9 A*';

# Read process accounting logs, out to end or to $checktime, whichever
# comes first.  Write out to temp file, in reverse order, with more
# standardized date/time stamps.  Return $temp_logfile name.

    # Do lastcomm, starting with the most recent and working backward,
    # reading lines into @lastcomm_logs with parsed date/time, until
    # we reach $checktime or run out of logs.

    # This algorithm doesn't quite work, because lastcomm's times are
    # the time the process started, but the record is written when it
    # ends, so the records can be out of order.
    # This could be fixed by checking that the time of the new log
    # is earlier, even if the duration is added to it (or if the
    # time is earlier by more than the duration).
    for ($idx = -1; $idx <= $MAX_PROCESS_ACCOUNTING_FILE; $idx++) {
	if ($idx >= 0) {
	    $acct_file = $acct_log . '.' . $idx;
	    # OK if these don't exist yet, only abort if the main one doesn't.
	    # Assumes no skipped numbers--we stop at the first nonexistent one.
	    last if (!-e $acct_file);
	}
	else {
	    $acct_file = $acct_log;
	    $new_checktime = gettimeofday();
	}

	if (!open (LASTCOMM, '-|', $LASTCOMM, '-f', $acct_file)) {
	    &send_error ($acct_file, "Could not open acct file $acct_file. $!");
	    exit; # or just return?
	}
	while (<LASTCOMM>) {
	    # Parse line, check time.  If lastcomm time <= $check_time,
	    # then set $idx to $MAX_PROCESS_ACCOUNTING_FILE+1 and exit with next.
	    chomp;

	    # Linux has older format with no duration.
	    if ($^O eq 'linux') {
	       ($command, $flags, $user, $tty, $time_info) = unpack ($linux_format, $_);
	       $flags =~ s/^\s*//;
	       $time_info =~ s/^\s*//;
	       ($cpu, $secs, $day_name, $month, $day, $time) = split (/\s+/, $time_info, 6);
	       $duration = '(0:00:00.00)'; # fake it for the calculation
	    }
	    elsif ($^O eq 'darwin') {
		# macOS can have spaces in command names.
		($command, $flags, $user, $tty, $time_info) = unpack ($macos_format, $_);
		$flags =~ s/^\s*//;
		$time_info =~ s/^\s*//;
		($cpu, $secs, $day_name, $month, $day, $time, $duration) = split (/\s+/, $time_info, 7);
	    }
	    else { # OpenBSD, macOS
    	    	 ($command, $flags, $user, $tty, $time_info) = split (/\s+/, $_, 5);
	    	 ($cpu, $secs, $day_name, $month, $day, $time, $duration) = split (/\s+/, $time_info, 7);
	    }
	    $time = $day_name . ' ' . $month . ' ' . $day . ' ' . $time;
	    $time_dec = parsedate ($time, PREFER_PAST => 1);
	    $duration =~ s/^\((.*)\)$/$1/;

	    # Stop this once we reach an entry earlier than last check.
	    # Correcting for long-duration processes started a long
	    # time ago that are out of sequence.
	    if ($time_dec < $checktime) {
		my ($dur_hours, $dur_mins, $dur_secs) = split (/:/, $duration);
		if ($checktime - $time_dec > ($dur_hours * SECSPERHOUR +
					      $dur_mins * SECSPERMIN +
					      $dur_secs)) {
		    $idx = $MAX_PROCESS_ACCOUNTING_FILE + 1;
		    last;
		}
	    }
	    
	    $log_line = "$time $tty $user $command $flags $cpu $secs";
	    $log_line .= " $duration" unless ($^O eq 'linux');

	    push (@lastcomm_logs, $log_line);
	}
	close (LASTCOMM);
    }

    # Now write out @lastcomm_logs to a temp file in reverse order.

    # Create temp file.
    if ($^O eq 'openbsd') {
	($temp_fh, $temp_logfile) = mkstemp ("$temp_dir/reportnew.XXXXXXX");
	if (!defined ($temp_logfile)) {
	    &send_error ($temp_logfile, "Could not open temp file $temp_logfile for writing. $!");
	    exit; # or just return?
	}
    }
    else {
	# create and open
	($temp_fh, $temp_logfile) = tempfile ("$temp_dir/reportnew.XXXXXXX");
	if (!defined ($temp_logfile)) {
	    &send_error ($temp_logfile, "Could not open temp file $temp_logfile for writing. $!");
	    exit; # or just return?
	}
	chomp ($temp_logfile);
    }

    # Print out each log line to the temp file.
    foreach $log_line (reverse (@lastcomm_logs)) {
	print $temp_fh "$log_line\n";
    }

    # Close temp file.
    close ($temp_fh);

    # Return the filename.
    return ($temp_logfile, $new_checktime);
}

# Read log information from Linux journal into a temp file to process.
# This subroutine trusts the config parser to have validated the
# arguments.
# Requires privileges.
sub read_linux_journal {
    my ($logfile, $checktime, $temp_dir) = @_;
    my ($temp_logfile, $temp_fh, $new_checktime);
    my (@time_components, $time_string, $full_time);
    my @selection_args;
    my $NO_ENTRIES = '-- No entries --';

    # Create temp file.
    # create and open
    ($temp_fh, $temp_logfile) = tempfile ("$temp_dir/reportnew.XXXXXXX");
    if (!defined ($temp_logfile)) {
	&send_error ($temp_logfile, "Could not open temp file $temp_logfile for writing. $!");
	exit; # or just return?
    }
    chomp ($temp_logfile);

    # Convert last checktime to English.
    if ($checktime != 0) {
	@time_components = localtime ($checktime);
	$time_string = strftime "%Y-%m-%d %H:%M:%S", @time_components;
	$full_time = sprintf "%s.%06d", $time_string, $checktime;
    }

    # Formulate selection arguments.
    if ($logfile =~ /journal unit ([\w\-\.]+)$/) {
	my $unit_arg = $1;
	if (!grep (/^$unit_arg$/, @linux_journal_units)) {
	    &send_error ($logfile, "Specified journal unit $unit_arg is not enabled.");
	    exit; # or just return?
	}
	@selection_args = ('-u', $unit_arg);
    }
    elsif ($logfile =~ /journal syslog-id ([\w\-\.]+)$/) {
	my $syslogid_arg = $1;
	# no check today
	@selection_args = ('-t', $syslogid_arg);
    }
    elsif ($logfile =~ /journal syslog-facility ([\w\-\.]+)$/) {
	my $syslog_facility_arg = $1;
	if (!grep (/^$syslog_facility_arg$/, @linux_journal_syslog_facilities)) {
	    &send_error ($logfile, "Specified journal syslog facility $syslog_facility_arg is not defined.");
	    exit; # or just return?    
	}
	@selection_args = ('--facility=' . $syslog_facility_arg);
    }
    else {
	&send_error ($logfile, "Could not parse journal logfile name. $logfile");
	exit; # or just return?
    }
    
    # Append date if checktime nonzero.
    push (@selection_args, '--since', $full_time) unless (!$checktime);

    # Open journalctl to read log lines.
    if (!open (JOURNAL, '-|', $JOURNALCTL, @selection_args)) {
	&send_error ($logfile, "Could not open file handle for $JOURNALCTL. $!");
	exit; # or just return?
    }

    while (<JOURNAL>) {
	print $temp_fh "$_" unless (/^$NO_ENTRIES$/);
    }

    # Set new checktime.
    $new_checktime = gettimeofday();

    # Close journalctl.
    close (JOURNAL);

    # Close temp file.
    close ($temp_fh);
    
    return ($temp_logfile, $new_checktime);
}

# Return 1 if a regexp is valid, 0 if not.
sub valid_regexp {
    my ($regexp) = @_;

    if (($regexp =~ /\/.*\//) ||
	($regexp =~ /!\/.*\//)) {
	return 1;
    }
    else {
	return 0;
    }
}

# Read the contents of the size file.
# If a current_logfile is specified, do not update hashes for that logfile.
sub read_size_file {
    my ($size_file, $current_logfile) = @_;
    my ($logfile, $size, $mtime, $checktime, $sha256_digest, $processing_pid);

    if (!-e $size_file) {
	foreach $logfile (@logfiles) {
	    $log_size{$logfile} = 0;
	    $log_mtime{$logfile} = 0;
	    $log_checktime{$logfile} = 0;
	    $log_sha256_digest{$logfile} = '';
	    $log_processing_pid{$logfile} = 0;
	}
	$processing_pid = 0;
    }
    else {
	if (open (SIZEFILE, '<', $size_file)) {
	    if (!flock (SIZEFILE, LOCK_SH)) {
		&send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot lock size file for reading. $!");
	    }
	    while (<SIZEFILE>) {
		chomp;
		($logfile, $size, $mtime, $checktime, $sha256_digest, $processing_pid) = split (/,/);
		if (!defined ($processing_pid)) { # bad line in size file
		    &send_notify ($SHORT_HOSTNAME, $config_file, $master_notify, "Malformed line in size file. $_\n");
		}
		if (!grep ($_ eq $logfile, @logfiles)) {
		    &send_notify ($SHORT_HOSTNAME, $config_file, $master_notify, "Logfile $logfile in size file is not in config file.");
		}
		if (!defined ($current_logfile) || $current_logfile ne $logfile) {
		    $log_size{$logfile} = $size;
		    $log_mtime{$logfile} = $mtime;
		    $log_checktime{$logfile} = $checktime;
		    if (!defined ($sha256_digest)) { # old size file
			$sha256_digest = '';
		    }
		    elsif ($sha256_digest eq 'null') { # how we store null ones
			$sha256_digest = '';
		    }
		    $log_sha256_digest{$logfile} = $sha256_digest;
		    if (!defined ($processing_pid)) { # old size file
			$processing_pid = 0;
		    }
		    $log_processing_pid{$logfile} = $processing_pid;
		}
	    }
	    if (!flock (SIZEFILE, LOCK_UN)) {
		&send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot unlock size file after reading. $!");
	    }
	    close (SIZEFILE);
	}
	else {
	    &send_error ($size_file, "Cannot open size file. $!");
	    exit;
	}

	if (!defined ($current_logfile)) {
	    foreach $logfile (@logfiles) {
		if (!defined ($log_size{$logfile})) {
		    &send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Logfile $logfile in config file is not in size file.");
		    $log_size{$logfile} = 0;
		    $log_mtime{$logfile} = 0;
		    $log_checktime{$logfile} = 0;
		    $log_sha256_digest{$logfile} = '';
		    $log_processing_pid{$logfile} = 0;
		    &write_size_file ($size_file, $logfile, $LOG_APPEND);
		}
	    }
	}
    }
}

# Get current log file size and mtime.
sub get_size {
    my ($logfile) = @_;
    my ($dev, $ino, $mode, $nlink, $uid, $gid, $rdev, $size, $atime,
	$mtime, $ctime, $blksize, $blocks);

    ($dev, $ino, $mode, $nlink, $uid, $gid, $rdev, $size, $atime,
     $mtime, $ctime, $blksize, $blocks) = stat $logfile;

    $size = 0 if (!defined ($size));
    $mtime = 0 if (!defined ($mtime));

    return ($size, $mtime);
}

# Return 1 if line matches regexp, 0 if not.
# If $return_group is specified, on match the first capture group is returned.
sub match_line {
    my ($regexp, $line, $return_group) = @_;
    my ($negative);

    if (!defined ($return_group)) {
	$return_group = 0;
    }

    if (substr ($regexp, 0, 1) eq '!') {
	$negative = 1;
	$regexp =~ s/^!//;
    }
    else {
	$negative = 0;
    }

    $regexp =~ s/^\///;
    $regexp =~ s/\/$//;

    if (($negative && ($line =~ !/$regexp/)) ||
	(!$negative && ($line =~ /$regexp/))) {
	return $1 if $return_group;
	return 1;
    }
    else {
	return 0;
    }
}

# Execute a script as nonprivileged user.
sub execute_script {

# Should verify the existence of script, permissions, and what else?

    if (fork) {
	wait;
	return $? >> 8;
    }

    # -- child
    # Drop privileges.
# Not yet ready...
#    drop_privileges('nobody'); # better, use _reportnew.
#    exec @_;
}

# Send a mail notification.
sub send_notify {
    my ($hostname, $logfile, $notify_list, @lines) = @_;
    my ($line);

    if (!defined ($notify_list)) {
	if (!defined ($master_notify)) {
	    # This seems to happen periodically, indicating a bug
	    # in the config parsing.
	    $notify_list = $SECURITY_ADMIN;
	}
	else {
	    $notify_list = $master_notify;
	}
    }

    # It is possible to get here before $email_sender is defined if
    # an error occurs while still parsing the config.
    $email_sender = $EMAIL_SENDER if (!defined ($email_sender));

    if ($debug_mode) {
	print "$hostname: $logfile ($notify_list)\n";
	foreach $line (@lines) {
	    print "$line\n";
	}
    }

    else {
	open (MAIL, '|-', $SENDMAIL, '-t');
	print MAIL "From: Reporter <$email_sender>\n";
	print MAIL "To: $notify_list\n";
	print MAIL "Subject: $hostname $logfile\n\n";
	foreach $line (@lines) {
	    print MAIL "$line\n";
	}
	close (MAIL);
    }
}

# Send a text message. This code could easily be merged with
# send_notify, it is identical except for the mail format.
sub send_text {
    my ($hostname, $logfile, $notify_list, @lines) = @_;
    my ($line);

    if (!defined ($notify_list)) {
	if (!defined ($master_notify)) {
	    # This seems to happen periodically, indicating a bug
	    # in the config parsing.
	    $notify_list = $SECURITY_ADMIN;
	}
	else {
	    $notify_list = $master_notify;
	}
    }

    if ($debug_mode) {
	print "$hostname: $logfile ($notify_list)\n";
	foreach $line (@lines) {
	    print "$line\n";
	}
    }

    else {
	open (MAIL, '|-', $SENDMAIL, '-t');
	print MAIL "To: $notify_list\n\n";
	foreach $line (@lines) {
	    print MAIL "$line\n";
	}
	close (MAIL);
    }
}

# Send error notification.
sub send_error {
    my ($filename, $error) = @_;

    if (defined ($master_notify)) {
	&send_notify ($SHORT_HOSTNAME, $filename, $master_notify, $error);
    }
    else {
	&send_notify ($SHORT_HOSTNAME, $filename, $SECURITY_ADMIN, $error);
    }
}

# Write out size file.
# This is always called immediately after a read_size_file, though one
# which might skip the current logfile.
# If current_logfile is not specified or the size file doesn't exist
# or can't be opened for reading but can be opened for writing and locked,
# we write out everything.
# If it's a new logfile that isn't in the size file, we just append it
# to the end.
# Otherwise, we read everything in and overwrite with the just-read data
# except for the log file we're updating.
sub write_size_file {
    my ($size_file, $current_logfile, $start_or_end) = @_;
    my ($logfile, $sha256_digest, $my_pid);
    my ($write_all_logfiles,
	$lock_timeout_limit, @size_file_lines, $size_file_line);

    # If we're just adding a new logfile to the end of the size file,
    # do that.
    if (defined ($current_logfile) && $start_or_end == $LOG_APPEND) {
	if (!open (SIZEFILE, '>>', $size_file)) {
	    &send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot open size file for appending. $!");
	    exit;
	}
	$lock_timeout_limit = time() + $SIZE_FILE_LOCK_TIMEOUT_LIMIT;
	until (flock (SIZEFILE, LOCK_EX | LOCK_NB)) {
	    if (time() > $lock_timeout_limit) {
		&send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot lock size file for writing. $!");
		exit;
	    }
	    sleep 1;
	}
	print SIZEFILE "$current_logfile,$log_size{$current_logfile},$log_mtime{$current_logfile},$log_checktime{$current_logfile},null,0\n";
	if (!flock (SIZEFILE, LOCK_UN)) {
	    &send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot unlock size file after appending. $!");
	    exit;
	}
	close (SIZEFILE);
	return;
    }

    # If we're just changing a single logfile, read in the current
    # size file without parsing (but we do lock).
    if (defined ($current_logfile) && (-e $size_file)) {
	$write_all_logfiles = 0;
	if (open (SIZEFILE, '<', $size_file)) {
	    if (flock (SIZEFILE, LOCK_SH)) {
		@size_file_lines = <SIZEFILE>;
	    }
	    else {
		&send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot lock size file for reading. $!");
		exit;
	    }
	}
	else {
	    &send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot open size file for reading. $!");
	    exit;
	}
	if (!flock (SIZEFILE, LOCK_UN)) {
	    &send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot unlock size file after reading. $!");
	    exit;
	}
	close (SIZEFILE);
    }
    else {
	$write_all_logfiles = 1;
    }

    # Now, we write everything out, either with what we have or with what
    # was just read from the size file except for our current logfile.
    if (!open (SIZEFILE, '>', $size_file)) {
	&send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot open size file for writing. $!");
	exit;
    }

    $lock_timeout_limit = time() + $SIZE_FILE_LOCK_TIMEOUT_LIMIT;
    until (flock (SIZEFILE, LOCK_EX | LOCK_NB)) {
	if (time() > $lock_timeout_limit) {
	    &send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot lock size file for writing. $!");
	    exit;
	}
	sleep 1;
    }

    # If we're writing out all log files, do that.
    if ($write_all_logfiles) {
	foreach $logfile (@logfiles) {
	    # Write out 'null' if blank. Should only be for process accounting logs.
	    if (!defined ($log_sha256_digest{$logfile})) {
		$sha256_digest = 'null';
	    }
	    else {
		$sha256_digest = $log_sha256_digest{$logfile};
		$sha256_digest = 'null' if ($sha256_digest eq '');
	    }

	    # Write it all out.
	    if ($logfile eq $current_logfile && $start_or_end == $LOG_PROCESSING_START) {
		$my_pid = $$;
	    }
	    else {
		$my_pid = 0;
	    }
	    print SIZEFILE "$logfile,$log_size{$logfile},$log_mtime{$logfile},$log_checktime{$logfile},$sha256_digest,$my_pid\n";
	}
    }
    else { # just changing current log info
	foreach $size_file_line (@size_file_lines) {
	    chomp ($size_file_line);
	    ($logfile) = split (/,/, $size_file_line);
	    if ($logfile eq $current_logfile) {
		# Write out 'null' if blank. Should only be for process accounting logs.
		if (!defined ($log_sha256_digest{$logfile})) {
		    $sha256_digest = 'null';
		}
		else {
		    $sha256_digest = $log_sha256_digest{$logfile};
		    $sha256_digest = 'null' if ($sha256_digest eq '');
		}

		# Write it all out.
		if ($logfile eq $current_logfile && $start_or_end == $LOG_PROCESSING_START) {
		    $my_pid = $$;
		}
		else {
		    $my_pid = 0;
		}
		print SIZEFILE "$logfile,$log_size{$logfile},$log_mtime{$logfile},$log_checktime{$logfile},$sha256_digest,$my_pid\n";
	    }
	    else {
		print SIZEFILE "$size_file_line\n";
	    }
	}
    }

    # Unlock and close size file.
    if (!flock (SIZEFILE, LOCK_UN)) {
	&send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot unlock size file after writing. $!");
	exit;
    }
    close (SIZEFILE);
}

# Subroutine to return 1 if process exists, 0 otherwise.
sub pid_exists {
    my ($pid) = @_;

    if (kill (0, $pid) || $!) {
	return 1 unless $! eq 'No such process';
    }

    return 0;
}
    
# Subroutine to replace macro names with values on preprocessing.
# Process host macros then global macros.
sub preproc_macro_substitution {
    my ($orig_regexp_line, $line_num) = @_;
    my ($more_to_process, $regexp_line, $macro_name, $global_macro);

    $regexp_line = $orig_regexp_line;

    $more_to_process = 1;

    while ($more_to_process) {
	if ($regexp_line =~ /%%([\w\-]+)%%/) {
	    $macro_name = $1;
	    $global_macro = 0;
	    if (!defined ($preproc_macro{$macro_name})) {
		if (defined ($global_preproc_macro{$macro_name})) {
		    $global_macro = 1;
		}
		else {
		    &send_error ($config_file, "Undefined preproc macro %%$macro_name%% on line $line_num. $orig_regexp_line\n");
		    exit;
		}
	    }
	    # Replace all occurrences.
	    if ($global_macro) {
		$regexp_line =~ s/%%$macro_name%%/$global_preproc_macro{$macro_name}/g;	
	    }
	    else {
		$regexp_line =~ s/%%$macro_name%%/$preproc_macro{$macro_name}/g;
	    }
	}
	else {
	    $more_to_process = 0;
	}
    }
    return ($regexp_line);
}

# Subroutine to rewrite output containing macro values by
# appending or substituting macro names. This would work
# better if only executed where we know the macro names were
# present in preprocessing.
# We have to go through all the macros on each line.
# Bad stuff could happen if there are macro values that match
# macro names.
# Process host macros first, then global macros.
sub postproc_macro_substitution {
    my (@output_lines) = @_;
    my ($output_line, $macro_value, $macro_name);

    my $APPEND = 1;
    my $SUBSTITUTE = 0;

    if ($have_postproc_macros) {
	foreach $output_line (@output_lines) {
	    foreach $macro_value (keys (%append_macro)) {
		if ($output_line =~ /$macro_value/) {
		    $output_line = &postproc_match_and_replace ($output_line, $macro_value, $append_macro{$macro_value}, $APPEND);
		}
	    }
	    foreach $macro_value (keys (%substitute_macro)) {
		if ($output_line =~ /$macro_value/) {
		    $output_line = &postproc_match_and_replace ($output_line, $macro_value, $substitute_macro{$macro_value}, $SUBSTITUTE);	    
		}
	    }
	}
    }

    if ($have_global_postproc_macros) {
	foreach $output_line (@output_lines) {
	    foreach $macro_value (keys (%global_append_macro)) {
		if ($output_line =~ /$macro_value/) {
		    $output_line = &postproc_match_and_replace ($output_line, $macro_value, $global_append_macro{$macro_value}, $APPEND);
		}
	    }
	    foreach $macro_value (keys (%global_substitute_macro)) {
		if ($output_line =~ /$macro_value/) {
		    $output_line = &postproc_match_and_replace ($output_line, $macro_value, $global_substitute_macro{$macro_value}, $SUBSTITUTE);	    
		}
	    }
	}
    }
    
    return (@output_lines);
}

# Subroutine to do post-processing macro matching and replacement,
# with special handling for IP addresses.
sub postproc_match_and_replace {
    my ($line, $macro_value, $macro_name, $append) = @_;

    # Special case handling of macro value matches for IP addresses.
    # Only match and replace if the IP address is anchored on the left
    # side by beginning of line, colon, or left bracket and on the right side
    # by end of line, colon, period, or right bracket.
    #
    # Note that this special casing is NOT done on the front end (preproc
    # macros), as we assume the match rule will contain the context for
    # anchoring the match--if we stuck things in it could break a rule
    # and would be very counter-intuitive to the builder of the config.
    my $IPv4_REGEXP = '^\d{1,3}\\\.\d{1,3}\\\.\d{1,3}\\\.\d{1,3}$';
    my $IPv6_REGEXP = '^(((?=(?>.*?::)(?!.*::)))(::)?(([0-9A-F]{1,4})::?){0,5}|((?5):){6})(\2((?5)(::?|$)){0,2}|((25[0-5]|(2[0-4]|1[0-9]|[1-9])?[0-9])(\.|$)){4}|(?5):(?5))(?<![^:]:)(?<!\.)\z';
    my $START_TOKENS = '^|[\s:\[]';
    my $END_TOKENS = '[\s:\.\]]|$';

    # Replace all occurrences that are neither preceded nor followed by
    # numeric including hex digits, using negative lookbehind and negative
    # lookahead. Might be better to do this instead of the start and end
    # tokens, as well.
    if ($macro_value =~ /^$IPv4_REGEXP$|^$IPv6_REGEXP$/i) {
	if ($line =~ /$START_TOKENS$macro_value$END_TOKENS/) {	
	    if ($append) {
		$line =~ s/(?<![\da-f])($macro_value)(?![\da-f])/$1\[$macro_name\]/g;
	    }
	    else {
		$line =~ s/(?<![\da-f])($macro_value)(?![\da-f])/$macro_name/g;		
	    }
	}
    }
    else {
	if ($append) {
	    $line =~ s/($macro_value)/$1\[$macro_name\]/g;
	}
	else {
	    $line =~ s/$macro_value/$macro_name/g;	
	}
    }
    return ($line);
}
