#!/usr/bin/perl
# Originally written 15 February 1999 by Jim Lippard as short hack script.
# Rewritten 25 February 1999 by Jim Lippard to use config file and be
#    a bit fancier.  Early a.m. 26 February: changed some error messages,
#    fixed uninitialized variable problem in read_size_file.
# Modified 11 August 1999 by Jim Lippard to support cyclog-format logs.
#    A cyclog is a directory containing files named with timestamps.
#    For cyclogs, we store the time logs were last examined as well as
#    the size of the last log file examined.  We can only detect a
#    reduction in size (editing) on the last log file examined.
#    cyclog is part of Daniel Bernstein's daemontools package, and may
#    be found at ftp://koobera.math.uic.edu/www/daemontools.html
#    This script now requires Time::HiRes from CPAN.
# Modified 26 August 1999 by Jim Lippard to support multilog-format
#    logs.  This is Bernstein's new replacement for cyclog, the format
#    is very similar.  The only real change is when converting the
#    timestamps.  Also modified to sort files within cyclogs/multilogs.
# Modified 23 December 1999 by Jim Lippard to change name on email to
#    "Reporter" and use hostname minus domain name in subject line.
# Modified 23 April 2002 by Jim Lippard to correctly parse regexps which
#    contain colons.
# Modified 12 February 2003 by Jim Lippard to allow the use of a single
#    reportnew.conf file for multiple hosts in a backwards-compatible
#    way by adding optional begin-host: hostname and end-host: hostname
#    fields.  If master_notify appears outside of any begin-host/end-host
#    blocks, it is the master_notify for all hosts.
# Modified 28 June 2003 by Jim Lippard--there appears to be a bug where
#    sometimes notifications are sent when the value in the notify hash
#    is undefined.  A workaround has been put in place to use the master_notify
#    address when an undefined value is sent to the send_notify sub.
# Modified 12 January 2009 by Jim Lippard to convert djbdns log IP addresses.
# Modified 11 February 2011 by Jim Lippard to change size for warning about
#    logfile turning over.
# Modified 3 December 2011 by Jim Lippard to catch an error condition
#    that leads to an unitialized value for $notify_list in the "To"
#    field generation of send_notify, probably caused by a bug in
#    parse_config that leaves everything undefined (perhaps when a
#    new log is added to the config file, perhaps when it's the first
#    log after a begin-host directive?).
# Modified 25 December 2011 by Jim Lippard to use /etc/reportnew.conf as
#    default config file and put default size file in same dir
#    or get it from the config file. Fixed bug mentioned in previous
#    (used "return" instead of "last" to prematurely exit from
#    parse_config subroutine).
# Modified 30 March 2013, 7-8 June 2013 by Jim Lippard to:
#    - Support multiple match/exclude/action triplets per log.
#    - Replace notify: with action: notify
#    - Add action: alert
# Modified 8 June 2013 by Jim Lippard to
#    - Add action: text
# Modified 4 July 2013 by Jim Lippard to add special casing for process
#    accounting logs.
# Modified 18 September 2013 by Jim Lippard to
#    - Add action: execute (with dropped privileges) [incomplete]
# Modified 25 October 2013 by Jim Lippard to change if (defined (@array))
#    to if (exists (@array)), since perl has deprecated the former and now warns.
# Modified 27 November 2019 by Jim Lippard to split hostname and domain name
#    differently (domain name is no longer hardcoded and hostname is just
#    first component of domain name rather than hostname with hardcoded domain
#    name removed).
# Modified 17 February 2020 by Jim Lippard to make notification email sender
#    configurable.
# Modified 22 February 2020 by Jim Lippard to look at rotated logs if a
#    log rotation has occurred since our last check of a standard logfile.
# Modified 23 February 2020 by Jim Lippard to give &match_line the option
#    to return the first capture group instead of 1 for a match.
# Modified 24 February 2020 by Jim Lippard to fix bug in checking for first
#    line date stamps which was causing repeat log reports.
# Modified 25 February 2020 by Jim Lippard to add session matching functionality.
# Modified 26-27 February 2020 by Jim Lippard to fix bugs in checking
#    date/time in first line of log (timezone, web log format).
# Modified 27 February 2020 by Jim Lippard to use SHA256 digest of first line
#    of log instead of parsing dates.
# Modified 28 February 2020 by Jim Lippard to assume a single digit number
#    of rotated logs in &identify_rotated_logs.
# Modified 2 September 2023 by Jim Lippard to read and write size file
#    before and after each log processed, to set email_sender properly
#    for errors that occur before it is defined, and to track current
#    processing on a log in the size file so that another process doesn't
#    start processing on the same log. Use File::Copy instead of system cp.
# Modified 3 September 2023 by Jim Lippard to fix minor bugs and properly
#    identify gzipped rotated log files.
# Modified 4 September 2023 by Jim Lippard to add new logfiles to size file
#    again, since I broke that.
# Modified 11 November 2023 by Jim Lippard to add macro substitution, both
#    pre-processing (to simplify match/exclude rules) and post-processing
#    (to enrich output by appending macro name or substituting macro name
#    in results). Added global and per-host macros in a single namespace.
# Modified 12 November 2023 by Jim Lippard to add special handling of
#    post-processing macro substitution for IP addresses to avoid appending
#    or substitution in the middle of a larger matching IP address.
# Modified 2 December 2023 by Jim Lippard to use unveil on OpenBSD to restrict
#    file system access to read-only for logs, execute-only for commands, and
#    read/write/create for /tmp.
# Modified 30 December 2023 by Jim Lippard to call pledge correctly.
# Modified 1 January 2024 by Jim Lippard so that first look at process
#    accounting logs in a new year doesn't go to the beginning (call to
#    parsedate was not using PREFER_PAST).
# Modified 1 January 2024 by Jim Lippard to clean up size file code and
#    implement file locking.
# Modified 10 February 2024 by Jim Lippard to allow importing macro values
#    from files.
# Modified 16 March 2024 by Jim Lippard to ignore comment lines in imported
#    files.
# Modified 31 March 2024 by Jim Lippard to properly complain about garbled
#    lines in size file.
# Modified 8 April 2024 by Jim Lippard to fix uninitialized $processing_pid
#    bug when size file is first created, make alert action use line breaks.
# Modified 14 April 2024 by Jim Lippard to handle process accounting logs
#    directly on OpenBSD for greater efficiency.
# Modified 17 April 2024 by Jim Lippard to set last log checktime more
#    appropriately for process accounting logs (to match end of most recent
#    log processing for OpenBSD, and start of most recent log procesing for
#    the old lastcomm/reverse order processing).
# Modified 22 April 2024 by Jim Lippard to remove 'ps' pledge by using
#    kill to verify existence of running processes instead of calling ps.
# Modified 23 April 2024 by Jim Lippard to use IO::Uncompress::Gunzip
#    instead of calling gunzip command, Sys::Hostname instead of hostname
#    command. Use OpenBSD::MkTemp on OpenBSD. Still need exec for sendmail,
#    tai64nlocal/echo (could use Time::TAI64 and Mail::Send; latter requires
#    escaping leading dots on message body lines).
# Modified 5 July 2024 by Jim Lippard to allow signedfile include macros
#    and add signify_publickey global directive.
# Modified 28 July 2024 by Jim Lippard to use Signify.pm.
# Modified 16 December 2024 by Jim Lippard for new config file format and
#    to add -c config check option and -d debug option (for existing
#    debug_flag). Remains backward compatible with the begin-host/end-host
#    format.
# Modified 17 December 2024 by Jim Lippard to fix up -c config check and
#    enforce restriction on using hosts and begin-host/end-host in the same
#    config file.
# Modified 22 December 2024 by Jim Lippard to properly handle process
#    accounting logs on a system that hasn't generated all of the rotated
#    logs yet and fail more gracefully if log files are missing.
# Modified 6 May 2025 by Jim Lippard to add include-macro-file and
#    include-macro-signedfile to allow files of full macro definitions
#    in addition to files of macro values. Create size file if it doesn't
#    exist to reduce unveil surface and pledges.
# Modified 8 May 2025 by Jim Lippard to do additional unveiling for signify
#    checking and use full signify public key path.
# Modified 6 July 2025 by Jim Lippard to use uid in process accounting logs
#    if there's no corresponding user in passwd file.
# Modified 13 August 2025 by Jim Lippard to allow whitespace (not just
#    non-whitespace) in macro definitions.
# Modified 14 September 2025 by Jim Lippard to change path of process
#    accounting log and handle lastcomm format for Linux, add -V version.
# Modified 16 September 2025 by Jim Lippard to support pulling logs from
#    Linux journals using journalctl.
# Modified 18 September 2025 by Jim Lippard to adjust $linux_format for
#    pacct for when there are overlength times.
# Modified 21 September 2025 by Jim Lippard to improve error message that
#    comes from OpenBSD process accounting when it gets turned off, clean
#    up some regexes.
# Modified 4 November 2025 by Jim Lippard to use File::Temp instead of
#    calling mktemp, do better validation on TAI64 dates, avoid shell
#    when invoking sendmail, use chomp instead of chop, create temp dir
#    once per execution, set umask so all created files are only readable
#    by root user, remove tai64nlocal command method for TAI64 log files.
# Modified 12 November 2025 by Jim Lippard to use $macos_format instead of
#    split for macOS process accounting logs, since command names can have
#    spaces in them.
# Modified 15 November 2025 by Jim Lippard to rearrange unveil order slightly,
#    fail if can't create temp dir, improve macOS process accounting sample in
#    config file.
# Modified 22 November 2025 by Jim Lippard to change read_size to get_size
#    to avoid possible implication that it's related to reading from the size
#    file. Do minimal validation on email addresses.
#    Fix minor bug in non-OpenBSD process accounting.
# Modified 25 November 2025 by Jim Lippard to open $JOURNALCTL without
#    invoking shell. Fix bug in identify_rotated_logs not matching gzips.
#    Preparation for privilege separation/running all log checks as
#    _reportnew when run as root.
# Modified 26-29 November 2025 by Jim Lippard to implement privilege
#    separation when run as root and _reportnew user and group exist.
#    Also currently requires use of -p option as well. Privilege
#    separation will parse config and (on OpenBSD) do pledge and unveil,
#    then set up a root listener and fork a child that drops privileges
#    and runs as _reportnew:_reportnew, sending requests to the parent
#    when root access is required to open files, get first line file hashes,
#    or perform Linux journalctl commands.
# Modified 30 November 2025 by Jim Lippard to add privsep directive to
#    reportnew.conf, fix bugs in privsep, add _reportnew user to process
#    accounting sample configs.
# Modified 1 December 2025 by Jim Lippard to support Linux process
#    accounting's gzipped rotated logs (and better support other OSs).
# Modified 2 December 2025 by Jim Lippard to add some minor security improvements:
#    die if child dropping privs fails, limit priv request length, explicitly block
#    directory traversal attempts, etc.
#
#
# To Do:
#    - Find way to not miss additional process execution within the same
#      minute of the last check?
#    - Add time range checking option for match and exclude (new directive?)

# Suggested enhancements:
# * Process all rotated logs and original log, as well as all components
#   of cyclogs or multilogs, together and process all notifications for them
#   together at once instead of once per match per file.
# * Allow customization of subject line so that multiple reportnew
#   configs can be used on the same machine/same logs and be distinguishable.
# * Allow to run continuously (like swatch) monitoring logs with
#   select.  That will perhaps be more efficient than starting up
#   a perl process every N minutes, and will catch log changes more
#   rapidly.  It should wait a little bit for additional matching
#   messages, though, so that it doesn't send a separate message for
#   each log line.  (Easiest way might be to make it go into an
#   infinite loop, sleeping every N minutes at the end.  Though
#   it would be more efficient to use select.)

### Required packages.

use strict;
use warnings;
use Digest::SHA qw( sha256_hex );
use Fcntl qw(:DEFAULT :flock);
use File::Basename;
use File::Copy;
use if $^O ne "openbsd", "File::Temp", qw( :mktemp tempfile );
use Getopt::Std;
use IO::Uncompress::Gunzip qw( gunzip $GunzipError);
use POSIX qw( strftime );
use Signify;
use Sys::Hostname;
use Time::HiRes qw( gettimeofday );
use Time::ParseDate;
# required for privilege separation
use base; # required for Privileges::Drop
use English; # required for Privileges::Drop
use IO::Socket::UNIX; # required for socketpair call
#use Socket; # required for socketpair call
# required for multilog format
#use Time::TAI64 qw( :tai64n );
#my $TimeTAI64_module = 1;
my $TimeTAI64_module = 0;

use if $^O eq "openbsd", "OpenBSD::MkTemp", qw( mkdtemp mkstemp );
use if $^O eq "openbsd", "OpenBSD::Unveil";
use if $^O eq "openbsd", "OpenBSD::Pledge";

use POSIX qw( ctime fmod );
use constant AHZ => 64;
use constant SECSPERHOUR => 60 * 60;
use constant SECSPERMIN => 60;

### Constants.

my $HOSTNAME = hostname();
my ($SHORT_HOSTNAME, $DOMAINNAME) = split (/\./, $HOSTNAME, 2);

### Set to your security admin.
my $SECURITY_ADMIN = 'lippard@discord.org';

my $EMAIL_SENDER = 'nobody@' . $DOMAINNAME;

### Set to your log time zone (used only in one subroutine below).
my $TIME_ZONE = 'MST';

# for Linux journal logs.
my $JOURNALCTL = '/usr/bin/journalctl';
my $SYSTEMCTL = '/usr/bin/systemctl';

my $LASTCOMM = '/usr/bin/lastcomm';
my $SENDMAIL = '/usr/sbin/sendmail';
my $SIGNIFY = '/usr/bin/signify';
my $ETC_DIR = '/etc';
my $ZONEINFO_DIR = '/usr/share/zoneinfo';

my $VERSION = 'reportnew 1.26d of 9 December 2025';

my $DEFAULT_CONFIG_DIR = '/etc/reportnew';
my $DEFAULT_CONFIG_NAME = 'reportnew.conf';
my $DEFAULT_SIZE_FILE_DIR = '/etc/reportnew';
my $DEFAULT_SIZE_FILE_NAME = 'reportnew.size';
my $CONFIG_SUFFIX = ".conf";
my $SIZE_SUFFIX = ".size";

my $SIZE_FILE_LOCK_TIMEOUT_LIMIT = 10;

my $SIGNIFY_DIR = '/etc/signify';

my $PROCESS_ACCOUNTING_LOG = '/var/account/acct'; # BSD and macOS location.
$PROCESS_ACCOUNTING_LOG = '/var/log/account/pacct' if ($^O eq 'linux');
my $MAX_PROCESS_ACCOUNTING_FILE = 3;
$MAX_PROCESS_ACCOUNTING_FILE = 9 if ($^O eq 'linux'); # not really a max

my $NL = '
';

my $LOG_TYPE_STANDARD_LOG = 0;
my $LOG_TYPE_CYCLOG_OR_MULTILOG = 1;
my $LOG_TYPE_PROCESS_ACCOUNTING = 2;
my $LOG_TYPE_LINUX_JOURNAL = 3;

my $LOG_PROCESSING_START = 1;
my $LOG_PROCESSING_END = 2;
my $LOG_APPEND = 3;

my $GLOBAL_CONTEXT = 1;
my $HOST_CONTEXT = 2;
my $SKIPPING = 3;
my $LOG_CONTEXT = 3; # not used, uses !defined($current_logfile)

my @INITIAL_PROMISES = ('unveil');
my @NONPRIVSEP_PROMISES = ('rpath', 'wpath', 'cpath', 'tmppath', 'flock', 'exec', 'proc');
my @PRIVSEP_INITIAL_CHILD_PROMISES = ('id', 'prot_exec');
my @PRIVSEP_CHILD_PROMISES = ('recvfd');
my @PRIVSEP_PARENT_PROMISES = ('chown', 'sendfd');

### Variables.

# Filenames.
use vars qw($config_file $size_file $temp_dir);

# Global variables from config file.
use vars qw(
    $master_notify
    $email_sender
    $signify_pubkey
    @logfiles
    %match_hash
    %exclude_hash
    %action_hash
    %match_hash_ref
    %exclude_hash_ref
    %action_hash_ref
    %global_preproc_macro
    $have_global_postproc_macros
    %global_append_macro
    %global_substitute_macro   
    %preproc_macro
    $have_postproc_macros
    %append_macro
    %substitute_macro
    );

# Global variables from size file.
use vars qw(
    %log_size
    %log_mtime
    %log_checktime
    %log_sha256_digest
    %log_processing_pid
    );

# Global variables for linux journal logs.
use vars qw(
    @linux_journal_units
    @linux_journal_syslog_facilities
);

# Other global variables.
use vars qw(
    $debug_mode
    $config_check
    %opts
    %defined_hosts
    %defined_hostlog
    );

# Local variables in main program.
my ($logfile, $size, $mtime, $sha256_digest,  @cyclog_files, $cyclog_file,
    $old_log_checktime, $got_first_cyclog_file, $temp_logfile);
my ($rotated_logs_flag, $processed_rotated_log_flag, @rotated_logs, $rotated_logfile);

# For privilege separation.
my ($user, $reporter_uid, $reporter_gid, $use_privsep,
    $privsep_flag, $priv_flag, $nonpriv_flag,
    $parent_sock, $child_sock);

### Main program.

getopts ('cdpV', \%opts) || die "Usage: reportnew [-c (check)|-d (debug)|-V (version)] [config-file]\n";

$config_check = $opts{'c'};
$debug_mode = $opts{'d'} || $config_check; # config_check implies debug_mode;
$use_privsep = $opts{'p'}; # can override default or "no" in config.
if ($opts{'V'}) {
    die "-V (version) cannot be used with other options.\n" if ($config_check || $debug_mode);
    print "$VERSION\n";
    exit;
}

if ($#ARGV == 0) {
    $config_file = $ARGV[0];
}
elsif ($#ARGV < 0) {
    $config_file = "$DEFAULT_CONFIG_DIR/$DEFAULT_CONFIG_NAME";
}
else {
    die "Usage: reportnew [-c (check)|-d (debug)|-V (version)] [config-file]\n";
}

if (substr ($config_file, length ($config_file) - 5, 5) ne $CONFIG_SUFFIX) {
    $config_file .= $CONFIG_SUFFIX;
}

# Sanitize environment
BEGIN {
    $ENV{PATH} = '/usr/bin:/bin';
    delete @ENV{qw(IFS CDPATH ENV BASH_ENV PERL5LIB LD_PRELOAD LD_LIBRARY_PATH)};
}

# If on OpenBSD, use pledge and unveil. Do as much as possible before
# parsing the config, then finish unveiling after the config is parsed.
if ($^O eq 'openbsd') {
    # Pledge. stdio is already included.
    # @INITIAL_PROMISES: unveil
    # @NONPRIVSEP_PROMISES: rpath, wpath, cpath, tmppath, flock, proc, exec
    #     flock for locking size file
    #     proc for pid testing and exec
    #     exec for sendmail
    # @PRIVSEP_INITIAL_CHILD_PROMISES: id, prot_exec - for dropping privs
    # @PRIVSEP_CHILD_PROMISES: recvfd - for receiving file descriptors
    # @PRIVSEP_PARENT_PROMISES: sendfd - for sending file descriptors
    pledge (@INITIAL_PROMISES, @NONPRIVSEP_PROMISES,
	    @PRIVSEP_PARENT_PROMISES,
	    @PRIVSEP_INITIAL_CHILD_PROMISES,
	    @PRIVSEP_CHILD_PROMISES) || die "Cannot pledge promises. $!\n";
    
    # Needed to parse dates on process accounting logs.
    unveil ($ZONEINFO_DIR, 'r');

    # Need for username resolution on process accounting logs.
    unveil ($ETC_DIR, 'r');

    # Unveil directory where config file is, so that any macros
    # with file import can be processed.
    my $macro_dir = dirname ($config_file);
    unveil ($macro_dir, 'r');

    # Allow writing to and creating files and dirs in /tmp.
    unveil ('/tmp', 'rwc');

    # Allow execution of commands. $LASTCOMM excluded since
    # it's not used on OpenBSD.
    unveil ($SENDMAIL, 'x');
    # Signify for signed include files in macros.
    unveil ($SIGNIFY, 'rx');
    unveil (dirname ($SIGNIFY), 'rx');
    unveil ($SIGNIFY_DIR, 'rx');
    unveil ('/dev/null', 'rw');
}

&parse_config ($config_file);

if ($config_check) {
    print "No issues identified in config file.\n";
    exit;
}

# Determine if we're going to use privilege separation.
# Conditions: If running as root and _reportnew user and group exist.
$user = $ENV{'LOGNAME'} || $ENV{'USER'} || $ENV{'USERNAME'} || 'unknown';
$reporter_uid = getpwnam ('_reportnew');
$reporter_gid = getgrnam ('_reportnew');

# Will quietly not use privsep if not run as root or _reportnew account doesn't exist.
if ($use_privsep && $user eq 'root' &&
    defined ($reporter_uid) &&
    defined ($reporter_gid)) {
    $privsep_flag = 1;
    $priv_flag = 0;
    $nonpriv_flag = 0;

    # Unveil /usr/local/libdata/perl5 if on OpenBSD to allow
    # loading these modules at runtime.
    unveil ('/usr/local/libdata/perl5', 'r') if ($^O eq 'openbsd');
    # Modules required for privilege separation.
    if (!eval { require IO::FDPass; 1 }) {
	die "Could not require IO::FDPass. $@\n";
    }
    if (!eval { require Privileges::Drop; 1 }) {
	die "Could not require Privileges::Drop. $@\n";
    }
}
elsif ($^O eq 'openbsd') { # not using privsep
        pledge (@INITIAL_PROMISES, @NONPRIVSEP_PROMISES) || die "Cannot pledge promises, non-privsep. $!\n";
}

# Unveil log dirs from config and lock.
# If script execution actions are added, will need to unveil here.
if ($^O eq 'openbsd') {
    my (%unveiled_dirs, $logdir, $size_file_dir);

    # Unveil log directories.
    foreach $logfile (@logfiles) {
	next if $logfile =~ /^journal /; # shouldn't happen.
	$logdir = dirname ($logfile);
	if (!defined ($unveiled_dirs{$logdir})) {
	    unveil ($logdir, "r");
	    $unveiled_dirs{$logdir} = 1;
	}
    }

    # Need to unveil containing dir of size file, which can but
    # need not be same as containing dir of config file.
    $size_file_dir = dirname ($size_file);
    unveil ($size_file_dir, 'r');
    
    # Allow reading from and writing to size file.
    # c required for append.
    unveil ($size_file, 'rwc');

    # Don't lock yet.
}

# Need to temporarily unveil containing dir with rwc in order to create
# size file if it doesn't already exist. Go ahead and create it.
if (!-e $size_file) {
    my $size_file_dir = dirname ($size_file);
    unveil ($size_file_dir, 'rwc') if ($^O eq 'openbsd');
    if (open (SIZEFILE, '>', "$size_file_dir/$size_file")) {
	close (SIZEFILE);
    }
    else {
	&send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot create size file. $!");
    }
    # If using privilege separation, give _reportnew:_reportnew ownership.
    chown ($reporter_uid, $reporter_gid, $size_file) if ($privsep_flag);

    # Remove unneeded access from dir.
    unveil ($size_file_dir, 'r') if ($^O eq 'openbsd');
}

# Lock down unveiling. Equivalent to removing pledge for @INITIAL_PROMISES
# (which so far only contains 'unveil').
unveil() if ($^O eq 'openbsd');
    
# Any files we create are rw for root (or running user, non-priv works
# fine for process accounting on non-Linux) only.
umask 0077;

# Create a temp_dir.
$temp_dir = mkdtemp ('/tmp/reportnew.XXXXXXX') || die "Cannot create temp dir. $!\n";
chomp ($temp_dir);

# Privilege separation, if running as root:
# Parent will set up listener to access files requiring root access,
# child will drop privileges and run as _reportnew:_reportnew.
if ($privsep_flag) {
    
    # Create socket for interprocess communications.
    ($parent_sock, $child_sock) = IO::Socket::UNIX->socketpair(AF_UNIX, SOCK_STREAM, PF_UNSPEC)
	or die "socketpair: $!";

    # Fork.
    my $pid = fork();
    die "fork: $!" unless defined $pid;

    # Parent, privileged listener.
    if ($pid != 0) {
	close $child_sock;

	print "DEBUG: child proc=$pid, parent proc=$$\n" if ($debug_mode);
	# Don't need @PRIVSEP_CHILD_PROMISES or @PRIVSEP_INITIAL_CHILD_PROMISES.
	if ($^O eq 'openbsd') {
	    pledge (@NONPRIVSEP_PROMISES, @PRIVSEP_PARENT_PROMISES) || die "Cannot pledge promises. $!\n"
	}

	# This is the privileged process.
	$priv_flag = 1;

	# chown temp_dir to _reportnew so child has access.
	chown ($reporter_uid, $reporter_gid, $temp_dir);

	# Listen for requests that require privileges.
	&priv_listener;

	# Shutdown after EOF.
	exit;
    }

    # Child.
    close $parent_sock;
    # This call will die if it fails.
    print "DEBUG: Privileges::Drop will always fail on macOS with perl 5.34.1 unless patched.\n" if ($debug_mode && $^O eq 'darwin' && $^V eq 'v5.34.1');
    Privileges::Drop::drop_uidgid ($reporter_uid, $reporter_gid);
    print "DEBUG: real uid: $<, eff uid: $>, real gid: $(, eff gid: $)\n" if ($debug_mode);

    $nonpriv_flag = 1;

    # No longer need @PRIVSEP_INITIAL_CHILD_PROMISES.
    if ($^O eq 'openbsd') {
	pledge (@NONPRIVSEP_PROMISES, @PRIVSEP_CHILD_PROMISES) || die "Cannot pledge promises. $!\n";
    }
}

# Modified to read and write size file after each log processed, so that
# if something fails on processing, work already done isn't repeated.

foreach $logfile (@logfiles) {

    # Read all logs from size file, skip this one if it's already
    # being processed, otherwise mark this one as being processed.
    &read_size_file ($size_file);
    next if ($log_processing_pid{$logfile} != 0 && &pid_exists ($log_processing_pid{$logfile}));
    &write_size_file ($size_file, $logfile, $LOG_PROCESSING_START); # save PID

    if ($logfile eq $PROCESS_ACCOUNTING_LOG) {
	# For process accounting logs, we get the log checktime from this
	# read and not at the end of processing the log.
	
	# On OpenBSD, we still create a temp logfile from process
	# accounting logs, but do so directly instead of by calling
	# lastcomm, and we find the starting point more efficiently.
	if ($^O eq 'openbsd') {
	    ($temp_logfile, $log_checktime{$logfile}) = &openbsd_read_process_acct_log ($PROCESS_ACCOUNTING_LOG, $log_checktime{$logfile}, $temp_dir);
	}
	# Otherwise:
	# Read process accounting logs out to the last time seen, or
	# for all of it, and write it out to a tmp file, $temp_logfile,
	# putting it into chronological order instead of reverse.
	else {
	    ($temp_logfile, $log_checktime{$logfile}) = &read_process_acct_log ($PROCESS_ACCOUNTING_LOG, $log_checktime{$logfile}, $temp_dir);
	}
	# Then use check_logfile on the temp file, disregarding the size,
	# which is set to 0, just as for files in cyclogs.
	my $ignore_checktime;
	($log_size{$logfile}, $log_mtime{$logfile}, $ignore_checktime, $log_sha256_digest{$logfile}) =
	    &check_logfile ($temp_logfile, 0, $log_mtime{$logfile},
			    $log_checktime{$logfile}, $log_sha256_digest{$logfile},
			    $match_hash_ref{$logfile},
			    $exclude_hash_ref{$logfile}, $action_hash_ref{$logfile}, $LOG_TYPE_PROCESS_ACCOUNTING);

	# Unlink $temp_logfile.
	unlink ($temp_logfile);
    }
    elsif ($logfile =~ /^journal /) {
	# Similar to process accounting files, we handle Linux journal logs
	# by writing out the relevant information to a temporary log file,
	# and don't care about tracking size. We use the last read time as
	# the start time (with journalctl --since).
	# Options:
	# journal unit <unit>
	#    journalctl -u <unit> --since <last_check_time>
	# journal syslog-id <identifier>
	#    journalctl -t <identifier> --since <last_check_time>
	# journal syslog-facility <facility>
	#    journalctl --facility=<facility> --since <last_check_time>
	($temp_logfile, $log_checktime{$logfile}) = &read_linux_journal ($logfile, $log_checktime{$logfile}, $temp_dir);
	# Then use check_logfile on the temp file, disregarding the size,
	# which is set to 0, just as for files in cyclogs.
	my $ignore_checktime;
	($log_size{$logfile}, $log_mtime{$logfile}, $ignore_checktime, $log_sha256_digest{$logfile}) =
	    &check_logfile ($temp_logfile, 0, $log_mtime{$logfile},
			    $log_checktime{$logfile}, $log_sha256_digest{$logfile},
			    $match_hash_ref{$logfile},
			    $exclude_hash_ref{$logfile}, $action_hash_ref{$logfile}, $LOG_TYPE_LINUX_JOURNAL, $logfile);

	# Unlink $temp_logfile.
	unlink ($temp_logfile);
    }
    elsif (!-d $logfile) { # Standard syslog file.
	# If there are archived rotated logs which have been modified since
	# log_checktime{$logfile}, we should check any contents that postdate
	# that time. The oldest rotated logfile changed after our last
	# checktime will be the last one we looked at OR a more recent one
	# that we have to look at in its entirety (depending on frequency
	# of checks vs log rotation/retention, it might have already been
	# deleted).
	# We check the oldest one modified after our last check, and
	# if its first line is newer than our last check we check the entire
	# thing, otherwise we presume it's the same logfile we last checked
	# and we start where we left off.
	($rotated_logs_flag, @rotated_logs) = &identify_rotated_logs ($logfile, $log_checktime{$logfile});
	# We have rotated logs we need to examine.
	if ($rotated_logs_flag) {
	    $processed_rotated_log_flag = 0;
	    foreach $rotated_logfile (@rotated_logs) {
		# If the oldest logfile is one we've seen part of before,
		# we'll seek to the right position. We verify by checking
		# the SHA256 digest of the first line to see if it matches
		# what was there before. This check also occurs in check_logfile.
		# This will "work" on a gzip but could have high rate of
		# false positives.
		if (!$processed_rotated_log_flag) {
		    # If first line is different from what we last saw,
		    # then start from the beginning.
		    if ($log_sha256_digest{$logfile} eq '' ||
			&first_log_line_sha256_digest ($rotated_logfile) ne
			$log_sha256_digest{$logfile}) {
			$log_size{$logfile} = 0;
		    }
		    # We don't look at return values here.
			&check_logfile ($rotated_logfile, $log_size{$logfile}, $log_mtime{$logfile},
					$log_checktime{$logfile},
					$log_sha256_digest{$logfile},
					$match_hash_ref{$logfile},
					$exclude_hash_ref{$logfile},
					$action_hash_ref{$logfile},
					$LOG_TYPE_STANDARD_LOG);
		    
			$processed_rotated_log_flag = 1;
		}
		else {
		    # Again, not looking at return values.
		    &check_logfile ($rotated_logfile, 0, 0, 0,
				    $log_sha256_digest{$logfile},
				    $match_hash_ref{$logfile},
				    $exclude_hash_ref{$logfile},
				    $action_hash_ref{$logfile},
				    $LOG_TYPE_STANDARD_LOG);
		}

		# Set log_size to 0 for the regular logfile since we need to
		# look at the whole thing, and update first line SHA256.
		$log_size{$logfile} = 0;
		$log_sha256_digest{$logfile} = &first_log_line_sha256_digest ($logfile);
	    } # End processing of rotated logs.
	} # Standard logfile check.
	
	($log_size{$logfile}, $log_mtime{$logfile}, $log_checktime{$logfile}, $log_sha256_digest{$logfile}) =
	    &check_logfile ($logfile, $log_size{$logfile}, $log_mtime{$logfile},
			    $log_checktime{$logfile},
			    $log_sha256_digest{$logfile},
			    $match_hash_ref{$logfile},
			    $exclude_hash_ref{$logfile}, $action_hash_ref{$logfile}, $LOG_TYPE_STANDARD_LOG);
    }
    else { # cyclog or multilog
	@cyclog_files = &get_cyclog_files ($logfile);
	if ($!) {
	    &send_error ($logfile, "Could not open cyclog/multilog $logfile. $!");
	}
	elsif (!@cyclog_files) {
	    &send_error ($logfile, "Empty cyclog/multilog $logfile. $!");
	}
	$got_first_cyclog_file = 0;
	$old_log_checktime = $log_checktime{$logfile};
	foreach $cyclog_file (sort (@cyclog_files)) {
	    next if ($cyclog_file eq 'lock'); # multilog format
	    next if ($cyclog_file eq 'state'); # multilog format
	    $cyclog_file = $logfile . '/' . $cyclog_file;
	    ($size, $mtime) = &get_size ($cyclog_file);
	    next if ($mtime < $old_log_checktime);
	    # If we get here, then we've found the oldest changed file
	    # (since we last checked).
	    $got_first_cyclog_file++;
	    if ($got_first_cyclog_file == 1) {
		($log_size{$logfile}, $log_mtime{$logfile}, $log_checktime{$logfile}, $log_sha256_digest{$logfile}) =
		    &check_logfile ($cyclog_file, $log_size{$logfile}, $log_mtime{$logfile},
				    $old_log_checktime,
				    $log_sha256_digest{$logfile},
				    $match_hash_ref{$logfile},
				    $exclude_hash_ref{$logfile},
				    $action_hash_ref{$logfile},
				    $LOG_TYPE_CYCLOG_OR_MULTILOG);
	    }
	    # For all the new files, we don't care about size or mtime.
	    else {
		($log_size{$logfile}, $log_mtime{$logfile}, $log_checktime{$logfile}) =
		    &check_logfile ($cyclog_file, 0, 0, 0,
				    $log_sha256_digest{$logfile},
				    $match_hash_ref{$logfile},
				    $exclude_hash_ref{$logfile},
				    $action_hash_ref{$logfile},
				    $LOG_TYPE_CYCLOG_OR_MULTILOG);
		# If we're on the last one, set the first line SHA256 digest.
		# (Count is number of last element, not number of elements.)
		# This is never reached if there is only one, but we've
		# already set SHA256 above for the first one (zeroth) as well.
		if ($got_first_cyclog_file > $#cyclog_files) {
		    $log_sha256_digest{$logfile} = &first_log_line_sha256_digest ($cyclog_file);
		}
	    } # foreach
	}
    }

    # Read all other logs from size file, then update this one.
    &read_size_file ($size_file, $logfile);
    &write_size_file ($size_file, $logfile, $LOG_PROCESSING_END);
}

# Remove temp dir.
rmdir ($temp_dir);

### Subroutines.

## Config parsing and related subroutines to validate config elements.

# Subroutine to parse configuration file.
# As written you the global directives at the top in the sample config file
# can be anywhere, it would probably be better to have a global section
# and individual host sections.
sub parse_config {
    my ($config_file) = @_;
    my ($current_context, $directive, $value, $line_num, $current_logfile,
	$specified_host, $current_host, $all_host_master_notify,
	$action, $action_value, $current_match_session_match_flag);
    my ($macro_name, $macro_value, $macro_options, $macro_file, $macro_dir);
    my ($multihost_config, $oldstyle_multihost, $found_my_host);
    my ($linux_journal_unit, $linux_journal_syslogid, $linux_journal_syslogfacility);

    $line_num = 0;
    $specified_host = 0;
    $current_match_session_match_flag = 0;
    $current_context = $GLOBAL_CONTEXT;
    $have_global_postproc_macros = 0;
    $have_postproc_macros = 0;
    $multihost_config = 0;
    $oldstyle_multihost = 0;
    $found_my_host = 0;
    $linux_journal_unit = 0;
    $linux_journal_syslogid = 0;
    $linux_journal_syslogfacility = 0;
    if (open (CONFIG, '<', $config_file)) {
	while (<CONFIG>) {
	    $line_num++;
	    if (!/^\s*#|^\s*$/) {
		chomp;
		# if SKIPPING, don't resume until we see another "hosts:",
		# unless doing a config_check.
		next if ($current_context == $SKIPPING &&
			 !/^\s*hosts:/ &&
			 !$config_check);
		# Macro definitions.
		if (/^([\w\-]+)\s*=\s*\"(.+)\"(.*$)/) {
		    $macro_name = $1;
		    $macro_value = $2;
		    $macro_options = $3;
		    &parse_macro ($macro_name, $macro_value, $macro_options,
				  $current_context, $current_host,
				  $line_num, 0);
		}
		elsif (/^.*:.*$/) {
		    ($directive, $value) = split (/:\s*/, $_, 2);

		    if ($directive eq 'hosts') {
			if ($multihost_config && $oldstyle_multihost) {
			    &send_error ($config_file, "Found \"hosts:\" directive while using old style \"begin-host:\" and \"end-host:\" directives on line $line_num. $value");
			    exit;
			}
			elsif (!$multihost_config) {
			    $multihost_config = 1;
			}
			if (defined ($master_notify) && !defined ($current_host)) {
			    $all_host_master_notify = $master_notify;
			}
			$current_host = $value if ($config_check);
			if (&my_host ($line_num, $value)) {
			    $current_context = $HOST_CONTEXT;
			    $current_host = $HOSTNAME if (!$config_check);
			    $found_my_host = 1;
			}
			else {
			    $current_context = $SKIPPING;
			}
		    }
		    elsif ($directive eq 'begin-host') {
			if ($multihost_config && !$oldstyle_multihost) {
			    &send_error ($config_file, "Found \"begin-host:\" directive while using new style \"hosts:\" directive on line $line_num. $value");
			    exit;
			}
			elsif (!$multihost_config) {
			    $multihost_config = 1;
			    $oldstyle_multihost = 1;
			}
			if (defined ($master_notify) && !defined ($current_host)) {
			    $all_host_master_notify = $master_notify;
			}
			$current_host = $value;
			$current_context = $HOST_CONTEXT;
			if ($config_check && !defined ($defined_hosts{$current_host})) {
			    print "New host name in \"begin-host:\" directive on line $line_num. $current_host\n";
			    $defined_hosts{$current_host} = 1;
			}
		    }
		    elsif ($directive eq 'end-host') {
			if ($multihost_config && !$oldstyle_multihost) {
			    &send_error ($config_file, "Found \"end-host:\" directive while using new style \"hosts:\" directive on line $line_num. $value");
			    exit;
			}
			if ($current_host ne $value) {
			    &send_error ($config_file, "end-host directive does not match begin-host directive (which uses \"$current_host\") on line $line_num. $value\n");
			    exit;
			}
			if ($current_host eq $HOSTNAME || $current_host eq $SHORT_HOSTNAME) {
			    $found_my_host = 1;
			    last unless ($config_check);
			}
			$current_host = "";
			undef $master_notify;
			undef @logfiles;
			undef %match_hash;
			undef %exclude_hash;
			undef %action_hash;
			undef %preproc_macro;
			undef %append_macro;
			undef %substitute_macro;
			$have_postproc_macros = 0;
		    }
		    elsif ($directive eq 'master_notify') {
			if (defined ($master_notify)) {
			    &send_error ($config_file, "Second master_notify directive on line $line_num. $value");
			    exit;
			}
			if (!&valid_email ($value)) {
			    &send_error ($config_file, "Invalid email address in master_notify directive on line $line_num. $value");
			    exit;
			}
			$master_notify = $value;
		    }
		    elsif ($directive eq 'size_file') {
			if (defined ($size_file)) {
			    &send_error ($config_file, "Second size_file directive on line $line_num. $value");
			    exit;
			}
			$size_file = $value;
		    }
		    elsif ($directive eq 'email_sender') {
			if (defined ($email_sender)) {
			    &send_error ($config_file, "Second email_sender directive on line $line_num. $value");
			    exit;
			}
			$email_sender = $value;
		    }
		    elsif ($directive eq 'privsep') {
			# not checking for multiple of these, first yes
			# overrides any subsequent no.
			if ($value eq 'yes') {
			    $use_privsep = 1;
			}
			elsif ($value eq 'no') {
			    $use_privsep = 0 unless (defined ($use_privsep)
						     && $use_privsep == 1);
			}
			else {
			    &send_error ($config_file, "Invalid value for privsep directive on line $line_num, must be \"yes\" or \"no\". $value");
			    exit;
			}
		    }
		    elsif ($directive eq 'signify_pubkey') {
			if (defined ($signify_pubkey)) {
			    &send_error ($config_file, "Second signify_pubkey directive on line $line_num. $value");
			    exit;
			}
			$signify_pubkey = $value;
			if ($signify_pubkey !~  /^[\w\-\.]+$/) {
			    &send_error ($config_file, "Invalid signify_pubkey file name \"$signify_pubkey\" line $line_num. $_\n");
			    exit;
			}
			$signify_pubkey .= '.pub' if (substr ($signify_pubkey, length ($signify_pubkey) - 4, 4)) ne '.pub';
			if (!-e "$SIGNIFY_DIR/$signify_pubkey") {
			    &send_error ($config_file, "Signify public key doesn't exist, \"$signify_pubkey\" on line $line_num. $_\n");
			    exit;
			}
			if (!-r "$SIGNIFY_DIR/$signify_pubkey") {
			    &send_error ($config_file, "Signify public key is not readable, \"$signify_pubkey\" on line $line_num. $_\n");
			    exit;	
			}
			$signify_pubkey = $SIGNIFY_DIR . '/' . $signify_pubkey;
		    }
		    elsif ($directive eq 'log') {
			# No longer check for logfile existence here due to need
			# to unveil first.
			# First, see if we already have this log file.
			if (grep ($_ eq $value, @logfiles)) {
			    if ($config_check && $multihost_config && !$oldstyle_multihost) {
				my (@hosts, $host);
				@hosts = split (/\s+/, $current_host);
				foreach $host (@hosts) {
				    if ($defined_hostlog{"$host:$value"}) {
					&send_error ($config_file, "Previously defined logfile for host $host on line $line_num. $value");
					exit;
				    }
				    $defined_hostlog{"$host:$value"} = 1;
				}
				# don't push to @logfiles, it's already there
				$current_logfile = $value;
				next;
			    }
			    else {
				&send_error ($config_file, "Previously defined logfile on line $line_num. $value");
				exit;
			    }
			}
			# Do minimal validation on log name.
			if (!&valid_logfile_format ($value)) {
			    &send_error ($config_file, "Invalid logfile name on line $line_num. $value");
			    exit;
			}
			if ($value =~ /^journal (unit|syslog-id|syslog-facility)/) {
			    if ($1 eq 'unit') {
				$linux_journal_unit = 1;
			    }
			    elsif ($1 eq 'syslog-id') {
				$linux_journal_syslogid = 1;
			    }
			    else {
				$linux_journal_syslogfacility = 1;
			    }
			}
			push (@logfiles, $value);
			$current_logfile = $value;
		    }
		    elsif ($directive eq 'match') {
			if (!defined ($current_logfile)) {
			    &send_error ($config_file, "No log directive corresponding to match directive on line $line_num. $_");
			    exit;
			}
			if (($value eq 'all') || &valid_regexp ($value) || ($value =~ /^session-with (.*$)/ && &valid_regexp ($1))) {
			    # Do preproc macro substitution.
			    $value = &preproc_macro_substitution ($value, $line_num) if ($value =~ /%%[\w\-]+%%/);
			    push (@{$match_hash{$current_logfile}}, $value);
			    if ($value =~ /^session-with/) {
				$current_match_session_match_flag = 1;
			    }
			    else {
				$current_match_session_match_flag = 0;
			    }
			}
			else {
			    &send_error ($config_file, "Invalid match directive on line $line_num. $_");
			    exit;
			}
		    }
		    elsif ($directive eq 'exclude') {
			if (!defined ($current_logfile)) {
			    &send_error ($config_file, "No log directive corresponding to exclude directive on line $line_num. $_");
			    exit;
			}
			if (($value eq 'none') || &valid_regexp ($value) || ($value =~ /^session-without (.*$)/ && &valid_regexp ($1))) {
			    if ($value =~ /^session-without/ && !$current_match_session_match_flag) {
				&send_error ($config_file, "Exclude directive is a session match but corresponding match directive is not on line $line_num. $_");
				exit;
			    }
			    elsif ($value !~ /^session-without/ && $current_match_session_match_flag) {
				&send_error ($config_file, "Exclude directive is not a session match but corresponding match directive is on line $line_num. $_");
				exit;
			    }
			    # Do preproc macro substitution.
			    $value = &preproc_macro_substitution ($value, $line_num) if ($value =~ /%%[\w\-]+%%/);
			    push (@{$exclude_hash{$current_logfile}}, $value);
			}
			else {
			    &send_error ($config_file, "Invalid exclude directive on line $line_num. $_");
			}
		    }
		    elsif ($directive eq 'action') {
			if (!defined ($current_logfile)) {
			    &send_error ($config_file, "No log directive corresponding to action directive on line $line_num. $_");
			    exit;
			}
			# Parse action (action, whitespace, value).
			if ($value !~ /\s/) {
			    $action = $value;
			    undef $action_value;
			}
			else {
			    ($action, $action_value) = split (/\s+/, $value, 2);
			}
			# action: notify
			if ($action eq 'notify') {
			    if (defined ($action_value)) {
				# Minimal email validation.
				my @check_emails = split (/,\s*/, $action_value);
				foreach my $check_email (@check_emails) {
				    if (!&valid_email ($check_email)) {
					&send_error ($config_file, "Invalid email address(es) following \"notify\" action in action directive on line $line_num. $_");
					exit;
				    }
				}
				push (@{$action_hash{$current_logfile}}, "$action,$action_value");
			    }
			    else {
				&send_error ($config_file, "Missing email address(es) following \"notify\" action in action directive on line $line_num. $_");
				exit;
			    }
			}
			# action: text
			elsif ($action eq 'text') {
			    if (defined ($action_value)) {
				# Should probably validate email format?
				push (@{$action_hash{$current_logfile}}, "$action,$action_value");
			    }
			    else {
				&send_error ($config_file, "Missing email address(es) following \"text\" action in action directive on line $line_num. $_");
				exit;
			    }
			}
			# action: alert
			elsif ($action eq 'alert') {
			    if (defined ($action_value)) {
				&send_error ($config_file, "Extraneous data following \"alert\" action in action directive on line $line_num. $_");
				exit;
			    }
			    push (@{$action_hash{$current_logfile}}, $action);
			}
			# action: execute
			elsif ($action eq 'execute') {
			    if (defined ($action_value)) {
				push (@{$action_hash{$current_logfile}}, "$action,$action_value");
			    }
			    else {
				&send_error ($config_file, "Missing script name following \"execute\" action in action directive on line $line_num. $_");
				exit;
			    }
			}
			# Other actions?
			else {
			    &send_error ($config_file, "Unknown action specified in action directive on line $line_num. $_");
			    exit;
			}
		    }
		    # For backwards compatibility.
		    elsif ($directive eq 'notify') {
			if (!defined ($current_logfile)) {
			    &send_error ($config_file, "No log directive corresponding to notify directive on line $line_num. $_");
			    exit;
			}
			push (@{$action_hash{$current_logfile}}, "$directive,$value");
			# need to specify that action=notify, and add
			# separate code to parse new action: directive.
		    }
		    # For including a file of macro definitions.
		    elsif ($directive eq 'include-macro-file' ||
			   $directive eq 'include-macro-signedfile') {
			$macro_file = $value;
			$macro_dir = dirname ($config_file);
			if ($macro_file !~  /^[\w\-\.]+$/) {
			    &send_error ($config_file, "Invalid macro include file name \"$macro_file\" in macro \"$macro_name\" on line $line_num. $_\n");
			    exit;
			}
			$macro_file = $macro_dir . '/' . $macro_file;
			if (!-r $macro_file) {
			    &send_error ($config_file, "Cannot read macro include file $macro_file in macro \"$macro_name\" on line $line_num. $_\n");
			    exit;
			}
			if ($directive =~ /signed/) {
			    if (!defined ($signify_pubkey)) {
				&send_error ($config_file, "No signify_pubkey directive has been parsed yet in config file before use of macro include file \"$macro_file\" on line $line_num. $_\n");
				exit;
			    }
			    if (!&verify_signify_sig ($macro_file)) {
				&send_error ($config_file, "Cannot verify signify signature on signed macro include file \"$macro_file\" on line $line_num. $_\n");
				exit;
			    }
			}
			if (open (INCLUDEFILE, '<', $macro_file)) {
			    my $include_file_line_num = 0;
			    while (<INCLUDEFILE>) {
				$include_file_line_num++;
				chomp;
				# ignore blank lines and comments
				if (!/^\s*$|^\s*#.*$/) {
				    if (/^([\w\-]+)\s*=\s*\"(\S+)\"(.*$)/) {
					$macro_name = $1;
					$macro_value = $2;
					$macro_options = $3;
					&parse_macro ($macro_name, $macro_value, $macro_options,
						      $current_context, $current_host,
						      $line_num, $include_file_line_num);
				    }
				    else {
					&send_error ($config_file, "Invalid macro definition line in macro include file \"$macro_file\" line $include_file_line_num, config file line $line_num.\n");
				    }
				}
			    }
			} # open
			else {
			    &send_error ($config_file, "Cannot open macro include file $macro_file in macro \"$macro_name\" on line $line_num. $! $_\n");
			}
		    }
		    else {
			&send_error ($config_file, "Unknown directive on line $line_num. $_");
			exit;
		    }
		}
	    }
	}
	close (CONFIG);
    }
    else {
	die "Cannot open config file $config_file. $!\n";
	&send_error ($config_file, "Cannot open config file. $!");
	exit;
    }

    # If multi-host, did we find our host in the config?
    if ($multihost_config && !$found_my_host) {
	&send_error ($config_file, "Did not find this host ($HOSTNAME) in config file.");
	exit;
    }

    if (!defined ($size_file)) {
	$size_file = "$DEFAULT_SIZE_FILE_DIR/$DEFAULT_SIZE_FILE_NAME";
    }
    elsif (substr ($size_file, length ($size_file) - 5, 5) ne $SIZE_SUFFIX) {
	$size_file .= $SIZE_SUFFIX;
    }

    if (!defined ($master_notify)) {
	if (defined ($all_host_master_notify)) {
	    $master_notify = $all_host_master_notify;
	}
	else {
	    $master_notify = $SECURITY_ADMIN;
	}
    }

    if (!defined ($email_sender)) {
	$email_sender = $EMAIL_SENDER;
    }

    foreach $current_logfile (@logfiles) {
	# These checks need to be changed.
	if (!defined ($match_hash{$current_logfile})) {
	    push (@{$match_hash{$current_logfile}}, 'all');
	}
	$match_hash_ref{$current_logfile} = \@{$match_hash{$current_logfile}};
	if (!defined ($exclude_hash{$current_logfile})) {
	    push (@{$exclude_hash{$current_logfile}}, 'none');
	}
	$exclude_hash_ref{$current_logfile} = \@{$exclude_hash{$current_logfile}};
	if (!defined ($action_hash{$current_logfile})) {
	    push (@{$action_hash{$current_logfile}}, $master_notify);
	    # need indicator for action=notify.
	}
	$action_hash_ref{$current_logfile} = \@{$action_hash{$current_logfile}};
    }

    # If there are linux journal logs, pull validation data.
    if ($linux_journal_unit) {
	@linux_journal_units = &get_linux_journal_units;
    }
    if ($linux_journal_syslogfacility) {
	@linux_journal_syslog_facilities = &get_linux_journal_syslog_facilities;
    }
    if ($linux_journal_syslogid) {
	# don't currently validate.
    }
}

# Minimal validation on email address.  Better to use
# Mail::RFC822::Address's valid.
sub valid_email {
    my ($email) = @_;

    if ($email =~ /.+\@.+\..+/) {
	return 1;
    }

    return 0;
}

# Minimal validation on logfile name. Lots of room for improvement.
# Also not great to be checking the linux journal format in so many
# places.
sub valid_logfile_format {
    my ($logfile) = @_;

    if ($logfile =~ /\.\./) {
	return 0;
    }
    elsif ($logfile =~ /^\/[\w\-\.\/]+$/) {
	return 1;
    }
    elsif ($logfile =~ /^journal (unit|syslog-id|syslog-facility) ([\w\-\.]+)$/) {
	return 1;
    }

    return 0;
}


# Subroutine to get linux journal units. Only loaded active and with
# names ending in ".service".
# Doesn't require privileges.
sub get_linux_journal_units {
    my @units;

    if (open (SYSTEMCTL, '-|', $SYSTEMCTL, 'list-units')) {
	while (<SYSTEMCTL>) {
	    chomp;
	    if (/^\s*(.*\.service).*loaded active/) {
		push (@units, $1);
	    }
	}
	close (SYSTEMCTL);
    }
    else {
	&send_error ($config_file, "Cannot pull journal units from $SYSTEMCTL. $!\n");
	exit;
    }
    return (@units);
}

# Subroutine to get available linux journal syslog facilities.
# Doesn't require privileges.
sub get_linux_journal_syslog_facilities {
    my @facilities;

    if (open (JOURNALCTL, '-|', $JOURNALCTL, '--facility=help')) {
	while (<JOURNALCTL>) {
	    chomp;
	    push (@facilities, $_) unless (/Available facilities:/);
	}
	close (JOURNALCTL);
    }
    else {
	&send_error ($config_file, "Cannot pull syslog facilities from $JOURNALCTL. $!\n");
	exit;
    }
    return (@facilities);
}

# Macro parsing moved out to separate subroutine (poorly modularized)
# in order to add include-macro-file/include-macro-signedfile.
# $line_num is config line number.
sub parse_macro {
    my ($macro_name, $macro_value, $macro_options,
	$current_context, $current_host,
	$line_num, $include_file_line_num) = @_;
    my ($macro_file, $macro_dir); # macro value file

    # Combine config line number and macro include file line number in errors
    # if we're processing a macro include file.
    if ($include_file_line_num) {
	$line_num = $include_file_line_num . ' of macro include file on config line ' . $line_num;
    }
    
    # if !defined ($current_host) then we're in global
    # context, otherwise we're in a specific host context.
    # need to convert all this stuff to subroutines.
    if (defined ($global_preproc_macro{$macro_name})) {
	&send_error ($config_file, "Previously defined global preproc macro \"$macro_name\" on line $line_num. $_\n");
	exit;
    }
    if (defined ($preproc_macro{$macro_name})) {
	&send_error ($config_file, "Previously defined host preproc macro \"$macro_name\" on line $line_num. $_\n");
	exit;
    }
    # Allow importation of macro value from a file in same
    # dir as config file. Only expand if either in global
    # context or if in host context for current host.
    if ($macro_value =~ /^<(?:signed)*file:(.*)>$/ &&
	(($current_context == $GLOBAL_CONTEXT) ||
	 ($current_context == $HOST_CONTEXT &&
	  $current_host eq $HOSTNAME))){
	$macro_file = $1;
	$macro_dir = dirname ($config_file);
	if ($macro_file !~  /^[\w\-\.]+$/) {
	    &send_error ($config_file, "Invalid macro value file name \"$macro_file\" in macro \"$macro_name\" on line $line_num. $_\n");
	    exit;
	}
	$macro_file = $macro_dir . '/' . $macro_file;
	if (!-r $macro_file) {
	    &send_error ($config_file, "Cannot read macro value file $macro_file in macro \"$macro_name\" on line $line_num. $_\n");
	    exit;
	}
	if ($macro_value =~ /^signed/) {
	    if (!defined ($signify_pubkey)) {
		&send_error ($config_file, "No signify_pubkey directive has been parsed yet in config file before use of macro value file \"$macro_file\" on line $line_num. $_\n");
		exit;			
	    }
	    if (!&verify_signify_sig ($macro_file)) {
		&send_error ($config_file, "Cannot verify signify signature on signed macro value file \"$macro_file\" on line $line_num. $_\n");
		exit;
	    }
	}
	if (open (VALUEFILE, '<', $macro_file)) {
	    $macro_value = "";
	    while (<VALUEFILE>) {
		chomp;
		# ignore blank lines and comments
		if (!/^\s*$|^\s*#.*$/) {
		    if ($macro_value eq "") {
			$macro_value = $_;
		    }
		    # If multiple lines, concatenate with |.
		    else {
			$macro_value .= '|' . $_;
		    }
		}
	    }
	    close (VALUEFILE);
	}
	else {
	    &send_error ($config_file, "Cannot open macro value file $macro_file in macro \"$macro_name\" on line $line_num. $! $_\n");
	}
    }
    if ($current_context == $GLOBAL_CONTEXT) {
	$global_preproc_macro{$macro_name} = $macro_value;
    }
    else {
	$preproc_macro{$macro_name} = $macro_value;
    }
    if ($macro_options =~ /:(append|substitute)/) {
	if ($1 eq 'append') {
	    if (defined ($global_append_macro{$macro_value})) {
		&send_error ($config_file, "Previously defined append global macro value \"$macro_value\" on line $line_num. $_\n");
		exit;				
	    }
	    if (defined ($append_macro{$macro_value})) {
		&send_error ($config_file, "Previously defined append host macro value \"$macro_value\" on line $line_num. $_\n");
		exit;
	    }
	    if ($current_context == $GLOBAL_CONTEXT) {
		$global_append_macro{$macro_value} = $macro_name;
		$have_global_postproc_macros = 1;
	    }
	    else {
		$append_macro{$macro_value} = $macro_name;
		$have_postproc_macros = 1;
	    }
	}
	else {
	    if (defined ($global_substitute_macro{$macro_value})) {
		&send_error ($config_file, "Previously defined substitute global macro value \"$macro_value\" on line $line_num. $_\n");
		exit;
	    }
	    if (defined ($substitute_macro{$macro_value})) {
		&send_error ($config_file, "Previously defined substitute host macro value \"$macro_value\" on line $line_num. $_\n");
		exit;
	    }
	    if ($current_context == $GLOBAL_CONTEXT) {
		$global_substitute_macro{$macro_value} = $macro_name;
		$have_global_postproc_macros = 1;
	    }
	    else {
		$substitute_macro{$macro_value} = $macro_name;
		$have_postproc_macros = 1;
	    }
	}
    }
    elsif ($macro_options ne '') {
	&send_error ($config_file, "Invalid macro options for macro \"$macro_name\" on line $line_num. $_\n");
	exit;
    }
}

# Verify signify signature on a file. Code originally derived from subroutine
# sigtree_signify_verify in sigtree.pl, now modified to use Signify.pm.
sub verify_signify_sig {
    my ($file) = @_;
    my (@errors);
    my $SKIP_SIGNIFY_CHECK = 0;
    my $SKIP_PRECHECKS = 0;

    # Already checked readability of file itself but Signify.pm will
    # check it again.
    if (Signify::verify ($file, $signify_pubkey)) {
	return 1;
    }

    @errors = Signify::signify_error;

    # Report any errors, apart from readability of file itself.
    if ($errors[0] =~ /^no executable/) {
	&send_error ($config_file, "No signify binary on system to verify signify signature.\n");
	return 0;
    }
    elsif ($errors[0] =~ /^no readable signature file/) {
	&send_error ($config_file, "Cannot open signed macro file \"$file\".\n");
	return 0;
    }
    elsif ($errors[0] =~ /^no readable public key/) {
	&send_error ($config_file, "Cannot open signify public key \"$signify_pubkey\" to verify signify signature.\n");
	return 0;
    }
    # shouldn't happen without opportune deletion.
    elsif ($errors[0] =~ /^no readable file/) {
	&send_error ($config_file, "Cannot read file $file to verify signify signature.\n");
	return 0;
    }
    else {
	&send_error ($config_file, "@errors");
	return 0;
    }
}

# Subroutine to return 1 if a host list includes the current host or "all"
# and 0 otherwise.
sub my_host {
    my ($line_num, $host_list) = @_;
    my (@hosts, $host);

    return 1 if ($host_list eq 'all');

    @hosts = split (/\s+/, $host_list);
    if ($config_check) {
	foreach $host (@hosts) {
	    if (!defined ($defined_hosts{$host})) {
		print "New host name in \"hosts:\" directive on line $line_num. $host\n";
		$defined_hosts{$host} = 1;
	    }
	}
    }

    return 1 if (grep { $_ eq $SHORT_HOSTNAME } @hosts);
    return 1 if (grep { $_ eq $HOSTNAME } @hosts);
    return 0;
}

## Subroutines for privilege separation.

# Subroutine for privileged process to listen for and process requests.
# Request format:
#  get-fd:logname[.N[.gz]] - get file descriptor and return it
#  get-fd-raw:logname[.N[.gz]] - open in raw mode
#  get-hash:logname[.N[.gz] - get SHA256 of first line and return it
#  get-journal:logname:checktime - get Linux journal info and return temp file location and checktime.
#  get-mclog-fd:logname:file - get file descriptor of specific file
#  get-mclog-files:logname - get multilog/cyclog file list
#  gunzip:logname[.N].gz - gunzip file and return temp file location
# Exit when the socket is closed on the other side.
sub priv_listener {
    my ($req, $req_type, $req_rest, $req_logfile,
	$req_canon_logfile, $req_checktime);
    my ($first_line_hash);
    my $RESTRICTED_REQ_LENGTH = 1024;

    print "DEBUG: starting &priv_listener\n" if ($debug_mode);
    while ($req = <$parent_sock>) {
	chomp ($req);
	print "DEBUG: parent received $req\n" if ($debug_mode);
	# Limit request length.
	if (length ($req) > $RESTRICTED_REQ_LENGTH) {
	    warn "Priv request too long.\n";
	    next;
	}
	
	if ($req =~ /(^[\w-]+):(.*)$/) {
	    $req_type = $1;
	    $req_rest = $2;

	    # before using $req_rest
	    if ($req_rest =~ /\.\./ || $req_rest =~ m{/\z/} ) {
		warn "Privileged parent received suspicious request: $req\n"; next;
	    }
	    
	    if ($req_type eq 'get-fd' ||
		$req_type eq 'get-fd-raw' ||
		$req_type eq 'get-hash') {
		$req_logfile = $req_rest;
		$req_canon_logfile = $req_rest;
		if ($req_rest =~ /^(.*)(\.\d)(\.gz){0,1}$/) {
		    $req_canon_logfile = $1;
		}
	    }
	    # These both have canonical logfile name:checktime.
	    elsif ($req_type eq 'get-journal' ||
		$req_type eq 'get-linux-pacct') {
		if ($req_rest =~ /^(.*):([\d\.]+)$/) {
		    $req_canon_logfile = $1;
		    $req_logfile = $1;
		    $req_checktime = $2;
		}
	    }
	    elsif ($req_type eq 'get-mclog-files') {
		$req_logfile = $req_rest;
		$req_canon_logfile = $req_rest;
	    }
	    elsif ($req_type eq 'get-mclog-fd') {
		if ($req_rest =~ /^(.*):(.*)$/) {
		    $req_canon_logfile = $1;
		    $req_logfile = $1 . '/' . $2;
		}
		else {
		    warn "Privileged parent process received invalid get-mclog-fd request: $req\n";
		    exit;
		}
	    }
	    elsif ($req_type eq 'gunzip') {
		$req_logfile = $req_rest;
		if ($req_rest =~ /^(.*)(\.\d\.gz)$/) {
		    $req_canon_logfile = $1;
		}
		else {
		    warn "Privileged parent process received invalid gunzip request: $req\n";
		    next;
		}
	    }
	    else {
		warn "Privileged parent process received invalid logfile request: $req\n";
		next;
	    }
	}
	unless (grep { $_ eq $req_canon_logfile } @logfiles) {
	    warn "Privileged parent process received invalid logfile name: $req\n";
	    next;
	}
	# Open logfile and return file descriptor.
	if ($req_type eq 'get-fd' ||
	    $req_type eq 'get-fd-raw' ||
	    $req_type eq 'get-mclog-fd') {
	    my $open_mode = '<';
	    $open_mode = '<:raw' if ($req_type eq 'get-fd-raw');
	    if (open (my $log_fh, $open_mode, $req_logfile)) {
		print $parent_sock "success\n";
		print "DEBUG: parent sending fd for $req_logfile\n" if ($debug_mode);
		IO::FDPass::send (fileno ($parent_sock), fileno ($log_fh))
		    or warn "IO::FDPass::send failed ($req): $!\n";
		print "DEBUG: parent sent fd for $req_logfile\n" if ($debug_mode);
		close $log_fh; # does this break it?
	    }
	    else {
		printf $parent_sock "%d\n", "$!"; # want numeric
		warn "Failed to open $req_logfile: $!\n";
	    }
	}
	# Get hash of first line and return it.
	elsif ($req_type eq 'get-hash') {
	    $first_line_hash = &first_log_line_sha256_digest ($req_logfile);
	    print $parent_sock "$first_line_hash\n";
	    next;
	}
	# Linux journal file and Linux process accounting.
	# Save to temp file for child process,
	# return filename and checktime.
	elsif ($req_type eq 'get-journal' || $req_type eq 'get-linux-pacct') {
	    my ($temp_logfile, $checktime);
	    ($temp_logfile, $checktime) = &read_linux_journal ($req_logfile, $req_checktime, $temp_dir) if ($req_type eq 'get-journal');
	    ($temp_logfile, $checktime) = &read_process_acct_log ($req_logfile, $req_checktime, $temp_dir) if ($req_type eq 'get-linux-pacct');
	    chown ($reporter_uid, $reporter_gid, $temp_logfile);
	    print $parent_sock "$temp_logfile,$checktime\n";
	    next;
	}
	# Get cyclog/multilog files and return, comma-separated.
	elsif ($req_type eq 'get-mclog-files') {
	    my @cyclog_files = &get_cyclog_files ($req_logfile);
	    if (@cyclog_files) {
		my $first_file = 1;
		foreach my $cyclog_file (@cyclog_files) {
		    print $parent_sock ',' if (!$first_file);
		    $first_file = 0;
		    print $parent_sock "$cyclog_file";
		}
	    }
	    print $parent_sock "\n"; # just a blank line if can't get any
	    next;
	}
	# Gzip. Copy to temp file for child process, return filename.
	elsif ($req_type eq 'gunzip') {
	    (my $temp_logfile) = &gunzip_logfile ($req_logfile, $temp_dir);
	    chown ($reporter_uid, $reporter_gid, $temp_logfile);
	    print $parent_sock "$temp_logfile\n";
	    next;
	}
    }
}

# Subroutine to send a request to the privileged parent process and
# get a response, for all except the file descriptor requests.
sub send_priv_req {
    my ($req) = @_;
    my ($return_result);

    if (!$privsep_flag) {
	die "Call to &send_priv_req when not using privilege separation.\n";
    }
    elsif ($priv_flag) {
	die "Call to &send_priv_req from privileged parent process.\n";
    }

    print "DEBUG: child sending $req\n" if ($debug_mode);
    print $child_sock "$req\n";
    $return_result = <$child_sock>;
    chomp ($return_result) if (defined ($return_result));
    print "DEBUG: child received $return_result\n" if ($debug_mode && defined ($return_result));
    return ($return_result);
}

# Subroutine as wrapper for file open. Open if readable, send priv request
# if using privilege separation and running unprivileged.
# Tries the open instead of checking -r so that $! gets returned with
# an appropriate error message.
sub nonpriv_open_fh {
    my ($logfile, $cyclog_file_flag, $raw_mode_flag) = @_;
    my ($log_fd, $log_fh, $open_mode, $mclog_dir, $mclogfile, $success_or_failure);

    $open_mode = '<';
    $open_mode = '<:raw' if ($raw_mode_flag);

    print "DEBUG: &nonpriv_open_fh on $logfile\n" if ($debug_mode);

    if (open ($log_fh, $open_mode, $logfile)) {
	return $log_fh;
    }
    elsif ($privsep_flag && $nonpriv_flag) {
	print "DEBUG: child sending priv req for fd for $logfile\n" if ($debug_mode);
	if ($cyclog_file_flag) {
	    $mclog_dir = dirname ($logfile);
	    $mclogfile = basename ($logfile);
	    # raw_mode_flag ignored
	    $success_or_failure = &send_priv_req ("get-mclog-fd:$mclog_dir:$mclogfile");
	}
	elsif ($raw_mode_flag) {
	    $success_or_failure = &send_priv_req ("get-fd-raw:$logfile");
	}
	else {
	    $success_or_failure = &send_priv_req ("get-fd:$logfile");
	}
	chomp ($success_or_failure);
	if ($success_or_failure eq 'success') {
	    print "DEBUG: child received success, now receiving fd for $logfile\n" if ($debug_mode);
	    $log_fd = IO::FDPass::recv (fileno ($child_sock));
	    print "DEBUG: child received fd for $logfile\n" if ($debug_mode);
	    print "DEBUG: child opening fh for $logfile\n" if ($debug_mode);
	    open ($log_fh, "+<&=$log_fd"); # if fails, will return undef and $!
	    return $log_fh;
	}
	else {
	    $! = $success_or_failure;
	}
    }

    return 0;
}

# Subroutine to get cyclog files in dir.
# Could require privileges, but we try once without even with
# privilege separation.
sub get_cyclog_files {
    my ($logfile) = @_;
    my (@cyclog_files, $priv_response);
    
    if (opendir (CYCLOG, $logfile)) {
	@cyclog_files = grep (!/^\./, readdir (CYCLOG));
	closedir (CYCLOG);
    }
    elsif ($privsep_flag && $nonpriv_flag) {
	$priv_response = &send_priv_req ("get-mclogfiles:$logfile");
	if (defined ($priv_response)) {
	    @cyclog_files = split (/,/, $priv_response);
	}
    }

    return (@cyclog_files);
}

## Main log checker.

# Look through a log file for any changed lines; add them to
# the global variable @notify_lines and execute the corresponding action.
#
# If $log_type == $LOG_TYPE_PROCESS_ACCOUNTING, then the display and
# size file reference is different from the name of the file actually
# being checked. (Should this be the same for cyclog/multilog?)
sub check_logfile {
    my ($logfile, $old_size, $old_mtime, $old_checktime, $old_sha256_digest, $match_ref, $exclude_ref, $action_ref, $log_type, $logfile_name) = @_;
    my ($ref_logfile, $size, $mtime, $checktime, $date, $line, $idx,
	@match_hashes, @exclude_hashes, @action_hashes,
	$match, $exclude, $action, $action_value,
	@notify_arrays, @notify_lines);
    my (@session_match_flag, @session_match_array, @session_exclude_array, $session_append_string);
    my $have_matches_flag;
    my $sha256_digest = '';
    my $gzip_temp_log_flag = 0;

    if ($log_type == $LOG_TYPE_PROCESS_ACCOUNTING) {
	$ref_logfile = $PROCESS_ACCOUNTING_LOG;
    }
    elsif ($log_type == $LOG_TYPE_LINUX_JOURNAL) {
	$ref_logfile = $logfile_name;
    }
    elsif (&is_gzip ($logfile)) {
	$gzip_temp_log_flag = 1;
	$ref_logfile = $logfile;
	$logfile = &gunzip_logfile ($ref_logfile, $temp_dir);
    }
    else {
	$ref_logfile = $logfile;
    }

    # Note: this is sometimes operating on a temp file in the case of gzipped
    # rotated logfiles or process accounting logs. So mtime will always
    # be > old_mtime for those
    # files -- but we've already verified that that's the case before
    # we got here so it shouldn't break anything.
    # If an old rotated log is larger than the last log file we looked
    # at, we're still checking the first log line to see if we need
    # to look at the whole log file, but we only compute that when needed.
    ($size, $mtime) = &get_size ($logfile);

    # Determine if we are processing a file we have already seen before,
    # or if it's a new one.
    # Not relevant to process accounting logs.
    if ($log_type == $LOG_TYPE_STANDARD_LOG ||
	$log_type == $LOG_TYPE_CYCLOG_OR_MULTILOG) {
	# If we don't have a first line SHA256 digest for the logfile,
	# get one. (Since it always gets passed in for log rotation and
	# cyclog/multilog processing, it should be non-null unless it's
	# a brand new log.)
	if ($old_sha256_digest eq '') {
	    $sha256_digest = &first_log_line_sha256_digest ($logfile);
	}
	# If it's an existing logfile -- we've received as input a
	# size (old_size > 0), an mtime (old_mtime > 0) and a first
	# line SHA256 digest (old_sha256_digest ne ''), then test to
	# see if we need to reset old_size to 0 and start at the
	# beginning.
	# If file has changed (mtime > old_mtime) and the size is
	# smaller than it was OR the first line SHA256 digest doesn't
	# match, then we start over (set old_size = 0).
	if ((($old_size > 0) &&
	     ($old_mtime > 0) &&
	     ($old_sha256_digest ne '') &&
	     ($mtime > $old_mtime)) &&
	    (($size < $old_size) ||
	     (($sha256_digest = &first_log_line_sha256_digest ($logfile)) ne $old_sha256_digest))) {
	    $old_size = 0;
	}
    }
    else { # process accounting logs, linux journal logs
	# We're always going to check for process accounting logs and
	# cyclogs/multilogs.  Used to say $size = $old_size + 1, but
	# since a change above, $size is size of /var/account/acct,
	# and $old_size = 0. [I don't understand this comment anymore.
	# I've just changed it so cyclogs get the test above.]
	# Process accounting logs always get old_size=0, size=1.
	$size = $old_size + 1;
    }

    # Turn match/exclude/action refs into arrays.
    @match_hashes = @{$match_ref};
    @exclude_hashes = @{$exclude_ref};
    @action_hashes = @{$action_ref};

    # Identify session rules.
    # Session rules collect matches as normal with the normal processing but most will be discarded.
    # The session_exclude_array is used to find the subset of matches that are kept (so it's somewhat misnamed), and by finding
    # strings which are appended to the session_match_array used for that final filtering.
    for ($idx = 0; $idx <= $#match_hashes; $idx++ ) {
	$session_match_flag[$idx] = 0;
	if ($match_hashes[$idx] =~ /^session-with (.*$)/) {
	    $match_hashes[$idx] = $1;
	    $session_match_array[$idx] = ''; # start empty
	    $session_match_flag[$idx] = 1;
	    if ($exclude_hashes[$idx] =~ /^session-without (.*$)/) {
		$session_exclude_array[$idx] = $1;
		$exclude_hashes[$idx] = 'none';
	    }
	    else {
		# This shouldn't happen.
		&send_error ($ref_logfile, "Internal error - found session match hash without corresponding session exclude hash for logfile $ref_logfile. $match_hashes[$idx] / $exclude_hashes[$idx]");
	    }
	}
	elsif ($exclude_hashes[$idx] =~ /^session-without/) {
	    # This also shouldn't happen.
	    &send_error ($ref_logfile, "Internal error - found session exclude hash without corresponding session match hash for logfile $ref_logfile. $match_hashes[$idx] / $exclude_hashes[$idx]");
	}
    }

    # Logfile has grown.
    if ($size > $old_size) {
	if (my $log_fh = &nonpriv_open_fh ($logfile, $log_type == $LOG_TYPE_CYCLOG_OR_MULTILOG)) {
	    seek ($log_fh, $old_size, 0) if ($old_size > 0);
	    while (<$log_fh>) {
		chomp;
		# Cycle through match/exclude hashes for each line.
		# Action is performed at end if notify--could be
		#   performed within this loop for other actions
		#   that might be performed on a line at a time.
		for ($idx = 0; $idx <= $#match_hashes; $idx++) {
		    $match = $match_hashes[$idx];
		    $exclude = $exclude_hashes[$idx];
		    $action = $action_hashes[$idx]; # May not be necessary.

		    # Process session matches. If we find a match to the exclude array, the relevant match group is returned so that
		    # it can be added to the $session_match_array which will be used to identify the matches to keep.
		    if ($session_match_flag[$idx]) {
			if ($session_append_string = &match_line ($session_exclude_array[$idx], $_, 1)) {
			    if ($session_match_array[$idx] eq '') {
				$session_match_array[$idx] = $session_append_string;
			    }
			    else {
				$session_match_array[$idx] .= '|' . $session_append_string;
			    }
			}
		    }

		    if ((($match eq 'all') || (&match_line ($match, $_))) &&
			(($exclude eq 'none') || (!&match_line ($exclude, $_)))) {
			if ($log_type == $LOG_TYPE_CYCLOG_OR_MULTILOG) { # cyclog or multilog
			    ($date, $line) = split (/\s+/, $_, 2);
			    if ((substr ($date, 0, 1) eq '@') && (length ($date) == 15)) { # cyclog
				$date = localtime ($date);
				push (@{$notify_arrays[$idx]}, $date . ' ' . $line);
			    }
			    elsif ((substr ($date, 0, 1) eq '@') && (length ($date) == 25) && $date =~ /^\@[\da-f]{24}$/) { # multilog
				if ($TimeTAI64_module) {
# Uncomment if using multilog/cyclog.				    
#				    $date = tai64nlocal ($date);
				}
				$line =~ s/\b([a-f0-9]{8})\b/join(".", unpack("C*", pack("H8", $1)))/eg;
				push (@{$notify_arrays[$idx]}, $date . ' ' . $line);
			    }
			    else { # unknown, leave it alone
				push (@{$notify_arrays[$idx]}, $_);
			    }
			}
			else { # syslog
			    push (@{$notify_arrays[$idx]}, $_);
			}
		    }
		}
	    }
	    close ($log_fh);

	    # If we were processing a gunzipped temp file, delete it.
	    unlink ($logfile) if ($gzip_temp_log_flag && $logfile =~ /^$temp_dir/);

	    # Perform action on corresponding matches, and reset
	    # @notify_lines for the next match/exclude/action.
	    for ($idx = 0; $idx <= $#action_hashes; $idx++) {
		$have_matches_flag = 0;
		$action = $action_hashes[$idx];
		($action, $action_value) = split (/,/, $action, 2);
		if (exists ($notify_arrays[$idx])) {
		    # Process session matches. Just return the notify_array lines which match the collected session match strings.
		    if ($session_match_flag[$idx]) {
			# Don't grep for a null string and match everything.
			if ($session_match_array[$idx] ne '') {
			    $have_matches_flag = 1;
			    @notify_lines = grep (/$session_match_array[$idx]/, @{$notify_arrays[$idx]});
			}
		    }
		    else { # regular matches
			$have_matches_flag = 1;
			@notify_lines = @{$notify_arrays[$idx]};
		    }
		}
		if ($have_matches_flag) {
		    # Here is where to do post-processing on @notify_lines to
		    # do substitution/appending of macro names on values.
		    if ($have_postproc_macros || $have_global_postproc_macros) {
			@notify_lines = &postproc_macro_substitution (@notify_lines);
		    }
		    if ($action eq 'notify') {
			&send_notify ($SHORT_HOSTNAME, $ref_logfile, $action_value, @notify_lines);
		    }
		    elsif ($action eq 'alert') {
			print "***$SHORT_HOSTNAME $ref_logfile\n";
			foreach $line (@notify_lines) {
			    print "$line\n";
			}
			print "***\n";
		    }
		    elsif ($action eq 'text') {
			# Might want to do separate text per line?
			&send_text ($SHORT_HOSTNAME, $ref_logfile, $action_value, @notify_lines);
		    }
		    elsif ($action eq 'execute') {
			&execute_script ($action_value, $HOSTNAME, $ref_logfile, @notify_lines);
		    }
		}
	    }

	    $checktime = gettimeofday();
	    $sha256_digest = $old_sha256_digest if ($sha256_digest eq '');
	    return ($size, $mtime, $checktime, $sha256_digest);
	}
	else {
	    &send_error ($ref_logfile, "Cannot open logfile $logfile. $!");
	}
    }

    $checktime = gettimeofday();
    $sha256_digest = $old_sha256_digest if ($sha256_digest eq '');
    return ($size, $mtime, $checktime, $sha256_digest);
}

# Is logfile a gzip file? Name and, if possible, magic number test.
sub is_gzip {
    my ($logfile) = @_;
    my ($gzip_fh, $magic_bytes, $magic_number);
    my $cyclog_flag = 0;
    my $raw_mode_flag = 1;

    if (substr ($logfile, length ($logfile) -3, 3) eq '.gz') {
	return 1 if (!-r $logfile); # assume it is
	if ($gzip_fh = &nonpriv_open_fh ($logfile, $cyclog_flag, $raw_mode_flag)) {
	    read ($gzip_fh, $magic_bytes, 2);
	    close ($gzip_fh);
	    $magic_number = unpack ('S>', $magic_bytes); # unsigned, short, big endian
	    return $magic_number == 0x1f8b;
	}
	return 1; # if we can't open, assume it is.
    }

    return 0;
}

# Subroutine to unzip zipped logfile into a temp dir.
# May require privileges.
sub gunzip_logfile {
    my ($logfile, $temp_dir) = @_;
    my ($temp_in_file, $temp_out_file, $temp_logfile);

    if (!-r $logfile &&
	$privsep_flag && $nonpriv_flag) {
	$temp_logfile = &send_priv_req ("gunzip:$logfile");
	return ($temp_logfile);
    }

    $temp_in_file = basename ($logfile);
    $temp_out_file = substr ($temp_in_file, 0, length ($temp_in_file) - 3);
    $temp_logfile = $temp_dir . '/' . $temp_out_file;

    copy ($logfile, "$temp_dir/$temp_in_file");
    gunzip "$temp_dir/$temp_in_file" => $temp_logfile or
	&send_error ($logfile, "gunzip failed: $GunzipError");

    # Remove in file.
    unlink ("$temp_dir/$temp_in_file");

    return ($temp_logfile);
}

# Subroutine to return a SHA256 hash of the first log line (or 0).
# This subroutine may be touching files only accessible by root,
# and &is_gzip will work on such files.
sub first_log_line_sha256_digest {
    my ($logfile) = @_;
    my ($first_line, $sha256_digest, $gzip_fh);

    if (!-r $logfile && $privsep_flag && $nonpriv_flag) {
	$sha256_digest = &send_priv_req ("get-hash:$logfile");
	return ($sha256_digest);
    }
    elsif (&is_gzip ($logfile)) {
	$gzip_fh = IO::Uncompress::Gunzip->new ($logfile)
	    or die "gunzip failed: $GunzipError\n";
	$first_line = <$gzip_fh>;
	close ($gzip_fh);
	if (defined ($first_line)) {
	    chomp ($first_line);
	    $sha256_digest = sha256_hex ($first_line);
	    return ($sha256_digest);
	}
    }
    elsif (open (LOG, '<', $logfile)) {
	$first_line = <LOG>;
	close (LOG);
	if (defined ($first_line)) {
	    chomp ($first_line);
	    $sha256_digest = sha256_hex ($first_line);
	    return ($sha256_digest);
	}
    }
    return 0;
}

# THIS IS NO LONGER USED, WILL KEEP AROUND FOR A WHILE IN CASE I
# DECIDE I NEED IT AGAIN. THE WEB_DATE_STRING PARSING IS INCOMPLETE.
# Replaced with SHA256 digest on first line to avoid dealing with
# parsing or timezone issues.
# Subroutine to return the parsed time of the first log line (or 0).
# DATE_STRING = standard syslog format
# DATE_STRING2 = process accounting log format
# RFC3339_date_string = RFC3339, newsyslog log rotation format
sub first_log_line_time {
    my ($logfile) = @_;
    my ($first_line, $log_time, $date);
    my $DATE_STRING = '\w{3}\s{1,2}\d{1,2}\s\d{2}:\d{2}:\d{2}';
    my $DATE_STRING2 = '\w{3}\s\w{3}\s{1,2}\d{1,2}\s\d{2}:\d{2}:\d{2}';
    my $WEB_DATE_STRING = '\[\w{3}\s\w{3}\s\d{1,2}\s\d{2}:\d{2}:\d{2}\.\d{6}\s\d{4}\]';
    my $RFC3339_date_string = '\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.\d{3}Z';
    my $timezone = $TIME_ZONE;
    my $rfc3339_timezone = 'UTC';

    if (open (LOG, '<', $logfile)) {
	$first_line = <LOG>;
	close (LOG);
	if (defined ($first_line)) {
	    chomp ($first_line);
	    if ($first_line =~ /^($DATE_STRING|$DATE_STRING2|$RFC3339_date_string)/) {
		$date = $1;
		$timezone = $rfc3339_timezone if ($date =~ /^$RFC3339_date_string/);
		$log_time = parsedate ($date, PREFER_PAST => 1, ZONE => $timezone);
		return ($log_time);
	    }
	}
    }
    return 0;
}

# Identify any rotated logs which have modification times more recent than
# our last check. Was going to check here if the first one found had a line
# newer than our last check, but I don't want to unzip files twice.
# Was ignoring gzips for a few versions.
# Assumption: /var/log and all other log file locations are world-readable,
sub identify_rotated_logs {
    my ($logfile, $old_checktime) = @_;
    my ($logdir, $logbase, @files, $file, $size, $mtime);
    my ($rotated_logs_flag, @rotated_logs);
    my $first_log_time;

    $rotated_logs_flag = 0;

    # Get directory and filename of logfile from full path.
    $logdir = dirname ($logfile);
    $logbase = basename ($logfile);

    # Read directory, searching for matching files.
    # Assumes a single-digit number of rotated logs.
    # Added match for gzips; sizes may be less meaningful.
    if (opendir (DIR, $logdir)) {
	@files = grep (/^$logbase\.\d(\.gz){0,1}$/, readdir (DIR));

	# Find files that have been modified since our last check.
	foreach $file (reverse (sort (@files))) {
	    ($size, $mtime) = &get_size ("$logdir/$file");
	    if ($mtime > $old_checktime) { # a rotated log that needs checking
		if (!$rotated_logs_flag) { # first one we find
		    $rotated_logs_flag = 1;
		}
		push (@rotated_logs, "$logdir/$file");
	    }
	}
	
	closedir (DIR); 
    }

    return ($rotated_logs_flag, @rotated_logs);
}

# Subroutine to read process accounting log files directly.
# Does not require root privileges.    
sub openbsd_read_process_acct_log {
    my ($acct_log, $checktime, $temp_dir) = @_;
    my ($found_first_record,
	$acct_file, $acct_file_size, $acct_file_mtime,
	$old_size, $processing_records);
    my ($command, $utime, $stime, $etime, $io, $btime, $uid, $gid,
	$mem, $tty, $pid, $flags);
    my ($date_time, $user, $cpu, $time, $delta, $duration);
    my ($new_checktime);
    my ($temp_fh);
    my ($rotated_logs_flag, @rotated_acct_logs, $acct_temp_logfile);
    my %DEV_NAME = (
	"-1", "__",
	"256","tty",
	"2048","tty00",
	"2049","tty01",
	"2050","tty02",
	"2051","tty03",
	"2052","tty04",
	"2053","tty05",
	"2054","tty06",
	"2055","tty07",
	"2056","tty08",
	"2057","tty09",
	"2058","tty0a",
	"2059","tty0b",
	"3072","ttyC0",
	"3073","ttyC1",
	"3074","ttyC2",
	"3075","ttyC3",
	"3076","ttyC4",
	"3077","ttyC5",
	"3078","ttyC6",
	"3079","ttyC7",
	"3080","ttyC8",
	"3081","ttyC9",
	"3082","ttyCa",
	"3083","ttyCb",
	"3327","ttyCcfg",
	"16896","ttyU0",
	"16897","ttyU1",
	"16898","ttyU2",
	"16899","ttyU3",
	"24064","ttyVI00",
	"24074","ttyVI10",
	"24084","ttyVI20",
	"24094","ttyVI30",
	"24104","ttyVI40",
	"9728","ttyc0",
	"9729","ttyc1",
	"9730","ttyc2",
	"9731","ttyc3",
	"9732","ttyc4",
	"9733","ttyc5",
	"9734","ttyc6",
	"9735","ttyc7",
	"1280","ttyp0",
	"1281","ttyp1",
	"1282","ttyp2",
	"1283","ttyp3",
	"1284","ttyp4",
	"1285","ttyp5",
	"1286","ttyp6",
	"1287","ttyp7",
	"1288","ttyp8",
	"1289","ttyp9",
	"1316","ttypA",
	"1317","ttypB",
	"1318","ttypC",
	"1319","ttypD",
	"1320","ttypE",
	"1321","ttypF",
	"1322","ttypG",
	"1323","ttypH",
	"1324","ttypI",
	"1325","ttypJ",
	"1326","ttypK",
	"1327","ttypL",
	"1328","ttypM",
	"1329","ttypN",
	"1330","ttypO",
	"1331","ttypP",
	"1332","ttypQ",
	"1333","ttypR",
	"1334","ttypS",
	"1335","ttypT",
	"1336","ttypU",
	"1337","ttypV",
	"1338","ttypW",
	"1339","ttypX",
	"1340","ttypY",
	"1341","ttypZ",
	"1290","ttypa",
	"1291","ttypb",
	"1292","ttypc",
	"1293","ttypd",
	"1294","ttype",
	"1295","ttypf",
	"1296","ttypg",
	"1297","ttyph",
	"1298","ttypi",
	"1299","ttypj",
	"1300","ttypk",
	"1301","ttypl",
	"1302","ttypm",
	"1303","ttypn",
	"1304","ttypo",
	"1305","ttypp",
	"1306","ttypq",
	"1307","ttypr",
	"1308","ttyps",
	"1309","ttypt",
	"1310","ttypu",
	"1311","ttypv",
	"1312","ttypw",
	"1313","ttypx",
	"1314","ttypy",
	"1315","ttypz"
	);

    # Returns @rotated_acct_logs with changes since $checktime, sorted
    # oldest to newest, which is what we want.
    ($rotated_logs_flag, @rotated_acct_logs) = &identify_rotated_logs ($acct_log, $checktime);
    # Unlike using lastcomm, which presents the records from newest to
    # oldest, we're going to start with the oldest file and read its
    # records ourselves from oldest to newest.
    push (@rotated_acct_logs, $acct_log);

    # Start where we left off if the oldest file that changed since we
    # last checked is the same one we're starting with.
    $old_size = 0;
    $old_size = $log_size{$acct_log} if ($checktime);

    # Start looking at accounting files, and allow for .gz rotated
    # logs. (Don't sort here because &identify_rotated_logs already
    # did it the way we want, oldest first.)
    foreach $acct_file (@rotated_acct_logs) {
	if (&is_gzip ($acct_file)) {
	    # gunzip into a temp file and look at that (doesn't currently
	    # happen on OpenBSD).
	    $acct_temp_logfile = &gunzip_logfile ($acct_file, $temp_dir);
	    $acct_file = $acct_temp_logfile;
	}

	$found_first_record = 0;
	$processing_records = 0;

	# Open file and look for first record if we need it. Once
	# we have a first record, open temp file and start writing out
	# to it.
	if (open (ACCTLOG, '<', $acct_file)) {
	    $/ = \64; # read 64-byte records
	    # Starting with the oldest file with an mtime > checktime.
	    # Skip past any records with time < checktime.
	    if (!$found_first_record) {
		seek (ACCTLOG, $old_size - 64, 0);
		# would like to test if this record is older than
		# checktime, if not, should do binary search or start
		# at beginning (watching for out-of-sequence records by
		# accounting for duration).
	    }

	    while (<ACCTLOG>) {
		($command, $utime, $stime, $etime, $io, $btime, $uid, $gid, $mem, $tty, $pid, $flags) = unpack ("A24 S< S< S< S< Q< L< L< L< l< L< b32", $_);
		if (!$processing_records &&
		    ($btime > $checktime || $btime + (&expand ($etime) / AHZ) > $checktime)) {
		    $found_first_record = 1;
		    $processing_records = 1;

		    # Create temp file (OpenBSD only).
		    if ($^O eq 'openbsd') {
			($temp_fh, $temp_logfile) = mkstemp ("$temp_dir/reportnew.XXXXXXX");
			if (!defined ($temp_logfile)) {
			    &send_error ($temp_logfile, "Could not open temp file $temp_logfile for writing. $!");
			    exit; # or just return?
			}
		    }
		    else { # this shouldn't be reached
			# create and open
			($temp_fh, $temp_logfile) = tempfile ("$temp_dir/reportnew.XXXXXXX");
			if (!defined ($temp_logfile)) {
			    &send_error ($temp_logfile, "Could not open temp file $temp_logfile for writing. $!");
			    exit; # or just return?
			}
		    }
		}
		if ($processing_records) {
		    $date_time = ctime ($btime);
		    # Remove year.
		    $date_time = substr ($date_time, 0, length ($date_time) - 6);
		    # Go from raw device number to name.
		    if (defined ($DEV_NAME{$tty})) {
			$tty = $DEV_NAME{$tty};
		    }
		    else {
			$tty = '??';
		    }
		    # Convert uid to user (or use uid if no user in passwd file).
		    $user = getpwuid($uid) || $uid;
		    # Command + pid.
		    $command = "$command\[$pid\]";
		    # Process flags.
		    $flags = &flagbits ($flags);
		    # User time plus system time.
		    $cpu = (&expand ($utime) + &expand ($stime)) / AHZ;
		    $cpu = sprintf "%.2f", $cpu; # was %6.2f for formatted cols
		    $delta = &expand ($etime) / AHZ;
		    $duration = sprintf "%1.0f:%02.0f:%05.2f", $delta / SECSPERHOUR,
			fmod ($delta, SECSPERHOUR) / SECSPERMIN,
			fmod ($delta, SECSPERMIN);
		    print $temp_fh "$date_time $tty $user $command $flags $cpu secs $duration\n";
		}
	    }
	}
	else {
	    &send_error ($acct_file, "Could not open acct file $acct_file. $!");
	    exit;
	}
	# set checktime at the end
	$new_checktime = gettimeofday();
	close (ACCTLOG);
	$/ = $NL;
    }

    if (!$found_first_record || !$processing_records) {
	# This should provoke an error and exit, we never wrote anything
	# out. This can happen if process accounting is turned off.
	&send_error ($acct_file, "Could not find any new records in acct file $acct_file (OpenBSD method). This shouldn't happen--is process accounting on?");
	exit;
    }
    # Otherwise, close the temp file and return log path.
    close ($temp_fh);
	
    return ($temp_logfile, $new_checktime);
}

# Subroutine to expand accounting time.
sub expand {
    my ($time) = @_;
    my $newtime;

    $newtime = $time & 017777;
    $time >>= 13;
    while ($time) {
        $time--;
        $newtime <<= 3;
    }
    return ($newtime);
}

# Subroutine to return process flags in human-readable form.
# Might want to re-do this with unpacking flags to hex and
# using bitwise operators. (0x02 was ASU, now removed)
#    vec ($AFORK, 0, 8) = 0x01; # F
#    vec ($AMAP, 0, 8) = 0x04; # M
#    vec ($ACORE, 0, 8) = 0x08; # D
#    vec ($AXSIG, 0, 8) = 0x10; # X
#    vec ($APLEDGE, 0, 8) = 0x20; # P
#    vec ($ATRAP, 0, 8) = 0x40; # T
#    vec ($AUNVEIL, 0, 8) = 0x80; # U
#    vec ($APINSYS, 0, 8) = 0x200; # S
#    vec ($ABTCFI, 0, 8) = 0x400; # B
sub flagbits {
    my ($flag) = @_;
    my ($output, $idx);
    my $flagcodes = 'F-MDXPTU-SB';

    $output = '-';
    for ($idx = 0; $idx <= 32; $idx++) {
	if (substr ($flag, $idx, 1) eq '1') {
	    $output .= substr ($flagcodes, $idx, 1);
	}
    }

    return ($output);
}

# Subroutine to read process accounting log files using lastcomm.
# Does not require root privileges on BSDs (including macOS), but
# does on Linux.
# Linux also gzips rotated process accounting logs and expects them
# to be piped to lastcomm with zcat.
sub read_process_acct_log {
    my ($acct_log, $checktime, $temp_dir) = @_;
    my ($idx, $acct_file, @lastcomm_logs, $log_line, $temp_logfile);
    my ($rotated_logs_flag, @rotated_acct_logs, $acct_temp_logfile);
    my ($command, $flags, $user, $tty, $time_info,
	$cpu, $secs, $day_name, $month, $day, $time, $duration,
	$time_dec);
    my ($new_checktime);
    my ($temp_fh);
    # last field A30+, no duration
    my $linux_format = 'A16 A7 A9 A9 A*';
    # last field A44+, includes duration
    my $macos_format = 'A11 A8 A9 A9 A*';
    my ($req_response); # for privsep

    if ($^O eq 'linux' && $privsep_flag && $nonpriv_flag) {
	$req_response = &send_priv_req ("get-linux-pacct:$logfile:$checktime");
	if (defined ($req_response) && $req_response =~ /,/) {
	    ($temp_logfile, $new_checktime) = split (/,/, $req_response);
	    return ($temp_logfile, $new_checktime);
	}
	&send_error ($logfile, "Received unexpected response from privileged parent process trying to get Linux process accounting from $logfile.");
	exit; # or just return?
    }

    # Read process accounting logs, out to end or to $checktime, whichever
    # comes first.  Write out to temp file, in reverse order, with more
    # standardized date/time stamps.  Return $temp_logfile name.

    # Do lastcomm, starting with the most recent and working backward,
    # reading lines into @lastcomm_logs with parsed date/time, until
    # we reach $checktime or run out of logs.

    # This algorithm doesn't quite work, because lastcomm's times are
    # the time the process started, but the record is written when it
    # ends, so the records can be out of order.
    # This could be fixed by checking that the time of the new log
    # is earlier, even if the duration is added to it (or if the
    # time is earlier by more than the duration).

    # Only looks at acct.N[.gz] where N is a single digit, Linux will go to
    # double digits. Also returns oldest first.
    # $rotated_logs_flag ignored, we're always going to do something
    # unless there's no log at all, which should already have been
    # determined (unless it just got deleted).
    ($rotated_logs_flag, @rotated_acct_logs) = &identify_rotated_logs ($acct_log, $checktime);
    # Insert current log at the front. It will be sorted anyway, but
    # this puts it where it belongs.
    unshift (@rotated_acct_logs, $acct_log);

    # Set new checktime to roughly correspond with the last log entry
    # (first one in the newest file, which we process first).
    $new_checktime = gettimeofday();
    # Sorting from oldest first to newest first. Maybe make an option
    # to &identify_rotated_logs to avoid unnecessary sort.
    # Note that sort here and in &identify_rotated_logs won't work
    # right if support is added for more than one digit in the filename,
    # unless we sort numerically on the number and keep the one without
    # a number at the front.
    foreach $acct_file (sort @rotated_acct_logs) {
	if (&is_gzip ($acct_file)) {
	    # gunzip into a temp file and run lastcomm on that.
	    $acct_temp_logfile = &gunzip_logfile ($acct_file, $temp_dir);
	    $acct_file = $acct_temp_logfile;
	}

	if (!open (LASTCOMM, '-|', $LASTCOMM, '-f', $acct_file)) {
	    &send_error ($acct_file, "Could not open acct file $acct_file. $!");
	    exit; # or just return?
	}
	while (<LASTCOMM>) {
	    # Parse line, check time.  If lastcomm time <= $check_time,
	    # then exit with "last."
	    chomp;

	    # Linux has older format with no duration.
	    if ($^O eq 'linux') {
	       ($command, $flags, $user, $tty, $time_info) = unpack ($linux_format, $_);
	       $flags =~ s/^\s*//;
	       $time_info =~ s/^\s*//;
	       ($cpu, $secs, $day_name, $month, $day, $time) = split (/\s+/, $time_info, 6);
	       $duration = '(0:00:00.00)'; # fake it for the calculation
	    }
	    elsif ($^O eq 'darwin') {
		# macOS can have spaces in command names.
		($command, $flags, $user, $tty, $time_info) = unpack ($macos_format, $_);
		$flags =~ s/^\s*//;
		$time_info =~ s/^\s*//;
		($cpu, $secs, $day_name, $month, $day, $time, $duration) = split (/\s+/, $time_info, 7);
	    }
	    else { # OpenBSD, macOS
    	    	 ($command, $flags, $user, $tty, $time_info) = split (/\s+/, $_, 5);
	    	 ($cpu, $secs, $day_name, $month, $day, $time, $duration) = split (/\s+/, $time_info, 7);
	    }
	    $time = $day_name . ' ' . $month . ' ' . $day . ' ' . $time;
	    $time_dec = parsedate ($time, PREFER_PAST => 1);
	    $duration =~ s/^\((.*)\)$/$1/;

	    # Stop this once we reach an entry earlier than last check.
	    # Correcting for long-duration processes started a long
	    # time ago that are out of sequence.
	    if ($time_dec < $checktime) {
		my ($dur_hours, $dur_mins, $dur_secs) = split (/:/, $duration);
		if ($checktime - $time_dec > ($dur_hours * SECSPERHOUR +
					      $dur_mins * SECSPERMIN +
					      $dur_secs)) {
		    unlink ($acct_temp_logfile) if (defined ($acct_temp_logfile) &&
						    $acct_file eq $acct_temp_logfile);
		    last;
		}
	    }
	    
	    $log_line = "$time $tty $user $command $flags $cpu $secs";
	    $log_line .= " $duration" unless ($^O eq 'linux');

	    push (@lastcomm_logs, $log_line);
	}
	close (LASTCOMM);
	unlink ($acct_temp_logfile) if (defined ($acct_temp_logfile) &&
					$acct_file eq $acct_temp_logfile);
    }

    # Now write out @lastcomm_logs to a new temp file in reverse order.

    # Create temp file.
    if ($^O eq 'openbsd') {
	($temp_fh, $temp_logfile) = mkstemp ("$temp_dir/reportnew.XXXXXXX");
	if (!defined ($temp_logfile)) {
	    &send_error ($temp_logfile, "Could not open temp file $temp_logfile for writing. $!");
	    exit; # or just return?
	}
    }
    else {
	# create and open
	($temp_fh, $temp_logfile) = tempfile ("$temp_dir/reportnew.XXXXXXX");
	if (!defined ($temp_logfile)) {
	    &send_error ($temp_logfile, "Could not open temp file $temp_logfile for writing. $!");
	    exit; # or just return?
	}
	chomp ($temp_logfile);
    }

    # Print out each log line to the temp file.
    foreach $log_line (reverse (@lastcomm_logs)) {
	print $temp_fh "$log_line\n";
    }

    # Close temp file.
    close ($temp_fh);

    # Return the filename.
    return ($temp_logfile, $new_checktime);
}

# Read log information from Linux journal into a temp file to process.
# This subroutine trusts the config parser to have validated the
# arguments.
# Requires privileges.
sub read_linux_journal {
    my ($logfile, $checktime, $temp_dir) = @_;
    my ($temp_logfile, $temp_fh, $new_checktime);
    my (@time_components, $time_string, $full_time);
    my @selection_args;
    my $NO_ENTRIES = '-- No entries --';
    my $req_response; # for privilege separation

    if ($privsep_flag && $nonpriv_flag) {
	$req_response = &send_priv_req ("get-journal:$logfile:$checktime");
	if (defined ($req_response) && $req_response =~ /,/) {
	    ($temp_logfile, $new_checktime) = split (/,/, $req_response);
	    return ($temp_logfile, $new_checktime);
	}
	&send_error ($logfile, "Received unexpected response from privileged parent process trying to get Linux journal info from $logfile.");
	exit; # or just return?
    }

    # Create temp file.
    # create and open
    ($temp_fh, $temp_logfile) = tempfile ("$temp_dir/reportnew.XXXXXXX");
    if (!defined ($temp_logfile)) {
	&send_error ($temp_logfile, "Could not open temp file $temp_logfile for writing. $!");
	exit; # or just return?
    }
    chomp ($temp_logfile);

    # Convert last checktime to English.
    if ($checktime != 0) {
	@time_components = localtime ($checktime);
	$time_string = strftime "%Y-%m-%d %H:%M:%S", @time_components;
	$full_time = sprintf "%s.%06d", $time_string, $checktime;
    }

    # Formulate selection arguments.
    if ($logfile =~ /journal unit ([\w\-\.]+)$/) {
	my $unit_arg = $1;
	if (!grep (/^$unit_arg$/, @linux_journal_units)) {
	    &send_error ($logfile, "Specified journal unit $unit_arg is not enabled.");
	    exit; # or just return?
	}
	@selection_args = ('-u', $unit_arg);
    }
    elsif ($logfile =~ /journal syslog-id ([\w\-\.]+)$/) {
	my $syslogid_arg = $1;
	# no check today
	@selection_args = ('-t', $syslogid_arg);
    }
    elsif ($logfile =~ /journal syslog-facility ([\w\-\.]+)$/) {
	my $syslog_facility_arg = $1;
	if (!grep (/^$syslog_facility_arg$/, @linux_journal_syslog_facilities)) {
	    &send_error ($logfile, "Specified journal syslog facility $syslog_facility_arg is not defined.");
	    exit; # or just return?    
	}
	@selection_args = ('--facility=' . $syslog_facility_arg);
    }
    else {
	&send_error ($logfile, "Could not parse journal logfile name. $logfile");
	exit; # or just return?
    }
    
    # Append date if checktime nonzero.
    push (@selection_args, '--since', $full_time) unless (!$checktime);

    # Open journalctl to read log lines.
    if (!open (JOURNAL, '-|', $JOURNALCTL, @selection_args)) {
	&send_error ($logfile, "Could not open file handle for $JOURNALCTL. $!");
	exit; # or just return?
    }

    while (<JOURNAL>) {
	print $temp_fh "$_" unless (/^$NO_ENTRIES$/);
    }

    # Set new checktime.
    $new_checktime = gettimeofday();

    # Close journalctl.
    close (JOURNAL);

    # Close temp file.
    close ($temp_fh);
    
    return ($temp_logfile, $new_checktime);
}

# Return 1 if a regexp is valid, 0 if not.
sub valid_regexp {
    my ($regexp) = @_;

    if (($regexp =~ /\/.*\//) ||
	($regexp =~ /!\/.*\//)) {
	return 1;
    }
    else {
	return 0;
    }
}

# Read the contents of the size file.
# If a current_logfile is specified, do not update hashes for that logfile.
sub read_size_file {
    my ($size_file, $current_logfile) = @_;
    my ($logfile, $size, $mtime, $checktime, $sha256_digest, $processing_pid);

    if (!-e $size_file) {
	foreach $logfile (@logfiles) {
	    $log_size{$logfile} = 0;
	    $log_mtime{$logfile} = 0;
	    $log_checktime{$logfile} = 0;
	    $log_sha256_digest{$logfile} = '';
	    $log_processing_pid{$logfile} = 0;
	}
	$processing_pid = 0;
    }
    else {
	if (open (SIZEFILE, '<', $size_file)) {
	    if (!flock (SIZEFILE, LOCK_SH)) {
		&send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot lock size file for reading. $!");
	    }
	    while (<SIZEFILE>) {
		chomp;
		($logfile, $size, $mtime, $checktime, $sha256_digest, $processing_pid) = split (/,/);
		if (!defined ($processing_pid)) { # bad line in size file
		    &send_notify ($SHORT_HOSTNAME, $config_file, $master_notify, "Malformed line in size file. $_\n");
		}
		if (!grep ($_ eq $logfile, @logfiles)) {
		    &send_notify ($SHORT_HOSTNAME, $config_file, $master_notify, "Logfile $logfile in size file is not in config file.");
		}
		if (!defined ($current_logfile) || $current_logfile ne $logfile) {
		    $log_size{$logfile} = $size;
		    $log_mtime{$logfile} = $mtime;
		    $log_checktime{$logfile} = $checktime;
		    if (!defined ($sha256_digest)) { # old size file
			$sha256_digest = '';
		    }
		    elsif ($sha256_digest eq 'null') { # how we store null ones
			$sha256_digest = '';
		    }
		    $log_sha256_digest{$logfile} = $sha256_digest;
		    if (!defined ($processing_pid)) { # old size file
			$processing_pid = 0;
		    }
		    $log_processing_pid{$logfile} = $processing_pid;
		}
	    }
	    if (!flock (SIZEFILE, LOCK_UN)) {
		&send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot unlock size file after reading. $!");
	    }
	    close (SIZEFILE);
	}
	else {
	    &send_error ($size_file, "Cannot open size file. $!");
	    exit;
	}

	if (!defined ($current_logfile)) {
	    foreach $logfile (@logfiles) {
		if (!defined ($log_size{$logfile})) {
		    &send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Logfile $logfile in config file is not in size file.");
		    $log_size{$logfile} = 0;
		    $log_mtime{$logfile} = 0;
		    $log_checktime{$logfile} = 0;
		    $log_sha256_digest{$logfile} = '';
		    $log_processing_pid{$logfile} = 0;
		    &write_size_file ($size_file, $logfile, $LOG_APPEND);
		}
	    }
	}
    }
}

# Get current log file size and mtime.
sub get_size {
    my ($logfile) = @_;
    my ($dev, $ino, $mode, $nlink, $uid, $gid, $rdev, $size, $atime,
	$mtime, $ctime, $blksize, $blocks);

    ($dev, $ino, $mode, $nlink, $uid, $gid, $rdev, $size, $atime,
     $mtime, $ctime, $blksize, $blocks) = stat $logfile;

    $size = 0 if (!defined ($size));
    $mtime = 0 if (!defined ($mtime));

    return ($size, $mtime);
}

# Return 1 if line matches regexp, 0 if not.
# If $return_group is specified, on match the first capture group is returned.
sub match_line {
    my ($regexp, $line, $return_group) = @_;
    my ($negative);

    if (!defined ($return_group)) {
	$return_group = 0;
    }

    if (substr ($regexp, 0, 1) eq '!') {
	$negative = 1;
	$regexp =~ s/^!//;
    }
    else {
	$negative = 0;
    }

    $regexp =~ s/^\///;
    $regexp =~ s/\/$//;

    if (($negative && ($line =~ !/$regexp/)) ||
	(!$negative && ($line =~ /$regexp/))) {
	return $1 if $return_group;
	return 1;
    }
    else {
	return 0;
    }
}

# Execute a script as nonprivileged user.
sub execute_script {

# Should verify the existence of script, permissions, and what else?

    if (fork) {
	wait;
	return $? >> 8;
    }

    # -- child
    # Drop privileges.
# Not yet ready...
#    drop_privileges('nobody'); # better, use _reportnew.
#    exec @_;
}

# Send a mail notification.
sub send_notify {
    my ($hostname, $logfile, $notify_list, @lines) = @_;
    my ($line);

    if (!defined ($notify_list)) {
	if (!defined ($master_notify)) {
	    # This seems to happen periodically, indicating a bug
	    # in the config parsing.
	    $notify_list = $SECURITY_ADMIN;
	}
	else {
	    $notify_list = $master_notify;
	}
    }

    # It is possible to get here before $email_sender is defined if
    # an error occurs while still parsing the config.
    $email_sender = $EMAIL_SENDER if (!defined ($email_sender));

    if ($debug_mode) {
	print "$hostname: $logfile ($notify_list)\n";
	foreach $line (@lines) {
	    print "$line\n";
	}
    }

    else {
	open (MAIL, '|-', $SENDMAIL, '-t');
	print MAIL "From: Reporter <$email_sender>\n";
	print MAIL "To: $notify_list\n";
	print MAIL "Subject: $hostname $logfile\n\n";
	foreach $line (@lines) {
	    print MAIL "$line\n";
	}
	close (MAIL);
    }
}

# Send a text message. This code could easily be merged with
# send_notify, it is identical except for the mail format.
sub send_text {
    my ($hostname, $logfile, $notify_list, @lines) = @_;
    my ($line);

    if (!defined ($notify_list)) {
	if (!defined ($master_notify)) {
	    # This seems to happen periodically, indicating a bug
	    # in the config parsing.
	    $notify_list = $SECURITY_ADMIN;
	}
	else {
	    $notify_list = $master_notify;
	}
    }

    if ($debug_mode) {
	print "$hostname: $logfile ($notify_list)\n";
	foreach $line (@lines) {
	    print "$line\n";
	}
    }

    else {
	open (MAIL, '|-', $SENDMAIL, '-t');
	print MAIL "To: $notify_list\n\n";
	foreach $line (@lines) {
	    print MAIL "$line\n";
	}
	close (MAIL);
    }
}

# Send error notification.
sub send_error {
    my ($filename, $error) = @_;

    if (defined ($master_notify)) {
	&send_notify ($SHORT_HOSTNAME, $filename, $master_notify, $error);
    }
    else {
	&send_notify ($SHORT_HOSTNAME, $filename, $SECURITY_ADMIN, $error);
    }
}

# Write out size file.
# This is always called immediately after a read_size_file, though one
# which might skip the current logfile.
# If current_logfile is not specified or the size file doesn't exist
# or can't be opened for reading but can be opened for writing and locked,
# we write out everything.
# If it's a new logfile that isn't in the size file, we just append it
# to the end.
# Otherwise, we read everything in and overwrite with the just-read data
# except for the log file we're updating.
sub write_size_file {
    my ($size_file, $current_logfile, $start_or_end) = @_;
    my ($logfile, $sha256_digest, $my_pid);
    my ($write_all_logfiles,
	$lock_timeout_limit, @size_file_lines, $size_file_line);

    # If we're just adding a new logfile to the end of the size file,
    # do that.
    if (defined ($current_logfile) && $start_or_end == $LOG_APPEND) {
	if (!open (SIZEFILE, '>>', $size_file)) {
	    &send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot open size file for appending. $!");
	    exit;
	}
	$lock_timeout_limit = time() + $SIZE_FILE_LOCK_TIMEOUT_LIMIT;
	until (flock (SIZEFILE, LOCK_EX | LOCK_NB)) {
	    if (time() > $lock_timeout_limit) {
		&send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot lock size file for writing. $!");
		exit;
	    }
	    sleep 1;
	}
	print SIZEFILE "$current_logfile,$log_size{$current_logfile},$log_mtime{$current_logfile},$log_checktime{$current_logfile},null,0\n";
	if (!flock (SIZEFILE, LOCK_UN)) {
	    &send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot unlock size file after appending. $!");
	    exit;
	}
	close (SIZEFILE);
	return;
    }

    # If we're just changing a single logfile, read in the current
    # size file without parsing (but we do lock).
    if (defined ($current_logfile) && (-e $size_file)) {
	$write_all_logfiles = 0;
	if (open (SIZEFILE, '<', $size_file)) {
	    if (flock (SIZEFILE, LOCK_SH)) {
		@size_file_lines = <SIZEFILE>;
	    }
	    else {
		&send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot lock size file for reading. $!");
		exit;
	    }
	}
	else {
	    &send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot open size file for reading. $!");
	    exit;
	}
	if (!flock (SIZEFILE, LOCK_UN)) {
	    &send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot unlock size file after reading. $!");
	    exit;
	}
	close (SIZEFILE);
    }
    else {
	$write_all_logfiles = 1;
    }

    # Now, we write everything out, either with what we have or with what
    # was just read from the size file except for our current logfile.
    if (!open (SIZEFILE, '>', $size_file)) {
	&send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot open size file for writing. $!");
	exit;
    }

    $lock_timeout_limit = time() + $SIZE_FILE_LOCK_TIMEOUT_LIMIT;
    until (flock (SIZEFILE, LOCK_EX | LOCK_NB)) {
	if (time() > $lock_timeout_limit) {
	    &send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot lock size file for writing. $!");
	    exit;
	}
	sleep 1;
    }

    # If we're writing out all log files, do that.
    if ($write_all_logfiles) {
	foreach $logfile (@logfiles) {
	    # Write out 'null' if blank. Should only be for process accounting logs.
	    if (!defined ($log_sha256_digest{$logfile})) {
		$sha256_digest = 'null';
	    }
	    else {
		$sha256_digest = $log_sha256_digest{$logfile};
		$sha256_digest = 'null' if ($sha256_digest eq '');
	    }

	    # Write it all out.
	    if ($logfile eq $current_logfile && $start_or_end == $LOG_PROCESSING_START) {
		$my_pid = $$;
	    }
	    else {
		$my_pid = 0;
	    }
	    print SIZEFILE "$logfile,$log_size{$logfile},$log_mtime{$logfile},$log_checktime{$logfile},$sha256_digest,$my_pid\n";
	}
    }
    else { # just changing current log info
	foreach $size_file_line (@size_file_lines) {
	    chomp ($size_file_line);
	    ($logfile) = split (/,/, $size_file_line);
	    if ($logfile eq $current_logfile) {
		# Write out 'null' if blank. Should only be for process accounting logs.
		if (!defined ($log_sha256_digest{$logfile})) {
		    $sha256_digest = 'null';
		}
		else {
		    $sha256_digest = $log_sha256_digest{$logfile};
		    $sha256_digest = 'null' if ($sha256_digest eq '');
		}

		# Write it all out.
		if ($logfile eq $current_logfile && $start_or_end == $LOG_PROCESSING_START) {
		    $my_pid = $$;
		}
		else {
		    $my_pid = 0;
		}
		print SIZEFILE "$logfile,$log_size{$logfile},$log_mtime{$logfile},$log_checktime{$logfile},$sha256_digest,$my_pid\n";
	    }
	    else {
		print SIZEFILE "$size_file_line\n";
	    }
	}
    }

    # Unlock and close size file.
    if (!flock (SIZEFILE, LOCK_UN)) {
	&send_notify ($SHORT_HOSTNAME, $size_file, $master_notify, "Cannot unlock size file after writing. $!");
	exit;
    }
    close (SIZEFILE);
}

# Subroutine to return 1 if process exists, 0 otherwise.
sub pid_exists {
    my ($pid) = @_;

    if (kill (0, $pid) || $!) {
	return 1 unless $! eq 'No such process';
    }

    return 0;
}
    
# Subroutine to replace macro names with values on preprocessing.
# Process host macros then global macros.
sub preproc_macro_substitution {
    my ($orig_regexp_line, $line_num) = @_;
    my ($more_to_process, $regexp_line, $macro_name, $global_macro);

    $regexp_line = $orig_regexp_line;

    $more_to_process = 1;

    while ($more_to_process) {
	if ($regexp_line =~ /%%([\w\-]+)%%/) {
	    $macro_name = $1;
	    $global_macro = 0;
	    if (!defined ($preproc_macro{$macro_name})) {
		if (defined ($global_preproc_macro{$macro_name})) {
		    $global_macro = 1;
		}
		else {
		    &send_error ($config_file, "Undefined preproc macro %%$macro_name%% on line $line_num. $orig_regexp_line\n");
		    exit;
		}
	    }
	    # Replace all occurrences.
	    if ($global_macro) {
		$regexp_line =~ s/%%$macro_name%%/$global_preproc_macro{$macro_name}/g;	
	    }
	    else {
		$regexp_line =~ s/%%$macro_name%%/$preproc_macro{$macro_name}/g;
	    }
	}
	else {
	    $more_to_process = 0;
	}
    }
    return ($regexp_line);
}

# Subroutine to rewrite output containing macro values by
# appending or substituting macro names. This would work
# better if only executed where we know the macro names were
# present in preprocessing.
# We have to go through all the macros on each line.
# Bad stuff could happen if there are macro values that match
# macro names.
# Process host macros first, then global macros.
sub postproc_macro_substitution {
    my (@output_lines) = @_;
    my ($output_line, $macro_value, $macro_name);

    my $APPEND = 1;
    my $SUBSTITUTE = 0;

    if ($have_postproc_macros) {
	foreach $output_line (@output_lines) {
	    foreach $macro_value (keys (%append_macro)) {
		if ($output_line =~ /$macro_value/) {
		    $output_line = &postproc_match_and_replace ($output_line, $macro_value, $append_macro{$macro_value}, $APPEND);
		}
	    }
	    foreach $macro_value (keys (%substitute_macro)) {
		if ($output_line =~ /$macro_value/) {
		    $output_line = &postproc_match_and_replace ($output_line, $macro_value, $substitute_macro{$macro_value}, $SUBSTITUTE);	    
		}
	    }
	}
    }

    if ($have_global_postproc_macros) {
	foreach $output_line (@output_lines) {
	    foreach $macro_value (keys (%global_append_macro)) {
		if ($output_line =~ /$macro_value/) {
		    $output_line = &postproc_match_and_replace ($output_line, $macro_value, $global_append_macro{$macro_value}, $APPEND);
		}
	    }
	    foreach $macro_value (keys (%global_substitute_macro)) {
		if ($output_line =~ /$macro_value/) {
		    $output_line = &postproc_match_and_replace ($output_line, $macro_value, $global_substitute_macro{$macro_value}, $SUBSTITUTE);	    
		}
	    }
	}
    }
    
    return (@output_lines);
}

# Subroutine to do post-processing macro matching and replacement,
# with special handling for IP addresses.
sub postproc_match_and_replace {
    my ($line, $macro_value, $macro_name, $append) = @_;

    # Special case handling of macro value matches for IP addresses.
    # Only match and replace if the IP address is anchored on the left
    # side by beginning of line, colon, or left bracket and on the right side
    # by end of line, colon, period, or right bracket.
    #
    # Note that this special casing is NOT done on the front end (preproc
    # macros), as we assume the match rule will contain the context for
    # anchoring the match--if we stuck things in it could break a rule
    # and would be very counter-intuitive to the builder of the config.
    my $IPv4_REGEXP = '^\d{1,3}\\\.\d{1,3}\\\.\d{1,3}\\\.\d{1,3}$';
    my $IPv6_REGEXP = '^(((?=(?>.*?::)(?!.*::)))(::)?(([0-9A-F]{1,4})::?){0,5}|((?5):){6})(\2((?5)(::?|$)){0,2}|((25[0-5]|(2[0-4]|1[0-9]|[1-9])?[0-9])(\.|$)){4}|(?5):(?5))(?<![^:]:)(?<!\.)\z';
    my $START_TOKENS = '^|[\s:\[]';
    my $END_TOKENS = '[\s:\.\]]|$';

    # Replace all occurrences that are neither preceded nor followed by
    # numeric including hex digits, using negative lookbehind and negative
    # lookahead. Might be better to do this instead of the start and end
    # tokens, as well.
    if ($macro_value =~ /^$IPv4_REGEXP$|^$IPv6_REGEXP$/i) {
	if ($line =~ /$START_TOKENS$macro_value$END_TOKENS/) {	
	    if ($append) {
		$line =~ s/(?<![\da-f])($macro_value)(?![\da-f])/$1\[$macro_name\]/g;
	    }
	    else {
		$line =~ s/(?<![\da-f])($macro_value)(?![\da-f])/$macro_name/g;		
	    }
	}
    }
    else {
	if ($append) {
	    $line =~ s/($macro_value)/$1\[$macro_name\]/g;
	}
	else {
	    $line =~ s/$macro_value/$macro_name/g;	
	}
    }
    return ($line);
}
